---
title: Untitled
date: 2025-03-20
tags:
  - blog
---
Advanced Mathematics I MATH1017 Lecture Notes Lorenzo Ntogramatzidis CONTENTS MATH1017 Contents 1 Mathematical logic 3 1.1 Propositional logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.1.1 Negation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.1.2 Conjunction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.1.3 Disjunction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.1.4 Material implication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.1.5 Biconditional . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.1.6 De Morgan’s laws . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.2 Predicate logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.2.1 De Morgan’s laws for quantifiers . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 1.2.2 Equality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 1.2.3 Univocal and functional predicates . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2 Set theory, functions and numerical structures 17 2.1 Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.2 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.2.1 Composition of functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 2.2.2 Inverse function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 2.3 Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.4 Real numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.4.1 Ordering of real numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 2.5 Natural, integer, rational numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 2.6 Maximum/minimum, bounds, supremum/infimum . . . . . . . . . . . . . . . . . . . . . . 44 2.6.1 The absolute value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 2.7 Powers and roots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 2.8 Exponentials and logarithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 2.9 Complex numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 2.9.1 Goniometric functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 2.9.2 Roots of a complex number . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 3 Real-valued functions of a real variable 92 3.1 Monotonic functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94 3.1.1 Subsequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 4 Limits, convergence, continuity 102 4.1 Definition of Limit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 4.1.1 Uniqueness of the limit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 4.1.2 Limit equal to ±∞ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 4.1.3 Limits as x → ±∞ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 4.2 A more general definition of limit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 4.2.1 Limits of restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127 4.2.2 Left and right limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 4.3 Landau symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130 Page 2 of 175 CONTENTS MATH1017 4.4 Continuous functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 4.5 Limit of the composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 4.6 Some further results on continuous functions . . . . . . . . . . . . . . . . . . . . . . . . 143 4.7 Extreme value theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 4.8 Bolzano’s theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 4.8.1 Continuity of the inverse function . . . . . . . . . . . . . . . . . . . . . . . . . . 146 4.9 Some important limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 4.10 Limits of sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156 4.11 Asymptotic expansions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157 4.11.1 Vertical asymptotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 5 Complement: Limits for complex numbers 162 6 Complement: Limits in topological spaces 164 7 Complement: Asymptotic comparison 167 Page 3 of 175 MATH1017 1 Mathematical logic We begin examining the language used in mathematics. Precision is of paramount importance in mathematics; we want to avoid misunderstandings, inconsistencies and imprecisions. A mistake in our proofs and in our mathematical statements may lead to errors in the results we obtain. However, more subtle issues arise when the definitions we have introduced are not “well-posed”, i.e., they do not work in the way we intended. The most classical logical structure is the so-called syllogism, which is a logical argument that applies deductive reasoning to arrive at a conclusion based on two or more propositions that are assumed to be true. The classical example is the following. If the two propositions “all men are mortal” and “Socrates is a man” are asserted to be true, we can conclude that “Socrates is mortal”. However, if we apply the same pattern to the two propositions “the months of the year are twelve” and “February and March are months of the year”, someone might deduce that “February and March are twelve”. This example shows how imprecise our everyday language can be; in particular, in this case the first proposition is written in an imprecise way (although it would not be subject to criticisms in other contexts). If we substitute it with “There are twelve months in a year”, we cannot get to the previous silly conclusion. Even if we do our very best to ensure that we phrase our sentences in a precise way, a problem that remains is the fact that different people may give slightly different meanings to words. For example, Mark asks John “do you own a pet?”, and John replies “Yes, I do”. Assuming that John is telling the truth, the question is phrased in such a way that we do not know if John has exactly one pet or more than one; in the first case we interpret the article “a” in the question as “exactly one”, and in the second we interpret it as “at least one”. This shows that different people may draw different conclusions from this conversation between Mark and John. In mathematics, we cannot allow for these imprecisions and ambiguities in the way we express our results. Generally speaking, in mathematics, if we say that two curves have “an intersection”, we mean at least one intersection; to express that the two curves have “exactly one intersection” we may say that “two curves have one and only one intersection”. Something we do not pay particular attention to in our everyday use of the language is the fact that we do not usually contemplate all the particular cases of our statements. For example, in a geometric construction we could say “let us consider two points in the plane”, without specifying if these points need to be distinct or if they are allowed to be coincident. Similarly, if we identify a triangle as the geometric object formed by the segments through three points of the space, if we do not specify how to choose these three points we may be forced to include, in the set of triangles, segments (if exactly two of the three points coincide or when the three points lie on the same line) and points (if the three points coincide). Another example is the following. Consider the statement “An isosceles triangle has two sides of equal length”; do we mean exactly two or at least two? In the first case, an equilateral triangle must be considered as an isosceles triangle. In the second case, an equilateral triangle is not isosceles. Again, the preferred choice in mathematics is to consider the interpretation of two as at least two, so that an equilateral triangle is indeed also an isosceles triangle. However, it should be clear that it is a special kind of isosceles triangle. If we make a claim about isosceles triangles, and to motivate or prove a claim we consider an equilateral triangle, we may reach an incorrect conclusion: while it is true that an equilateral triangle is a special kind of isosceles triangle, it enjoys properties that isosceles triangles do not have, in general. Therefore, when trying to say something meaningful about isosceles triangles, we have to be careful not to consider particular cases. In other words, we have to consider an arbitrary isosceles triangle, and not a special kind. This is another peculiar aspect of the mathematical language; if we ask John to draw a triangle, and John draws an equilateral triangle, it is not fair to say that his triangle is not general enough, or that it is not an arbitrary triangle, because the issue is not in the drawing of the triangle itself. The problem arises only when John decides to use his triangle to establish a general result on all triangles: he is not allowed to exploit the fact that his triangle is equilateral. These considerations are not exhaustive of all the circumstances in which our everyday language is unsuitable for Page 4 of 175 1.1 Propositional logic MATH1017 the task we have in mind. However, they should convince the reader that it is essential to be very careful in the way we phrase every sentence/proposition/claim to avoid unpleasant surprises. It is essential to use a language that is at the same time poor but precise; in an introduction or a remark the use of our everyday language can be justified. But when it comes to formalizing definitions, theorems and, in general, mathematical results, it is essential to give priority to clarity and unambiguousness. 1.1 Propositional logic A proposition is a linguistic statement which is either true or false (but not both!). Example The statement “snow is white” is true. The statement “roses are animals” is false. Thus, these two statements are propositions. The statements “I loved that book” and “Phillip is greedy” are not propositions. Questions are also not propositions, because we cannot attribute a value of true or false to them. The statement “This statement is false” is not a proposition, because it is neither true nor false (if it is true, then it must be false, and if it is false, it must be true). The statements “1 + 1 = 2” and “1 + 1 = 3” are propositions: the first one is true, the second is false. The statement 0/0 = 1 is not a proposition, because 0/0 is a so-called ill-defined expression (an expression is simply a sequence of mathematical symbols). Indeed, the division by 0 is an undefined concept. If a sentence (used for example in a definition, in the statement of a theorem or in a proof) contains for example the expression x/y = z, it needs to specify that y is not equal to 0. Propositions can be modified to generate new propositions, via the so-called logical connectives. 1.1.1 Negation Given a proposition p, we can construct another proposition “not p”, written ¬ p, which is true when p is false and false when p is true. The table p ¬ p T F F T is called truth table: its first columns show all the possible values of the original propositions (just p in this case, which can take only the two values of “true” or “false”), and the last one represents the logical values of the result of the application of the connectives. The negation ¬ is called unary logical connective, because it applies to a single proposition. The next logical connectives are called binary, because they connect two or more propositions. Example The proposition “it is not true that 1 + 1 = 3” is true. In our everyday language, we can express “not p” as “p is not true”, or “p is false”, or “it is not true that p holds”, etc. Page 5 of 175 1.1 Propositional logic MATH1017 1.1.2 Conjunction Given two propositions p and q, the conjunction of p and of q is the proposition “p and q”, and is denoted by p ∧ q. We define p ∧ q to be true when p and q are true, and false in all the other cases. The truth table of the conjunction is p q p ∧ q T T T T F F F T F F F F Here, the first two columns contain all possible combinations of true/false values taken by the propositions p and q, and the last one is the truth value of the proposition “p and q”.1 Example If p is the proposition “snow is white” and q is the proposition “roses are animals”, then p and q is the proposition “snow is white and roses are animals”. Example The proposition “1 + 1 = 2 and 2 · 3 = 6” is true, whereas “1 + 1 = 2 and 2 · 3 = 5” is false. In our everyday language there are different ways to express the conjunction. For example, “both p and q are true”, or even “p but q”. What changes is the connotation that we give to this linguistic expressions. 1.1.3 Disjunction We now consider the term “or” between two sentences.2 Given two propositions p and q, the disjunction of p and of q is the proposition “p or q”, and is denoted by p ∨ q. The proposition p ∨ q is defined to be true when at least one of the two propositions p and q is true. The truth table of the disjunction is p q p ∨ q T T T T F T F T T F F F Example If p is the proposition “snow is white” and q is the proposition “roses are animals”, then p or q is the proposition “snow is white or roses are animals”. 1The number of rows in a truth table is 2n , where n is the number of propositions involved. 2Unfortunately, in our everyday language this word is used ambiguously. Sometimes it is used in an exclusive sense (where “p or q” means that exactly one between p and q is true, but not both), and sometimes in an inclusive sense (where “p or q” is true if at least one is true). In mathematical logic, ambiguity cannot be tolerated, and the disjunction “or” always refers to the second meaning. Page 6 of 175 1.1 Propositional logic MATH1017 1.1.4 Material implication The material implication (or simply implication) is the most delicate of the logical connectives. Given two propositions p and q, the proposition “p implies q” is the proposition “if p, then q”, and we will write p ⇒ q. The proposition p in this case is called antecedent and q is called consequent. The truth table of the material implication is p q p ⇒ q T T T T F F F T T F F T In our everyday speech, an implication, or “if... then...” sentence, implicitly involves a form of causality between the antecedent and the consequent: we view the antecedent as the “cause” and the consequent as the “effect”. For example, “if you do not know the alphabet, you cannot read” suggests that not knowing the alphabet is the reason why a person is unable to read. However, which proposition takes the role of the cause and which takes the role of the effect is often subjective. For example, “Mike ate an apple” implies “Mike ate a fruit”, but not everyone would agree that eating an apple is the cause of eating a fruit. In addition to not being able to give a precise general meaning to the notions of cause and effect, we cannot expect mathematical logic to reach a conclusion on the logical value of the proposition p ⇒ q exclusively on the basis of the truth value of p and q. We therefore have to abandon our intuitive idea of implication as something underpinned by causality, and define it – at least within the realm of mathematical logic – so as to satisfy useful requirements: (i) if it true that p ⇒ q and if we know that p is true, then q must be true as well. This property of the material implication is known as modus ponens (or modus ponendo ponens).3 In symbols: (p ⇒ q) ∧ p  ⇒ q. (1) In fact, we see that the only line of the truth table that corresponds to the case where p ⇒ q is true and p is true is the first, which has a value of true for q, as well. In (1), as is normal in logical mathematics and in mathematics in general, the parentheses are used to establish a precedence rule. (ii) If p ⇒ q is true and q is false, then p must be false. This property is known as modus tollens (or modus tollendo tollens)4 : (p ⇒ q) ∧ ¬ q  ⇒ ¬ p. In fact, we see that the only line of the truth table that corresponds to the case where p ⇒ q is true and q is false is the last one, which has a value of false for p. For example suppose that the statement “if it is raining, then I open my umbrella” is true. Then, if I do not open my umbrella, it is not raining. This property is also called contrapositive: p ⇒ q is the same as ¬q ⇒ ¬p. We will clarify with the definition of biconditional what we mean by “being the same”. 3Latin for “the way that affirms by affirming”. 4Latin for “the way that denies by denying” Page 7 of 1 1.1 Propositional logic MATH1017 (iii) If p ⇒ q is true, it is not necessarily true that q ⇒ p. For example, if p is the proposition “Mark was born in Sydney” and q is the proposition “Mark was born in Australia”, then clearly p ⇒ q is true, but q ⇒ p may not be true (not all Australians were born in Sydney). Thus, the lines of the truth table that correspond to p ⇒ q being true and q being true are the first and the third, and p has values “true” and “false” respectively, so knowing that p ⇒ q and that q are true does not allow us to conclude that p is true. Remark 1 It may seem counterintuitive that when p is false, regardless of the logical value of q, the implication is true. These are cases where the implication is “vacuous”, in the sense that it is not providing any valuable information. For example, formally the lecturer is not lying if he says that yesterday he gave a million dollars to every student who was born in Greenland (assuming that there are no students born in Greenland, but this is usually a safe assumption). In this case, the statement is vacuously true because the antecedent is false, but it is not saying anything meaningful: we could replace the consequent with any other statement, and we would still obtain a true implication.a a It is said that Bertrand Russell, in a lecture on logic, mentioned that a false proposition implies any proposition. A student raised his hand and said “Given that 2 + 2 = 5, prove that you are the Pope”. Russell allegedly answered something along these lines: “if 2 + 2 = 5, then 1 = 2 (subtract 3 from both sides). By modus ponens, then 1 = 2. The set containing just me and the Pope has 2 members. But 2 = 1, so it has only 1 member; therefore, I am the Pope”. We read the material implication p ⇒ q in one of the following ways: • “p implies q”; • “if p is true, then q is true”, or “if p, then q”; • “p is a sufficient condition for q”; • “q is a necessary condition for p”. Example We have: • The implication “3 = 3 ⇒ 3 2 = 9” is true, because the antecedent and the consequent are both true; • The proposition “3 = 2 ⇒ 3 2 = 4” is true: both the antecedent and the consequent are false; • The proposition “3 = −3 ⇒ (−3)2 = 9” is true: false implies true. Vacuously true implications are important in mathematics: we will see an example of this later on. 1.1.5 Biconditional Given two propositions p and q, the proposition “p if and only if q” (written p ⇔ q) is the proposition “p implies q and q implies p” (written (p ⇒ q) ∧ (q ⇒ p)). In other words, p ⇔ q means that whenever p is true, then q has to be true, and whenever q is true, p has to be also. The corresponding truth table is Page 8 of 175 1.1 Propositional logic MATH1017 p q p ⇒ q q ⇒ p p ⇔ q T T T T T T F F T F F T T F F F F T T T Notice that in this truth table we also have two intermediate columns (for p ⇒ q and q ⇒ p) which we can add for convenience to obtain the truth value of the last one. The proposition p ⇔ q is also called logical equivalence of p and q, and we read it in one of the following ways: • “p is true if and only if q is true”; • “p is equivalent to q”; • “p is necessary and sufficient condition for q”. Example Let p =“8 is even” and q =“there exists a natural number m such that 8 = 2 m”. Then, p and q are logically equivalent, i.e., p ⇔ q. The fact that 8 is even implies that we can write 8 as 2 m for some natural number m. Conversely, the fact that 8 = 2 m for some m implies that 8 is even. Notice that p =“7 is even” and q =“there exists a natural number m such that 7 = 2 m” are also logically equivalent, i.e., p ⇔ q, because they are both false. Example We have ¬(¬p) ⇔ p. Indeed, if p is true, then ¬ p is false, which means that ¬(¬ p) is true. If p is false, then ¬ p is true, and therefore ¬(¬ p) is false. We say that p is true if and only if ¬(¬ p) is true, and that p and ¬(¬ p) are logically equivalent. This fact can be formally seen using the truth table: p ¬ p ¬(¬ p) T F T F T F In fact, the first column and the last one are identical, and this amounts to saying that ¬(¬ p) is true whenever p is. From a logical point of view, the two propositions p and ¬(¬ p) are indistinguishable. Example We have (p ⇒ q) ⇔ (¬ p) ∨ q  . Indeed, p q ¬ p (¬ p) ∨ q T T F T T F F F F T T T F F T T Page 9 of 17 1.1 Propositional logic MATH1017 Notice that the last column is the same as the one defining the material implication. For this reason, some authors define p ⇒ q as (¬ p) ∨ q. Example The logical conjunction enjoys the so-called commutative property: if p and q are propositions, then p∧q is equivalent to q ∧ p. In symbols, (p ∧ q) ⇔ (q ∧ p), as one can check using the truth table: p q p ∧ q q ∧ p T T T T T F F F F T F F F F F F Example Show that the logical conjunction is associative, i.e., it enjoys the so-called associative property: if p, q and r are propositions, then (p ∧ q) ∧ r ⇔ p ∧ (q ∧ r), Example Show that disjunction enjoys the commutative property (p ∨ q) ⇔ (q ∨ p), as well as the associative property (p ∨ q) ∨ r ⇔ p ∨ (q ∨ r). Example Show the distributive property p ∧ (q ∨ r) ⇔ (p ∧ q) ∨ (p ∧ r) Remark 2 We follow the linguistic convention to interpret “if” as “if and only if” whenever a definition is involved. Consider for example the definition “n ∈ N is even if n = 2 m for some m ∈ N”. Since we defined an even number as a number that is divisible by 2, we all agree that a number which is not divisible by 2 is not even (and this follows from the intuitive idea we all share of a definition). Therefore, the statements “n is even” and “n = 2 m for some m” are logically equivalent. In other words, even if, linguistically, in a definition we use “if” in place of “if and only if” (sometimes abbreviated as “iff”), logically speaking we are dealing with a biconditional.a aWe could say that when in a definition we write p ⇒ q, we also mean that (¬p) ⇒ (¬q). However, by modus tollens the latter is equivalent to q ⇒ p, and therefore we obtain p ⇔ q. 1.1.6 De Morgan’s laws De Morgan’s laws5 show that negation converts the conjunction into the disjunction and vice-versa. More precisely, these laws state that (i) the negation of a conjunction is the disjunction of the negations; and (ii) the negation of a disjunction is the conjunction of the negations. 5Augustus De Morgan (27 June 1806 – 18 March 1871) was a British mathematician and logician. Page 10 of 175 1.2 Predicate logic MATH1017 Theorem 1 [De Morgan’s Laws] Let p and q be two propositions. Then: (i) ¬ (p ∨ q) ⇔ (¬ p) ∧ (¬ q); (ii) ¬ (p ∧ q) ⇔ (¬ p) ∨ (¬ q). Proof Consider the first proposition. From the truth tables p q p ∨ q ¬ (p ∨ q) T T T F T F T F F T T F F F F T p q ¬ p ¬ p (¬ p) ∧ (¬ q) T T F F F T F F T F F T T F F F F T T T we find that indeed ¬ (p ∨ q) and (¬ p) ∧ (¬ q) are equivalent. Consider the second proposition. The truth tables p q p ∧ q ¬ (p ∧ q) T T T F T F F T F T F T F F F T p q ¬ p ¬ p (¬ p) ∨ (¬ q) T T F F F T F F T T F T T F T F F T T T show that indeed ¬ (p ∧ q) and (¬ p) ∨ (¬ q) are equivalent. Example The negation of the proposition “Mark owns a car and Jane owns a scooter” is “Mark does not own a car or Jane does not own a scooter”, and not “Mark does not own a car and Jane does not own a scooter”: negating the proposition means that “Mark owns a car” and “Jane owns a scooter” are not both true, but it leaves the possibility open that just one of them could be true. Example The proposition “it is not true that 7 is even and positive” is true (since 7 is not even). This proposition is logically equivalent to “7 is not even or 7 is not positive”, which is in fact also true. The given proposition is not logically equivalent to “7 is not even and 7 is not positive”, which is false. Example The proposition p =“it is not true that π ≥ 1 or π ≤ −1” is false, because “π ≥ 1 or π ≤ −1” is true. Using De Morgan’s laws, p is equivalent to “π < 1 and π > −1”, which in fact is also false. It is incorrect to say that p is equivalent to “π < 1 or π > −1” (can you see why?), and in fact this proposition is true. 1.2 Predicate logic Suppose x is a variable: it is an object whose identity is undetermined. We say that p{x} is a “predicate” if it is a sentence containing the symbol x which becomes a proposition when we substitute the symbol x with a precise, but entirely arbitrary, value from a so-called domain of discourse D. Page 11 of 175 1.2 Predicate logic MATH1017 Example Consider the predicate p{x} defined by “x 2 , 2”. Specifying the domain of discourse D is essential: if we assume that D is the set of natural numbers, then every x will render p{x} a true proposition. If we consider, instead, D to be the set of real numbers, then p{ √ 2} is a false proposition and p{− √ 2} is also a false proposition, but all other values of x will render p{x} true. We can define in a similar way predicates that depend on more than one variable: for example, a predicate that depends on two variables is denoted by p{x, y}, and it becomes a proposition when we attribute specific values to x and y. Until we quantify both variables, we cannot attribute a truth value to p{x, y}. For example, if p{x, y} is the predicate “x < y”, then p{1, 2} is true, while p{2, 1} is false. Definition 1 [Quantifiers] Let p{x} be a predicate that depends on a variable x. We define two new propositions : (i) p{x} is true for all x. The proposition “p{x} is true for all x” is written ∀ x, p{x}  or (∀ x), p{x}. (ii) there exists at least an x for which p{x} is true. The proposition “there exists at least an x for which p{x} is true” is written ∃ x : p{x} or ∃ x : p{x}  or (∃ x) p{x}. The symbol ∀ is called universal quantifier. The symbol ∃ is called existential quantifier. Definition 2 Let p{x} and q{x} be predicates that depend on a variable x. Then, (i) ∀p{x} x, q{x}  is the proposition ∀x, p{x} ⇒ q{x}  ; (ii) ∃p{x} x : q{x}  is the proposition ∃ x : p{x} ∧ q{x}  . The proposition ∀p{x} x, q{x}  can also be written as “every x for which p{x} is true is such that q{x} is also true”. The proposition ∃p{x} x : q{x}  can also be written as “there exists (at least) an x that verifies p{x} for which also q{x} is true”. Example Consider the proposition “all men are mortal”. This proposition can be written by defining the two predicates • p{x} def = “x is a person” • q{x} def = “x is mortal” Now, the proposition “all people are mortal” is simply ∀p{x} x, q{x}  , i.e., for every x, if x is a person then x is mortal, and this is exactly ∀x, p{x} ⇒ q{x}  . Consider the proposition “there is (at least) a person who is taller than 2 meters”. This proposition can be written by defining the two predicates • p{x} def = “x is a person” • q{x} def = “x is taller than 2 meters” Now, the proposition “there is (at least) a person who is taller than 2 meters” is ∃p{x} x : q{x}  , i.e., there exists an x that verifies p{x} (so that x is a person) which also verifies q{x} (so that x is taller than 2 meters). Pag 1.2 Predicate logic MATH1017 Example Consider the predicate “(x + 1)2 = x 2 + 2 x + 1”. This predicate does not have a definite truth value. However, the statement ∀ x ∈ R, (x + 1)2 = x 2 + 2 x + 1 has a definite truth value (and in particular it is true), and it is therefore a proposition. Similarly, the predicate “x + 1 = 4” does not have a definite truth value, but the statement ∃ x ∈ R : x + 1 = 4 does: in particular it is true (take x = 3). On the contrary, the statement ∀ x ∈ R, x + 1 = 4 is false: there are many real numbers x such that x + 1 , 4. It should be clear that one cannot prove a “for all” statement by examples: in the latter case, x = 3 is an example of real number for which x + 1 = 4, but it is not true that the same identity holds for other real numbers, let alone all of them. It is, however, possible to prove “there exists” statements with examples. Example This example shows the role played by vacuous statements in proofs. Consider the predicate p{n} =“n ∈ N ⇒ n (n + 1) is even”. Then, we have the theorem ∀ n, p{n}, which reads as ∀ n, n ∈ N ⇒ n (n + 1) is even. To prove an implication, we assume that the antecedent is true, and use this to deduce the consequent (this is a valid procedure even if the antecedent turns out to be false: the material implication does not provide information on the truth value of the antecedent, but only ensure that the consequent is true if the antecedent is true). In this case, we assume that n is a natural number, and therefore it is even or odd. Taking for granted that the product of an even natural number with any natural number is even, we can argue as follows: if n is even, then n (n + 1) is even. If n is odd, then n + 1 is even, and therefore n (n + 1) is even. In both cases n (n + 1) is even, and we are done. Since n is either even or odd (but not both), one of the two implications “if n is even, then n (n + 1) is even” and “if n is odd, then n (n + 1) is even” (used in the previous argument and both need to be true to provide a correct proof) has a false antecedent, and it is therefore vacuous (but true nevertheless). Example A common error is to prove an implication by assuming the consequent instead of the antecedent. Suppose we need to prove the theorem “for all x, if 3 x − 1 = 8, then x = 3. We are tempted to plug the value x = 3 in the equation and, in doing that, we notice that the identity is satisfied. In other words, what we may be tempted to do is: x = 3 ⇒ 3 x = 9 ⇒ 3 x − 1 = 8. This is incorrect. The correct chain of implications to prove the theorem is 3 x − 1 = 8 ⇒ 3 x = 9 ⇒ x = 9 3 = 3. It would be correct, however, to write x = 3 ⇔ 3 x = 9 ⇔ 3 x − 1 = 8. Page 13 of 175 1.2 Predicate logic MATH1017 Example We want to prove the theorem ∀x > 0 x, sin x = 1 ⇒ x ≥ π 2 . We want to use a so-called proof by contradiction, which exploits the contrapositive (p ⇒ q) ⇔ (¬q ⇒ ¬p). Hence, suppose ¬q is true, i.e., x < π 2 . Since x > 0, then 0 < x < π/2. Since the sine function increases in the interval (0, π/2) and sin 0 = 0 and sin(π/2) = 1, it follows that 0 < sin x < 1. Hence, it is not true that sin x = 1, which is what we wanted. 1.2.1 De Morgan’s laws for quantifiers We now investigate the case where the quantifiers are used jointly with the negation. Consider the sentence “there does not exists an immortal man”. This sentence is not equivalent to the sentence “there exists a man who is not immortal”, but we are saying something stronger: we are saying that “every man is mortal”. Similarly, when we say “it is not true that every man is more than 1 meter tall” we do not mean that “every man is less than 1 meter tall”, but that “there exists at least one man who is less than 1 meter tall”. In other words, we can shift the negation internally in the sentence, but we have to change the quantifier. This rule is formalized in the following theorem. Theorem 2 [De Morgan’s Laws for Quantifiers] Let p{x} be a predicate that depends on a variable x. Then: (i) ¬ ∀ x, p{x}  ⇔ ∃ x : ¬ p{x}; (ii) ¬ ∃ x : p{x}  ⇔ ∀ x , ¬ p{x}. Let q{x} be another predicate that depends on a variable x. Then: (i) ¬ ∀p{x} x, q{x}  ⇔ ∃p{x} x : ¬ q{x}; (ii) ¬ ∃p{x} x : q{x}  ⇔ ∀p{x} x, ¬ q{x}. Proof We prove the first proposition. Suppose ¬ ∀ x, p{x}  . Then, for some value a the proposition p{a} is not true. Thus, ¬ p{a} is true, from which it follows that ∃ x : ¬ p{x}. Conversely, if ∃ x : ¬ p{x}, we can let a be a value of x such that ¬ p{a} is true, i.e., p{a} is false. Thus, it is not true that ∀ x, p{x}, i.e., ¬ ∀ x, p{x}  . Example The proposition “it is not true that there exists a corrupted politician” is equivalent to the sentence “every politician is not corrupted”. Example We said before that “for all” statements cannot be proved by examples, whereas “there exists” statements can. Since with De Morgan’s laws for quantifiers the ¬ turns ∀ into ∃ in ¬ ∀ x, p{x}  ⇔ ∃ x : ¬ p{x}, if we want to disprove “for all”, it is sufficient to find a counterexample: if we find just an x such that p{x} is false, Page 14 1.2 Predicate logic MATH1017 then it is not true that p{x} is true for all x. 1.2.2 Equality We now want to formalise the concept of equality. Definition 3 [Equality] Let a, b be two variables. Then, we say that a is equal to b (and we write a = b) if = satisfies the following two axioms: (i) ∀ x, x = x; (ii) Let p{α} be a predicate that depends on a variable α. Then, ∀ x, y, (x = y) ⇔ (p{x} ⇔ p{y}). The property (ii) in Definition 3 is also known as Leibniz’s rule. We said that (i) and (ii) are axioms. However, to be precise (ii) is an axiom schema: we have one axiom for any possible predicate. Theorem 3 [Symmetry and Transitivity of Equality] The following results hold: (i) ∀ x, y, (x = y) ⇒ (y = x); (ii) ∀ x, y,z, (x = y) ∧ (y = z)  ⇒ (x = z). Proof We prove the first. Let a and b be objects such that a = b. Let p{α} be a predicate that depends on α. From Leibniz’s law, p{a} ⇔ p{b}. Since the biconditional is commutative (see Tutorial), we have also p{b} ⇔ p{a}, which, from Leibniz’s law, gives b = a. We now prove the second proposition. Let a, b and c be objects such that a = b and b = c. Let p{α} be a predicate in the free variable α. From Leibniz’s law, since a = b, we have p{a} ⇔ p{b}. From Leibniz’s law, since b = c, we have p{b} ⇔ p{c}. Since the biconditional is transitive (see Tutorial), we have p{a} ⇔ p{c}. From Leibniz’s law, we obtain a = c. 1.2.3 Univocal and functional predicates We now introduce the notion of univocal predicate, which is a predicate that is true for only one value of the variable. If p{x} is a predicate that depends on the variable x and u is an arbitrary but specific value, we denote by p{u} the proposition obtained by substitution of the variable x with the specific value u. Definition 4 [Univocal Predicates] Let p{x} be a predicate that depends on a variable x. The predicate “there exists at most one x such that p{x}” Page 15 of 17 1.2 Predicate logic MATH1017 is defined as the predicate ∀ u, ∀ v, (p{u} ∧ p{v}) ⇒ (u = v). Indeed, if p{u} and p{v} are both true, then u and v coincide. Example The predicate “there exists at most one x such that x ∈ R and e x = 7” is univocal: indeed, there is only one real number x = ln 7 such that e x = 7. Definition 5 [Functional Predicates] Let p{x} be a predicate that depends on a variable x. We define the predicates “there exists one and only one x such that p{x}” and “p{x} is functional in x” as the predicate ∃ x : p{x} ∧ “there exists at most one x such that p{x}” The symbol ∃! x means “there exists one and only one x”. Thus, the predicate “there exists one and only one x such that p{x}” can be written as ∃! x : p{x}. If p{x} is functional in x, it defines an object, which is the only x that satisfies p{x}. Example The predicate “x ∈ R+ ∧ x 2 = 2” is functional in x: the only x for which the predicate “x ∈ R+ ∧ x 2 = 2” is true is √ 2. Let us now consider predicates that depend on more than one variable: for example, a predicate that depends on two variables is denoted by p{x, y}, and it becomes a proposition when we attribute specific values to x and y. We now want to examine how the quantifiers operate on these predicates. It is easy to see that ∃ x : ∃ y : p{x, y} is equivalent to ∃ y : ∃ x : p{x, y}. For this reason, we will often write them as ∃ x, y : p{x, y}. Likewise, ∀ x, ∀ y, p{x, y} is equivalent to ∀ y, ∀ x, p{x, y}, and these will be written as ∀ x, y, p{x, y}. Page 16 of 175 1.2 Predicate logic MATH1017 If in a proposition we have quantifies of both types, we have to be more careful. Indeed, ∃ x : ∀ y, p{x, y} is not equivalent to ∀ y, ∃ x : p{x, y}. In fact, the first proposition says that it is possible to first choose x so that, choosing y arbitrarily afterward, the proposition p{x, y} is true. The second says that every time we assign y, it is possible to choose x afterward, so that p{x, y} is true. In this second case, we allow the choice of x to depend on the value of y that has been chosen; in the first case, such dependence is forbidden. Consider for example the proposition “Everyone has a car”. The corresponding formalization in mathematical language is ∀ y, ∃ x : p{x, y}, where p{x, y} is “the person y owns a car x” (i.e., for every person y, there exists a car x such that the person y owns the car x”). In this case we are not authorized to swap the role of the quantifiers, because we would obtain ∃ x : ∀ y, p{x, y}, which means “there exists a car x such that for every person y, the person y own the car x”, i.e., there exists a car that is owned by every person. Example Consider two variables x, y ∈ R. The proposition ∃ x ∈ R : ∀ y ∈ R, y > x is false. In this proposition, the variable x is “frozen”, and the subsequent choice of y ∈ R is arbitrary. In particular, one is authorized to choose y = x, which immediately implies that it is not true that y > x. Consider now the proposition ∀ y ∈ R, ∃ x ∈ R : y > x. In this case, every time y has been assigned, we can choose for example x = y − 1; in this case the choice of x is allowed to depend on the choice of y. Page 17 of 175 MATH1017 2 Set theory, functions and numerical structures We now introduce fundamental notions that are constantly used in mathematics and science in general. We could say that sets are the “building blocks” of mathematics: we will only touch the surface, but we will try to provide insight into the main issues that arise in developing a rigorous approach to set theory. 2.1 Sets Intuitively, a set is a collection – or group – of objects. Obviously this is not a precise definition of set, because it hinges on other undefined concepts: collection, group, and object. However, it seems unavoidable that our first definition will involve concepts and ideas which have not previously defined: these are the so-called primitive notions. In this case, we rely on our intuition: we all have a mental image of what a collection of objects looks like. Besides, we are not that interested in the ontological question of what sets and objects are, but, rather, in how they can manipulated, which properties they satisfy, and so forth. It is worth mentioning that a set is an object, but there are objects that are not necessarily sets. For example, for us, the number 3 is not a set, but an object.6 Let A be a set. We introduce the notion of membership as follows: if an object a belongs to A, we write a ∈ A. We also say that a is an element of A. If a does not belong to A, we write a < A. The notions of set and membership are primitive, and they can be made precise by introducing a number of axioms: these are the starting points that allow us to prove the other properties of sets that we need. The standard axiomatic system for sets are the ZFC axioms (named after Ernst Zermelo and Abraham Fraenkel) and C comes from the axiom of choice.7 Now, if A and B are two sets, we say that A is a subset of B if every element of A is also an element of B; in symbols, ∀ x, (x ∈ A ⇒ x ∈ B). We use the notation A ⊆ B to say that A is a subset of B. According to this definition, every set is a subset of itself. In other words, for every set A, A ⊆ A. 6 It is worth saying that in pure set theory every object is a set. The differences that arise in this case are minimal, and therefore we prefer to keep the distinction between sets and objects here. 7The reason why this axiom is considered to be separate from the remaining ones is because it is somewhat different: even if today most mathematicians accept the axiom of choice, in the past it led to some controversies. It is possible to build mathematics where the axiom of choice is not accepted. Loosely speaking, the axiom of choice says that given an infinite collection of sets, where each set contains at least one element, it is possible to construct a new set by arbitrarily choosing one element from each set. Page 18 of 175 2.1 Sets MATH1017 Two sets coincide if and only if each one is a subset of the other:8 A = B ⇔ (A ⊆ B and B ⊆ A). Every proof of equality of two sets A and B consists of two parts: first, it is proved that A ⊆ B, and then that B ⊆ A. We write A ⊂ B if A ⊆ B and A , B. In this case, we say that A is a proper subset of B. It is easy to see that A ⊂ B if and only if A ⊆ B and ∃ b ∈ B : b < A. 9 Notice also that A ⊆ B ⇒ A ⊂ B or A = B. The set without elements is called empty set, and it is denoted by ∅, (or ∅, or {}) The empty set is a subset of every set. Indeed, given a set A, the proposition “∅ ⊆ A” is the same as ∀ x, x ∈ ∅ ⇒ x ∈ A. Since the antecedent is false (x cannot be contained in ∅), the implication is vacuously true.10 A set is determined by its elements. Therefore, it is possible to define a set by listing its elements. For example, if A is the set whose elements are natural numbers between 0 and 6, we write A = {0, 1, 2, 3, 4, 5, 6}. The order of the elements is irrelevant, so that we can write alternatively A = {5, 4, 1, 0, 2, 3, 6}. A set that has a single element is called a singleton. For example, A = {a} is a set which contains only the element a. Do not get confused between the element a and the set {a} containing that element. If A is a set and a ∈ A, then {a} ⊆ A. It is not always possible to list of all the elements of a set. We can therefore specify a property that the elements of a set need to satisfy. To this end, we use the so-called set-builder notation to write sets. A set in this notation is written as A =  x | p{x} , 8This is, actually, an axiom of set theory known as “axiom of extensionality”: it says that two sets are equal if they have the same elements. In symbols ∀ A, ∀ B, ∀ x, (x ∈ A ⇔ x ∈ B) ⇒ A = B  . Axioms are statements – usually perceived as evident – that are taken to be true, and serve as starting points for the development of a theory. Very loosely speaking, we want to impose only as few axioms as possible, to ensure that we do not impose too much and lead to a contradiction within the theory, but we need enough axioms to ensure that the theory is complete. In view of the axiom of extensionality, a set is completely and uniquely determined by its elements (which is another way of saying that two sets with the same elements coincide). 9Notice that the “if” in the sentence “We write A ⊂ B if A ⊆ B and A , B” has a different meaning from the “if and only if” of “A ⊂ B if and only if A ⊆ B and ∃ b ∈ B : b < A”. The first “if” is defining a new concept on the basis of previously defined ones. The “if and only if” says that the two propositions are logically equivalent. 10Another way of seeing the same thing is to notice that if ∅ ⊆ A was false, there would exist x ∈ ∅ such that x < A, but this contradicts the fact that ∅ has no elements. Page 19 of 17 2.1 Sets MATH1017 where p{x} is a predicate which is verified (i.e., it is true) for the elements of A, and only those. For example, the set of vehicles contained in Mike’s garage can be written as A =  x | p1{x} and p2{x} , where p1{x} is the predicate which is true if x is a vehicle, and p2{x} is the predicate which is true if x is in Mike’s garage. Alternatively, if we denote the set of vehicles as V, we can write A as A =  x ∈ V | p2{x} . Remark 3 It is natural to ask ourselves if every predicate p{x} gives rise to a set via the definition A =  x | p{x} . The answer is negative. Consider for example the predicate “x < x”. If x is the set of triangles, this predicate is true: the set of triangles is not a triangle, and therefore x does not contain itself as an element. If x is the set of elements that are not triangles, the predicate x < x is false, because x contains itself as an element (the set of elements that are not triangles is not itself a triangle). Now, we ask ourselves if A =  x | p{x} =  x | x < x (i.e., the set of sets that do not contain themselves as members) defines a set in this case. There are only two possibilities: either A ∈ A or A < A. If A ∈ A, then since A contains the elements x such that x < x, we have A < A, which leads to a contradiction. Suppose that A < A; since the elements x such that x < x belong to A, then A ∈ A, and this leads to another contradiction. To conclude, if A =  x | x < x , then A ∈ A ⇔ A < A. This is known as Russel’s paradox. The axioms of set theory must ensure that the operations introduced for sets do not lead to contradictions such as Russel’s paradox.a We cannot pursue this issue here, but it is important to be aware of the dangers behind definitions and possible contradictions. a In case you are curious, the two axioms that ensure that Russel’s paradox is avoided are: • the axiom of regularity, which says that every non-empty set A contains an element x such that A and x are disjoint sets: ∀ A, A , ∅ ⇒ ∃ x : x ∈ A ∧ x ∩ A = ∅  . • the axiom of pairing, which says that if A and B are sets, then there exists a set which contains A and B as elements: ∀ A, ∀ B, ∃C : (A ∈ C) ∧ (B ∈ C)  . With these two axioms, no set can be an element of itself. In fact, given an arbitrary set A, the axiom of pairing ensures that {A} is a set. From the axiom of regularity, there must be a member of {A} which is disjoint from {A}. Since the only element of {A} is A, we conclude that A is disjoint from {A} (i.e., A ∩ {A} = ∅), and therefore we cannot have A ∈ A. Another important axiom is the axiom of specification, which says that, given a predicate p{x} and a set A, then  x ∈ A | p{x} (containing exactly those elements x of A that satisfy p) is always a set. Formally, given any set A, there is a set B (which is a subset of A) such that, given any x, x is an element of B if and only if x is an element of A and p{x} is true: ∀ A, ∃ B : ∀ x, x ∈ B ⇔ (x ∈ A ∧ p{x})  . Rigorously speaking, this is not an axiom by an axiom schema, i.e., we have one such axiom for each predicate p. Notice that this axiom can only construct subsets: it does not allow the construction of an object like  x | p{x} , because this would not rule out Russel’s paradox. Page 20 of 2.1 Sets MATH1017 This axiom also shows that the universal set, i.e., the set containing all objects (including itself) does not exist. In fact, we know from the axiom of specification that given an arbitrary set A, we can construct the set B = {x ∈ A | x < x} of all the elements of A that do not contain themselves. Then B < A, because it it were it would be an element of itself. Therefore, every set A has a subset B that it does not contain, and therefore A cannot be universal. Remark 4 If we want to convince ourselves that the order of the elements in a set is irrelevant, consider e.g. a set with two objects A = {a, b}. We can write it as A = {x | x = a or x = b}, and this is clearly the same as {x | x = b or x = a} = {b, a}. The standard operations between sets are: (i) the union: given two sets A and B, the union A ∪ B is the set of elements which are in A or in B: A ∪ B = {x | x ∈ A or x ∈ B}. Here, x ∈ A or x ∈ B is a logical predicate which is true if x ∈ A or if x ∈ B (or both); (ii) the intersection: given two sets A and B, the intersection A ∩ B is the set of elements which are in A and in B simultaneously: A ∩ B = {x | x ∈ A and x ∈ B}. Two sets A and B are said to be disjoint if the intersection is the empty set, i.e., if A ∩ B = ∅; (iii) the set difference A \ B of A and B, i.e., the elements that are in A but not in B: A \ B = {x | x ∈ A and x < B}; If A ⊆ X, we define the complement of A in X as the set ∁X(A) = X \ A; If the set X is understood from the context, we write also A ∁ = ∁X(A) = X \ A; (iv) the Cartesian product. Before we introduce this notion, we define the concept of ordered pair, or simply pair. Given two elements a and b, we can build a new object called “ordered pair”, and denoted by (a, b), which depends on the elements a and b and on the order in which they appear, so that the ordered pair (a, b) is equal to the ordered pair (c, d) if and only if a = c and b = d. More precisely, we define (a, b) =  {a}, {a, b} . If a , b, then (a, b) , (b, a).11 We are ready to give the definition of Cartesian product: given two sets A and B, the Cartesian product A × B is the set of pairs in the form (a, b), where a ∈ A and b ∈ B: A × B = {(a, b) | a ∈ A and b ∈ B}. 11In the same way, we can introduce a triple (a, b, c) as the ordered pair (a, b), c  , and so forth. Page 21 of 17 2.1 Sets MATH1017 Example There holds {1, 2, 3} × {1, 2} = {(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2)}. 1 2 3 1 2 Example Consider the sets A = {x ∈ R | 2 < x < 3} and B = {x ∈ R | 1 < x < 2} of R (later on, sets of this kind will be referred to as intervals). Then, A × B is a rectangle in R 2 : A × B = {(x, y) ∈ R 2 | 2 < x < 3 and 1 < y < 2}. 1 2 3 1 2 A B A × B (v) Given a set X, the power set P(X) is defined as the set of all possible subsets of X. 12 Example If X = {1, 2}, then P(X) =  ∅, {1}, {2}, {1, 2} . If A = {a, b, c}, the power set is P(A) =  ∅, {a}, {b}, {c}, {a, b}, {a, c}, {b, c}, {a, b, c} . Notice that in both cases, denoting by n the number of elements (also called cardinality) of the original set, the power set contains 2n elements; indeed, in defining a subset, we have two independent choices for each element, whether it belongs to the set or not. For this reason, the power set of X is also denoted by 2X . Obviously this consideration only applies to finite sets. Remark 5 Consider a set Λ. We can generalize the concept of union as follows. We define [ λ ∈ Λ Aλ to be the set whose elements that belong to at least one of the Aλ: [ λ ∈ Λ Aλ def = {x | ∃ λ ∈ Λ : x ∈ Aλ}. This definition reduces to the union of two sets whenever Λ = {1, 2}. In a similar way, the set \ λ ∈ Λ Aλ is defined to be the set whose elements belong to each Aλ: \ λ ∈ Λ Aλ def = {x | ∀ λ ∈ Λ, x ∈ Aλ}. 12There is an axiom in set theory, called axiom of power set, which postulates that, for any set X, there is a set Y that contains every subset of X. Page 22 of 175 2.1 Sets MATH1017 This definition reduces to the intersection of two sets when Λ = {1, 2}. Note that A ∩ [ λ ∈ Λ Aλ = [ λ ∈ Λ (A ∩ Aλ). To show that this is true, we show that the left hand-side is contained in the right hand-side, and then that the right hand-side is contained in the left hand-side. Let x ∈ A ∩ [ λ ∈ Λ Aλ. Then, x ∈ A and x ∈ [ λ ∈ Λ Aλ, i.e., x belongs to some Aλ¯ with λ¯ ∈ Λ. It follows that x ∈ A ∩ Aλ¯. It follows that x ∈ [ λ ∈ Λ (A ∩ Aλ). Now, we have to prove the converse: let x ∈ [ λ ∈ Λ (A∩Aλ). Then, there exists λ¯ ∈ Λ such that x ∈ A∩Aλ¯. Then, x ∈ A and x ∈ Aλ¯, and from the second we have x ∈ [ λ ∈ Λ Aλ, so that x ∈ A ∩ [ λ ∈ Λ Aλ. As an exercise, show that A ∪ \ λ ∈ Λ Aλ = \ λ ∈ Λ (A ∪ Aλ). Theorem 4 Let Λ be a set. Let X be a set. Let A, B be subsets of X and let Aλ be a subset of X for every λ ∈ Λ. Then, (1) ∅ ∁ = X and X∁ = ∅; (2) A ⊇ B ⇒ A ∁ ⊆ B ∁ ; (3) A ∩ A ∁ = ∅ and A ∪ A ∁ = X; (4)  [ λ ∈ Λ Aλ ∁ = \ λ ∈ Λ A ∁ λ and  \ λ ∈ Λ Aλ ∁ = [ λ ∈ Λ A ∁ λ [De Morgan’s Laws] Partial proof We prove for example the second point of (4). The remaining are left as an exercise. We have x ∈  \ λ ∈ Λ Aλ ∁ ⇒ x < \ λ ∈ Λ Aλ ⇒ ∃ λ¯ ∈ Λ : x < Aλ¯ ⇒ ∃ λ¯ ∈ Λ : x ∈ A ∁ λ¯ ⇒ x ∈ [ λ ∈ Λ A ∁ λ . Conversely, x ∈ [ λ ∈ Λ A ∁ λ ⇒ ∃ λ¯ ∈ Λ : x ∈ A ∁ λ¯ ⇒ ∃ λ¯ ∈ Λ : x < Aλ¯ ⇒ x < \ λ ∈ Λ Aλ ⇒ x ∈  \ λ ∈ Λ Aλ ∁ . Before making other examples, we recall the fundamental sets of numbers: N (or N) set of natural numbers: {0, 1, 2, 3, . . . , }, Z (or Z) set of integer numbers: {0, ±1, ±2, ±3, . . . , }, Q (or Q) set of rational numbers, i.e., numbers in the form p/q where p, q are integers with q , 0, R (or R) set of real numbers, which also includes square roots and transcendental numbers like π or e, etc. Page 23 of 175 2.1 Sets MATH1017 C (or C) set of complex numbers, which will be discussed later. Note that some texts exclude 0 from N. This is just a convention. For us, N includes 0. We now present a few more examples of the set-builder notation: Example The set of natural numbers smaller or equal to 6 can be written as {n | n ∈ N and n ≤ 6} or as {n ∈ N | n ≤ 6}. Example The set of even natural numbers can be written as {n | ∃ m ∈ N : n = 2 m} or as {2 n | n ∈ N}. The notation {n | ∃ m ∈ N : n = 2 m} indicates that this set contains objects n such that there exists a natural number m that allows us to write n as n = 2 m, or, stated differently, objects that can be written as n = 2 m for some natural number m. Example The set of odd natural numbers can be written as {n | ∃ m ∈ N : n = 2 m + 1} or as {2 n + 1 | n ∈ N} or as {n ∈ N | ∀ m ∈ N, n , 2 m}. We will also use the following notation: (i) the set of non-zero natural numbers (i.e., the set {1, 2, 3, 4, . . .}: N ∗ = N \ {0} = {n ∈ N | n , 0}; (ii) the set of non-zero real numbers: R ∗ = R \ {0} = {x ∈ R | x , 0}; (iii) the set of non-negative real numbers: R+ = {x ∈ R | x ≥ 0}; (iv) the set of non-positive real numbers: R− = {x ∈ R | x ≤ 0}. We can also define R ∗ + = R ∗ ∩ R+ = {x ∈ R | x > 0}, and R ∗ − = R ∗ ∩ R− = {x ∈ R | x < 0}. Example Other examples of sets are the intervals of the real line. A set A ⊆ R is an interval if, for any choice of a, b ∈ A (with a ≤ b), every real number between a and b is an element of A. The sets that follow are all examples of intervals. Given a, b ∈ R, with a ≤ b, we define the intervals [a, b] = {x ∈ R | a ≤ x ≤ b} (2) [a, b) = {x ∈ R | a ≤ x < b} (3) (a, b] = {x ∈ R | a < x ≤ b} (4) (a, b) = {x ∈ R | a < x < b}. (5) Page 24 of 175 2.2 Functions MATH1017 The points a, b are called end-points of the interval. Notice that with this definition [a, a] = {a}, and [a, a) = (a, a] = (a, a) = ∅ (why?). Given a ∈ R, we also define the intervals [a, +∞) = {x ∈ R | a ≤ x} (6) (a, +∞) = {x ∈ R | a < x} (7) (−∞, a] = {x ∈ R | x ≤ a} (8) (−∞, a) = {x ∈ R | x < a}. (9) The set R ∗ = R \ {0} is not an interval. In fact, 1 ∈ R ∗ and −1 ∈ R ∗ , but 0 (which is a real number between −1 and 1) is not in R ∗ . 2.2 Functions Let A and B two sets. Let Γ ⊆ A × B. The triple (A, B, Γ) is called “correspondence”. The set A is called domain and the set B is called codomain of the correspondence (A, B, Γ). The set Γ is called graph of the correspondence (A, B, Γ). Intuitively, a correspondence (A, B, Γ) is a relationship between elements of A and elements of B. The fact that a ∈ A is related to b ∈ B is expressed by the property (a, b) ∈ Γ. If (a, b) ∈ Γ, we say that b corresponds to a. Example Consider the sets A = {1, 2, 3} and B = {α, β}, and let Γ = {(1, α), (1, β), (2, α)}. Then, A × B = {(1, α), (2, α), (3, α), (1, β), (2, β), (3, β)}. Since Γ ⊂ A × B, the triple (A, B, Γ) is a correspondence. The element 1 ∈ A has two correspondents: α and β, while 2 ∈ A has only one correspondent α, whereas 3 has no correspondents. If (A, B, Γ) is a correspondence, we can define Γ −1 = {(b, a) | (a, b) ∈ Γ}. The correspondence (B, A, Γ −1 ) is said to be the inverse of the correspondence (A, B, Γ). Example Considering the sets of the previous example, we have Γ −1 = {(α, 1), (β, 1), (α, 2)}. Let A and B be two sets. We say that f is a function from A to B if it is a correspondence with domain A and codomain B which maps every element of A into one and only one element of B. More formally, a function is a correspondence (A, B, Γ) such that (i) ∀ x ∈ A, ∃ y ∈ B : (x, y) ∈ Γ (i.e., every element x ∈ A has at least a correspondent y ∈ B. In other words, a function is defined at every point in its domain); (ii) ∀ x ∈ A, ∀ y1, y2 ∈ B, (x, y1) ∈ Γ ∧ (x, y2) ∈ Γ  ⇒ y1 = y2 (i.e., every element of A has at most one correspondent). Page 25 of 17 2.2 Functions MATH1017 Example The correspondence (A, B, Γ) of the previous example is not a function, because it violates both (i) and (ii). In fact, 3 ∈ A has no correspondent in B (and so (i) is not satisfied), and there are two distinct correspondents to 1 (which are α and β). Example Consider the sets A = {1, 2, 3} and B = {α, β, γ}, and let Γ = {(1, α), (2, α), (3, β)}. This is a function, because every element of A has one and only one correspondent in B. Hence, given two sets A and B, a function f with domain A and codomain B is an assignment of an element of B to each element of A and we write f : A −→ B. Given an element a of A, we denote by f(a) the element of B that f associates with a. In other words, informally, we can regard a as the “input” and f(a) as the “output”. We also say that f maps a into f(a). The action of a function can be visualised as a block that transforms the “input” a into the “output” f(a). f a f(a) Example Let A be the set of humans born before the year 2000. Consider the function f : A −→ A, that assigns to every human born before 2000 their mother; the codomain of f is also A, because clearly if a human was both before the year 2000, so is their mother. Given a ∈ A, in this case f(a) is the mother of a. We use the following notation to specify the way a function operates. Consider for example a function that maps a natural number to its negative: hence, for example, f(3) = −3. We can write this function as f(x) = −x, x ∈ N, or as f : N −→ Z x 7→ −x. The second is the most complete way to specify a function (because the first does not specify the codomain), and it is the one we will be using most often. Example Given a real number x, we denote by ⌊x⌋ the “floor” of x: it is the maximum integer smaller or equal to x. For example, ⌊7.5⌋ = 7, ⌊π⌋ = 3, ⌊−7.5⌋ = −8, ⌊−8⌋ = −8. In this way, we can define a function f : R −→ Z x 7→ ⌊x⌋. Page 26 of 175 2.2 Functions MATH1017 Floor function The domain is determined by the function. For example, the two functions f : R −→ R x 7→ sin x or g : [0, 2 π) −→ R x 7→ sin x must be regarded as different (the second function is said to be a “restriction” of the first to the interval [0, 2 π), and we write also g = f |[0,2 π)). On the contrary, there is more flexibility in the codomain. For example, the sine function can be defined alternatively as f : R −→ R x 7→ sin x or as f : R −→ [−1, 1] x 7→ sin x. (10) In fact, the output of the (real) sine function can only take values in the closed interval [−1, 1].13 Two distinct elements a1 and a2 of A are not necessarily mapped into two distinct elements of B. In other words, it may happen that f(a1) is equal to f(a2) even if a1 and a2 are different. For example, in the case of the sine function, we know that sin 0 = sin π = 0: the two distinct elements 0 and π of the domain R are mapped into the same element 0 of the codomain. Functions that map distinct elements of the domain into distinct elements of the codomain are called injective or one-to-one. Hence, f is injective if, for any a1, a2 ∈ A, if f(a1) = f(a2), then necessarily we must have a1 = a2. In symbols ∀ a1, a2 ∈ A,  f(a1) = f(a2) ⇒ a1 = a2  . (11) 13What would be entirely incorrect is to define f : R −→ [0, 1] x 7→ sin x. In fact, in this case the codomain does not contain all possible outputs that can be obtained applying f to elements of R. For example, f(3π/2) = sin(3π/2) = −1 is not an element of the codomain in this case. Page 27 of 175 2.2 Functions MATH1017 Equivalently, by modus tollens, f is injective if and only if ∀ a1, a2 ∈ A,  a1 , a2 ⇒ f(a1) , f(a2)  . (12) The statement (12) is the contrapositive of (11). Hence, (12) says that, for all elements a1 and a2 in the set A, if a1 , a2, then we must have f(a1) , f(a2).14 The sine function is not injective: as aforementioned, sin 0 = sin π = 0, even if 0 and π are two distinct elements of R. However, the restriction of the sine function to the interval h − π 2 , π 2 i is injective. The image or range of a function is, loosely speaking, the set of all its attainable outputs, and we denote it by f(A). Using the set-builder notation, we can write f(A) = {b ∈ B | ∃ a ∈ A : f(a) = b} or f(A) = {f(a) ∈ B | a ∈ A}. The notation f(A) = {b ∈ B | ∃ a ∈ A : f(a) = b} is saying that the elements of f(A) are those elements of B that are obtained by applying f to some element a of A. Hence, f(A) is the set of those elements of B that are in the form b = f(a) for some a ∈ A. We say that f is surjective or onto if f(A) = B. This means, in particular, that every element of the codomain can be obtained by applying f to some element of the domain. Clearly, every function becomes surjective if we take the codomain to be the image of the function. For example, the first function in (10) is not surjective, but the second is. A surjective function is a function that “covers” or “spans” all its codomain: every element of the codomain is the output that corresponds to a certain input. Finally, we say that f is bijective (or a one-to-one correspondence) if it is injective and surjective. 14This is an excellent example that explains why it is convenient to assume that vacuous propositions are true in degenerate cases. Suppose that A = {2} and B = {3}, and let the function f : A −→ B be the function f(2) = 3. We expect this function to satisfy the definition of injective function. And, in fact, using for example (12), we realize that the antecedent is always false: taking two elements from the set A which is a singleton necessarily means that these two elements are equal, and therefore the consequent is vacuously true. Page 28 of 175 2.2 Functions MATH1017 Example Consider the function x y 1 f : R \ {1} −→ R x 7→ 1 x − 1 . Notice that the domain of this function is R \ {1} (all the real numbers except for the real number 1) because f(x) = 1 x−1 : we cannot divide by 0, and therefore 0 must be excluded from the domain. We want to check whether f is injective. One idea is to use the definition: let x1, x2 ∈ R \ {1}. We have to show that f(x1) = f(x2) implies x1 = x2. Indeed, f(x1) = f(x2) ⇒ 1 x1 − 1 = 1 x2 − 1 ⇒ x1 − 1 = x2 − 1 ⇒ x1 = x2. Alternatively, we can decide to establish if f is injective geometrically, by drawing straight lines parallel to the x-axis (which corresponds to a certain output y in the codomain), and check that their intersection with the graph is either empty, or it is only a single point: in this case, the line y = 0 (which corresponds to the x-axis) does not have any intersection with the graph, and for y = y0 , 0 we have a single intersection: x f(x) 1 y = 4 y = 2 y = 0 y = −1 y = −3 Therefore, this function is injective. This is equivalent to solving the equation 1 x−1 = y in x, and obtaining at most one solution (why?). In this case: 1 x − 1 = y ⇔ 1 = x y − y ⇔ x y = 1 + y. Page 29 of 175 2.2 Functions MATH1017 If y = 0 we have no solutions (because with this value x y = 1+y becomes 0 = 1), and if y , 0 we obtain one solution x = 1 + y y . We now want to see if f is surjective: geometrically, we can use the lines parallel to the x-axis again, i.e., the lines of equation y = y0, where y0 is in the codomain R, and check that each of this lines has at least one intersection with the graph (and in this case we do not care if there are more than one intersection). We have already seen that for y0 = 0 there is no intersection, and therefore f is not surjective. We can also get to the same result analytically: to this end, we start finding the image of f . The image of f is given by the values of y ∈ R such that the equation 1 x−1 = y admits at least one solution x (with x , 1). This equation is equivalent to y (x − 1) = 1, i.e., x y = 1 + y. This equation cannot be solved in x unless y , 0. In other words, this equation admits solutions in R if and only if y , 0. The image of f is therefore R \ {0}, and this means that applying f to all possible elements of the domain R \ {1}, we can obtain all real numbers except for 0. Therefore, this function is not surjective, because R \ {0} , R. By contrast, the function g : R \ {1} −→ R \ {0} x 7→ 1 x − 1 obtained by replacing the codomain R with the image R \ {0} is injective and surjective, and it is therefore bijective. How would you generalise this argument based on straight lines parallel to the x-axis for functions of more two variables? This is a point that will be discussed in the sequel. We can also define the so-called inverse image (or counter-image): if U is a subset of B, the inverse image of U is the set f −1 (U) = {a ∈ A | f(a) ∈ U}. In other words, the inverse image is the set of all elements of A which f maps into elements of U. Even if in this notation we are using the symbol f −1 in f −1 (U), the inverse image exists even if f is not invertible (but we will rigorously introduce the inverse function later on: for the moment we rely on our intuition, by describing the inverse of f , if it exists, as a function f −1 which “undoes” what f does. To do the opposite of what f does, the domain and codomain of the inverse function f −1 need to be, respectively, the codomain and domain of f). Notice that the image of a function is a subset of the codomain B, whereas the inverse image of a subset U of the codomain is a subset of the domain A. Example To get some insight, this example deals with functions between finite sets. Consider a function f : A −→ B, where A = {1, 2, 3, 4, 5} and B = {α, β, γ}, described by: f(1) = α, f(2) = β, f(3) = γ, f(4) = α and f(5) = α, as shown in the Figure: Page 30 of 175 2.2 Functions MATH1017 A B 5 4 3 2 1 γ β α This function is not injective: f maps the distinct elements 1, 4 and 5 into the same element α of the codomain. However, it is surjective. Indeed, every element of the codomain results from the application of f to an element of the domain. Stated differently, the image of f is {α, β, γ}, which is equal to the codomain. We cannot find a function f −1 : B −→ A which “undoes” what f does: indeed, if such function f −1 existed, we would not know what value to assign to f −1 (α), since f(1) = α, f(4) = α and f(5) = α. In other words, f −1 would need to map α into, simultaneously, 1, 4 and 5. However, by definition a function maps each element of the domain into one and only one element of the codomain, and therefore an inverse of f does not exist. Nevertheless, we can define the inverse image of {a} through f : f −1 ({a}) = {1, 4, 5}. Now consider the function f : A −→ B, where A = {1, 2, 3} and B = {α, β, γ, δ} defined by f(1) = α, f(2) = β, f(3) = γ, as shown in the Figure: A B 3 2 1 δ γ β α The function in this case is injective: each element of the codomain comes from at most one element of the domain: α comes from 1, β comes from 2 and γ comes from 3. However, the image of f is {α, β, γ}, whereas the codomain is B = {α, β, γ, δ}. Again, we cannot find a function f −1 : B −→ A which “undoes” what f does: indeed, if such function f −1 existed, then f −1 (δ) would be undefined, and this means that B would not be the right domain for f −1 . a The problem would be solved by replacing B with the image f(A): A f(A) 3 2 1 γ β α Page 31 of 175 2.2 Functions MATH1017 In this case, the function f −1 : f(A) −→ A operates as follows: f −1 (α) = 1, f −1 (β) = 2, f −1 (γ) = 3. Finally, the function f : A −→ B, where A = {1, 2, 3} and B = {α, β, γ} and shown in the Figure A B 3 2 1 γ β α is injective (each element of the codomain comes from at most one arrow) and surjective (all the elements of the codomain come from some element of the domain). This function is invertible: f −1 : B −→ A maps α 7→ 2, β 7→ 1 and γ 7→ 3. aNevertheless, the inverse image of a subset of B can always be defined. For example, f −1 ({β}) = 2 and f −1 ({δ}) = ∅. Let X, Y be sets, and let f : X −→ Y. The following facts are easy to prove: • Let Λ be a set, and let Aλ ⊆ X for all λ ∈ Λ. Then, f  [ λ ∈ Λ Aλ  = [ λ ∈ Λ f(Aλ). • Let M be a set, and let Bµ ⊆ Y for all µ ∈ M. Let also B ⊆ Y. Then, f −1  [ µ ∈ M Bµ  = [ µ ∈ M f −1 (Bµ) and f −1  \ µ ∈ M Bµ  = \ µ ∈ M f −1 (Bµ) and f −1 (B ∁ ) = f −1 (B) ∁ . However, f  \ λ ∈ Λ Aλ  ⊆ \ λ ∈ Λ f(Aλ), and we do not have equality in general.15 Moreover, it is not true in general that f(A ∁ ) = f(A) ∁ . 16 Definition 6 Let A and B be two sets. We define B A def = {f : A −→ B}. In other words, B A contains all the functions from A to B. 15If f : R −→ R is the function f(x) = x 2 , and we take A1 = {1} and A2 = {−1}, then f(A1 ∩ A2) = f(∅) = ∅, but f(A1) ∩ f(A2) = {1} ∩ {1} = {1}. 16If f : R −→ R is the function f(x) = x 2 , if A = {0}, then A ∁ = R \ {0}, and so f(A ∁ ) = {y ∈ R | y > 0}, whereas f(A) ∁ = ({0}) ∁ = {y ∈ R | y , 0}. Page 32 of 2.2 Functions MATH1017 Example Let A = {1, 2, 3} and B = {a, b}. Then, B A contains the functions f1, . . . , f8 : A −→ B defined by    f1(1) = a f1(2) = a f1(3) = a    f2(1) = a f2(2) = a f2(3) = b    f3(1) = a f3(2) = b f3(3) = a    f4(1) = a f4(2) = b f4(3) = b    f5(1) = b f5(2) = a f5(3) = a    f6(1) = b f6(2) = a f6(3) = b    f7(1) = b f7(2) = b f7(3) = a    f8(1) = b f8(2) = b f8(3) = b The set A B contains the functions g1, . . . , g9 : B −→ A defined by ( g1(a) = 1 g1(b) = 1 ( g2(a) = 1 g2(b) = 2 ( g3(a) = 1 g3(b) = 3 ( g4(a) = 2 g4(b) = 1 ( g5(a) = 2 g5(b) = 2 ( g6(a) = 2 g6(b) = 3 ( g7(a) = 3 g7(b) = 1 ( g8(a) = 3 g8(b) = 2 ( g9(a) = 3 g9(b) = 3 Notice that in both cases, if the domain dom f has m elements and the codomain cod f has n elements, the set (cod f) (dom f) has n m elements. This explains the reason why we use the notation B A . 2.2.1 Composition of functions Let A, B and C be sets, and consider two functions f : A −→ B and g : B −→ C. We define the composition of f and g as the function g ◦ f : A −→ C such that ∀ a ∈ A, (g ◦ f)(a) = g f(a)  . We can represent the action of g ◦ f on the elements of A in terms of the block diagram f a f(a) g g f(a)  Notice that even if in the notation g ◦ f the symbol g comes first, in the way g ◦ f operates, f is applied first, to get f(a), and then g is applied to f(a) to get g f(a)  . When the codomain of f coincides with the domain of g, the composition g ◦ f is always defined: A B C D a f(a) g f(a)  g ◦ f f g Page 33 of 2.2 Functions MATH1017 However, the composition is defined also in situations where the domain of g contains the image of f . In other words: consider four sets A, B, C and D, along with the two functions f : A −→ B and g : C −→ D. To ensure that g f(a)  is well defined for all a ∈ A, we must have f(A) ⊆ C (and therefore also f(A) ⊆ B∩C, why?). Given two functions f and g, the fact that g ◦ f is defined does not imply that f ◦ g is defined. Even if g ◦ f and f ◦ g are both defined, they may not be equal. Indeed, the domain of g ◦ f is the domain of f , whereas the domain of f ◦ g is the domain of g. Example Let A be the set of people in a city. Let f : A −→ N denote the function that maps a person to their age, and let g : N −→ N be the function that adds up the digits in a natural number; for example, g(156) = 1 + 5 + 6 = 12. If a ∈ A is 31 years old, then (g ◦ f)(x) = g f(x)  = g(31) = 4. However, f ◦ g is not defined: f would be applied to numbers, but f can only be applied to people. However, even in the special case where both g ◦ f and f ◦ g are defined and with the same domain, they could be different, as the following example shows. Example Let f : R −→ R x 7→ x 2 + 1 and g : R −→ R y 7→ 3 y + 2. We denoted the variable of f by x and the variable of g by y, only to avoid confusion: how we decide to name a variable is irrelevant. Then, g ◦ f : R −→ R and for every x ∈ R (g ◦ f)(x) = g f(x)  = g(x 2 + 1) = 3 (x 2 + 1) + 2 = 3 x 2 + 5. Here, f ◦ g is defined and for every y ∈ R (f ◦ g)(y) = g f(y)  = f(3 y + 2) = (3 y + 2)2 + 1 = 9 y 2 + 12 y + 5. Hence, for example, (g ◦ f)(1) = 8 whereas (f ◦ g)(1) = 26. Example Consider again the case of functions between finite sets: f : A −→ B and g : B −→ C, where A = {1, 2, 3}, B = {α, β, γ} and C = {a, b, c}, shown below: A B 3 2 1 γ β α f g c b a C Notice that f(A) = {α, β}, which is contained in B. We have f(1) = β, f(2) = α, f(3) = β, and g(α) = a; g(β) = b, g(γ) = c. Page 34 of 2.2 Functions MATH1017 The composition g ◦ f : A −→ C works as follows: (g ◦ f)(1) = g f(1) = g(β) = b, (g ◦ f)(2) = g f(2) = g(α) = a, (g ◦ f)(3) = g f(3) = g(β) = b. 2.2.2 Inverse function Given two sets A and B and a bijective function f : A −→ B, the inverse of f is the function f −1 : B −→ A such that (i) ∀ a ∈ A, f −1 f(a)  = a (ii) ∀ b ∈ B, f f −1 (b)  = b. In other words, f −1 “undoes” what f does, whether we think about the action of f −1 to take place to the left or to the right of f . f a f(a) f −1 a f b −1 f −1 (b) f b Notice that the inverse f −1 exists if and only if f is bijective: we need injectivity for (i) to hold, and surjectivity for (ii) to hold. Intuitively, if a function is not injective, there are two distinct elements a1 and a2 of its domain which are mapped into the same element f(a1) = f(a2) of the codomain: how can the function f −1 “know”, from the knowledge of f(a1) = f(a2), if f was applied to a1 or to a2? Notice also that (ii) says that b ∈ f(A), and since b is any element of B, it follows that f(A) = B, i.e., f must be surjective. Remark 6 We can express the invertibility of a function in a more precise way by first defining the so-called identity functions IA : A −→ A x 7→ x and IB : B −→ B y 7→ y. Then, f : A −→ B is invertible if, by definition, there exists a function f −1 : B −→ A such that f ◦ f −1 = IA and f −1 ◦ f = IB. In fact, the first says that f f −1 (y)  = y for all y ∈ B, which is (ii), and the second says that f −1 f(x)  = x for all x ∈ A, which is exactly (i). Example Let A = {x ∈ R | 0 ≤ x < 1} and B = {y ∈ R | y ≤ 0}. Consider the function Page 35 2.2 Functions MATH1017 x y 1 f : A −→ B x 7→ x x − 1 . We begin by observing that f is well defined over A, because the denominator is never zero if x ∈ A. Moreover, f is well defined in terms of codomain as well, because if x ∈ A, then x ≥ 0 and x − 1 < 0, so that f(x) = x x−1 ≤ 0. To see if f is bijective, we study the equation f(x) = y, as y varies in B. In fact, f will be surjective if and only if f(x) = y has at least one solution for every y ∈ B, and it will be injective if and only if such solution is unique. Let y ∈ B, i.e., y ≤ 0. Consider the equation x x − 1 = y ⇔ x = x y − y ⇔ (1 − y) x = −y ⇔ (y − 1) x = y. Its only solution in R is x = y y−1 . Since y ≤ 0, then both the denominator and numerator of y y−1 are negative, so that x = y y−1 ≥ 0. Moreover, since y ≤ 0, then y > y − 1, so that x = y y−1 < 1. Hence, 0 ≤ x < 1, which means that x ∈ A. Therefore f is bijective, and f −1 : B −→ A y 7→ y y − 1 . x 1 1 f −1 : B −→ A y 7→ y y − 1 f(x) f −1 (x) y = x Notice that f(x) and f −1 (x) are symmetric with respect to the straight line y = x. This is a general rule: the graphs of a function and its inverse are symmetric to each other with respect to the line y = x. Can you find out why? This point will be discussed in the sequel. Page 36 of 175 2.3 Sequences MATH1017 2.3 Sequences A sequence is a particular kind of function where the domain is N, or a subset of N. Examples of sequences are a : N −→ R n 7→ n n + 1 and b : N ∗ −→ R k 7→ 1 k . (13) Traditionally, when dealing with sequences like these, instead of writing a(n) for the value of the sequence at n ∈ N, we write an. Sequences like those in (13) are denoted using the symbols (an)n ∈ N and (bk)k ∈ N∗ . With this notation, the codomain is omitted. 2.4 Real numbers We will not construct the set of real numbers. We will simply assume that a certain set R is assigned, for which certain operations and an order relation are defined with some properties attached to them. These properties are introduced through three groups of axioms: • field axioms • order axioms • supremum axiom The description of R will be completed only after the introduction of all the axioms. First, we want to define the concept of operation over a set A. An operation in A is a function A × A −→ A. For example, an operation τ : A × A −→ A maps an element (a1, a2) of A × A into an element τ(a1, a2) of A. We denote the element τ(a1, a2) as a1 τ a2. Example Let A = N. The operation “+” denotes the usual operation of addition of natural numbers. It is the function + : N × N −→ N (n, m) 7→ n + m. Notice how we write n+m instead of +(n, m). The name of this operation is “addition”, and the result of this operation is the “sum” of n and m. We now start with the description of R. As we mentioned before, the set R is assumed to be assigned, together with two operations + (called addition) and · (called multiplication) which satisfy the following properties (field axioms): (FA1) commutative property: ∀ a, b ∈ R, a + b = b + a and a · b = b · a; Page 37 of 175 2.4 Real numbers MATH1017 (FA2) associative property: ∀ a, b, c ∈ R, (a + b) + c = a + (b + c) and (a · b) · c = a · (b · c); (FA3) distributivity property of the multiplication over the addition: ∀ a, b, c ∈ R, (a + b) · c = (a · c) + (b · c); (FA4) there exists an element in R, called “zero” and denoted with the symbol 0, such that ∀ a ∈ R, a + 0 = 0 + a = a; (FA5) there exists an element in R, called “one” and denoted with the symbol 1 which is different from 0 and is such that ∀ a ∈ R, a · 1 = 1 · a = a; (FA6) for every element a of R there exists an element −a of R such that a + (−a) = (−a) + a = 0; (FA7) for every element a of R different from zero (so in fact a ∈ R ∗ ) there exists an element a −1 of R such that a · a −1 = a −1 · a = 1. Remark 7 We have introduced only two operations over R: the addition and the multiplication. How about the subtraction and the division? These two additional operations that come “for free”, from the definition of −a and that of a −1 when a , 0: − : R × R −→ R (a, b) 7→ a + (−b) and ÷ : R × R ∗ −→ R (a, b) 7→ a · b −1 . The results of these operations are called difference and quotient, respectively. Remark 8 If there are no parentheses, we assume that the multiplication has precedence over the addition, and we will almost always write a b instead of a · b. For example, a b + a c is equivalent to (a · b) + (a · c). If we have a sequence of operations, we assume that the operations are to be carried out in the order in which they appear. For example, a + b + c is the same as (a + b) + c, and a b c is the same as (a b) c. On the other hand, from the associativity (FA2), we have (a + b) + c = a + (b + c) and (a b) c = a (b c). However, some care needs to be taken, because for example a − b + c is (a − b) + c, which is different from a − (b + c). Finally, a b−1 is the same as a (b −1 ), and a+b −1 is the same as a+(b −1 ). In other words, the division by numbers different from 0 takes precedence over the addition. Page 38 of 175 2.4 Real numbers MATH1017 The following theorem presents some consequences of the properties in axioms (FA1)-(FA7), which we will use in calculations. Theorem 5 The following statements hold: (I) left distributivity property of the multiplication over the addition: ∀ a, b, c ∈ R, c (a + b) = c a + c b; (II) cancellation rule for the sum: ∀ a, b, c ∈ R, a + c = b + c ⇒ a = b; (III) cancellation rule for the product: ∀ a, b, c ∈ R, (a c = b c and c , 0) ⇒ a = b; (IV) the elements 0 and 1 satisfying (FA4)-(FA5) are unique; (V) ∀ a ∈ R, a · 0 = 0; (VI) Consider the “first degree (algebraic) equation” a x = b, where x is unknown (and belonging to R) and a, b ∈ R are assigned. Then, if a , 0, this equation has one and only one solution x = a −1 b; (VII) ∀ a ∈ R, −(−a) = a; (VIII) ∀ a ∈ R ∗ , we have a−1 , 0 and (a −1 ) −1 = a; (IX) ∀ a, b ∈ R, we have (−a) + (−b) = −(a + b) and −(a b) = (−a) b; (X) ∀ a, b ∈ R, then a b = 0 if and only if a = 0 or b = 0; (XI) ∀ a, b ∈ R ∗ , a b , 0 and (a b) −1 = a −1 b −1 . Partial proof We do not present the complete proof (which, by the way, is elementary). Consider (II). From a + c = b + c we find (a + c) + (−c) = (b + c) + (−c). Using the associative property a + c + (−c)  = b + c + (−c)  ⇒ a + 0 = b + 0, Page 39 of 1 2.4 Real numbers MATH1017 so that a = b. Consider (V). Using the distributive rule we have a + a · 0 = a · 1 + a · 0 = a · (1 + 0) = a · 1 = a. It follows that a + a · 0 = a = a + 0, and the conclusion follows applying the cancellation rule (II). Let us consider (VI) If a, b ∈ R and a , 0, applying the associative property of the multiplication we find a (a −1 b) = (a a−1 ) b = 1 · b = b. Hence, a −1 b is a solution of a x = b. We have to show that this is the only solution of a x = b. Suppose that x is a solution of a x = b. Applying the associative property of the multiplication to a x = b yields a −1 (a x) = a −1 b ⇒ (a −1 a) x = a −1 b ⇒ x = a −1 b. In other words, if a solution exists, it needs to be equal to a −1 b. We conclude that if a , 0 a solution exists and it is also unique. Remark 9 An algebraic structure endowed with two operations + and · and satisfying (FA1)-(FA7) is referred to as field. Properties (I)-(XI) of Theorem 5 can be obtained by using exclusively (FA1)-(FA7), and therefore they hold in every field. For example, Q satisfies (FA1)-(FA7), and it is therefore also a field. This means in particular that (I)-(XI) of Theorem 5 hold true for Q as well. Remark 10 The cancellation rule (III) of Theorem 5 requires c , 0. This assumption is essential. Indeed, from property (V), given 2 = 1 + 1, we find 2 · 0 = 1 · 0 = 0, but we cannot conclude that 2 = 1. 2.4.1 Ordering of real numbers We continue our description of real numbers by considering the order property. The relation a < b satisfies the following properties: (OA1) ∀ a ∈ R, it is not true that a < a; (OA2) ∀ a, b ∈ R, if a < b, then it is not true that b < a; (OA3) ∀ a, b, c ∈ R, if a < b and b < c, then a < c; (OA4) ∀ a, b ∈ R and a , b, then either a < b or b < a (and only one one of these, by (OA2)); (OA5) ∀ a, b, c ∈ R, if a < b, then also a + c < b + c; (OA6) ∀ a, b, c ∈ R, if a < b and 0 < c, then a c < b c. Given two real numbers a and b, when we write a ≤ b (14) Page 40 of 175 2.5 Natural, integer, rational numbers MATH1017 we mean that a < b or a = b. We can also write b > a (15) instead of a < b, and b ≥ a (16) instead of a ≤ b. We have a number of important consequences of properties (OA1)-(OA6). To introduce them, we define, given a ∈ R, the square of a as a 2 def = a · a. (17) Theorem 6 The following statements hold: (I) ∀ a, b, c ∈ R with a < b and c < 0, then, b c < a c; (II) ∀ a ∈ R, then 0 ≤ a 2 ; (III) ∀ a, b ∈ R with 0 < a < b, then 0 < a 2 < b 2 ; (IV) ∀ a, b ∈ R with b < a < 0, then 0 < a 2 < b 2 ; (V) ∀ a ∈ R, then a > 0 implies a−1 > 0; (VI) ∀ a ∈ R, then a < 0 implies a−1 < 0; (VII) ∀ a, b ∈ R, then if a > 0 and b > 0, then a b > 0; (VIII) ∀ a, b ∈ R, then if a > 0 and b < 0, then a b < 0; (IX) ∀ a, b ∈ R, then if a < 0 and b < 0, then a b > 0. Partial proof Again, we limit ourselves to proving a few points. Consider (II). If a = 0, then a 2 = 0 ≥ 0. If a > 0, from (OA6) we obtain a 2 > a · 0 = 0. Finally, if a < 0, from (I) we find a 2 > a · 0 = 0. Consider (IV). From b < a and a < 0 we obtain, applying (I), a 2 < a b. Moreover, since b < 0, from b < a it follows that a b < b 2 . The conclusion then follows by applying (OA3). 2.5 Natural, integer, rational numbers The symbol N represents the set of natural numbers 0, 1, 2, . . .. Natural numbers come with a set of axioms that describe their fundamental properties. There are several ways to axiomatize the natural numbers: Page 41 of 175 2.5 Natural, integer, rational numbers MATH1017 one can use the cardinality of sets. Another way, due to von Neumann, is to define the natural numbers recursively starting from the empty set as 0 = ∅ 1 = 0 ∪ {0} = ∅ ∪ {∅} = {∅} 2 = 1 ∪ {1} = {∅} ∪  {∅} =  ∅, {∅} 3 = 2 ∪ {2} =  ∅, {∅} ∪ n ∅, {∅} o = n ∅, {∅},  ∅, {∅} o . . . Obviously this requires proving that ∅, {∅},  ∅, {∅} , etc. are distinct objects. Perhaps the most popular set of axioms for the natural numbers is Peano’s axioms. Peano defines the natural numbers plus a “successor” function S : (i) 0 is a natural number (ii) for every natural number n, the successor S (n) is a natural number (iii) distinct natural numbers have distinct successors, i.e., for all natural numbers n and m, if S (n) = S (m), then n = m (this means that S is injective) (iv) 0 is not the successor of any natural number, i.e., for every natural number n, S (n) is false (v) For any predicate p such that • p{0} is true • for every natural number, p{n} being true implies that p  S (n) is true, then p{n} is true for every natural number. This last axiom is called axiom of induction (even if it is an axiom schema: we have one axiom for each possible predicate). As already mentioned, some authors do not include 0 in N: this is a matter of personal preference. With our conventions, we will denote by N ∗ the set of non-zero natural numbers: N ∗ = N \ {0}. We do not have the time to define the addition and multiplication of natural numbers: we rely on what you learned in elementary school. We limit ourselves to saying that the key to define the addition is to use the successor function in Peano’s axioms jointly with the induction axiom: if n is a natural number, we define 0 + n as n. Suppose that we have inductively defined how to add m to n. Then, we can define S (m) + n as S (m) + n def = S (m + n). In this way, 0 + n = n, 1 + n = S (0) + n = S (n), 2 + n = S (1) + n = S S (n)  , . . . Page 42 of 17 2.5 Natural, integer, rational numbers MATH1017 Interestingly, the properties (including commutativity and associativity) of the addition can be established uniquely using Peano’s axioms and this definition. To define the multiplication, we proceed similarly. If n is a natural number, we define 0 · n as 0. Suppose that we have inductively defined how to multiply m to n. Then, we can define S (m) · n as S (m) · n def = (m · n) + m. In this way, 0 · n = 0, 1 · n = 0 + n = n, 2 · n = 0 + n + n, . . . Moreover, N ⊂ R+. (18) If n ∈ N ∗ , then clearly −n < N ∗ . We denote by Z the set of integer numbers:17 Z def = N ∪ {−n | n ∈ N ∗ }. (19) Sums and products of integer numbers give integer numbers. Moreover, if n ∈ Z, we have also −n ∈ Z. In general, however, if n ∈ Z \ {0}, we have n −1 < Z. For example, 2 ∈ Z, but 2−1 = 1 2 < Z. We define the set of rational numbers Q as18 Q def = m n     m ∈ Z and n ∈ N ∗  . (20) It is easy to verify that Q is a field: sums and products of rational numbers are rational numbers; if q ∈ Q then −q ∈ Q, and if q ∈ Q\{0} then q −1 ∈ Q. It follows that Q, together with the operations of addition + and multiplication ·, satisfies the conditions (FA1)-(FA7). 19 In Q, the conditions (OA1)-(OA6) also continue to hold. This begs the question: why cannot we work only in Q? We will see that Q does not satisfy the supremum property. This property is crucial in the development of mathematical analysis. A first issue with Q can be explained as follows. Consider the equation x 2 = 2. (21) This equation does not have solutions in Q (and we will see that this is actually due to the fact that the supremum property does not hold in Q). To verify this fact, we introduce the following definition and notations. We start with the definition of prime number: A prime number (or a prime) is a natural number greater than 1 that is not a product of two smaller natural numbers. 17The letter “Z” comes from “zahl” (German for number). 18The letter “Q” comes from “quotient”. 19We also say, more succinctly, that the triple (Q, +, ·) satisfies (FA1)-(FA7). Page 43 of 175 2.5 Natural, integer, rational numbers MATH1017 Definition 7 [Prime Number] Let p ∈ N satisfy p ≥ 2. We say that p is prime if two natural numbers q and r different from 1 and p cannot be found for which p = q · r. Example The number 6 is not prime, since 6 = 2 · 3. Examples of prime numbers are 2, 3, 5, 7, etc. Remark 11 In symbols, the condition in Definition 7 can be written as ∄ q,r ∈ N \ {1, p} : p = q · r, (22) or, equivalently,a ∀ q,r ∈ N, p = q · r ⇒ q,r ∈ {1, p}. aWe have the following chain of logical equivalences: ∄ q,r ∈ N \ {1, p} : p = q · r if and only if ¬ ∃ q,r ∈ N \ {1, p} : p = q · r  if and only if ¬ ∃ q,r ∈ N : q,r < {1, p} and p = q · r  if and only if ∀ q,r ∈ N ¬ q,r < {1, p} and p = q · r  (De Morgan’s laws for quantifiers) if and only if ∀ q,r ∈ N, q,r ∈ {1, p} or ¬ p = q · r  (De Morgan’s laws) if and only if ∀ q,r ∈ N, p = q · r ⇒ q,r ∈ {1, p} (recall that (p ⇒ q) ⇔ (¬p ∨ q)) We recall the notion of power with natural exponent: if a ∈ R and n ∈ N ∗ , then a n = a · a · a · . . . · a | {z } n times . We also use the following important result (so important that is sometimes referred to as “fundamental theorem of arithmetic), that we do not prove. Theorem 7 [Prime Factorisation Theorem] Let n ∈ N ∗ . Then, n can be represented in one and only one way in the form n = p α1 1 p α2 2 · · · p αr r , (23) where p1, . . . , pr are prime numbers and α1, . . . , αr are natural numbers. Remark 12 If we wanted to be ultra pedantic, we would re-write the statement of Theorem 7 as follows: Let n ∈ N ∗ . Then, there exists r ∈ N, there exist prime numbers p1, . . . , pr ∈ N satisfying p1 < p2 < . . . < pr ≤ n, and there exist α1, . . . , αr ∈ N such that (23) holds. The expression (23) is called canonical representation of n. Page 44 of 2.6 Maximum/minimum, bounds, supremum/infimum MATH1017 Example We have for example 60 = 2 2 · 3 · 5. Remark 13 The result of Theorem 7 is would not be true if we considered the natural number 1 to be prime. We are now ready to prove that there does not exist x ∈ Q which satisfies x 2 = 2. Theorem 8 Eq. (21) does not have any rational solution, i.e., ∄ x ∈ Q : x 2 = 2. Proof We reason by contradiction. We suppose that there exists a rational solution x. Then, we can write x = p q or in the form x = − p q for some natural numbers p and q (and this means, in the language of logic, that there exist p, q ∈ N, with q , 0, such that x = p q or x = − p q ). From x 2 = 2 we obtain p 2 q 2 = 2, so that p 2 = 2 q 2 . We now factorise p in prime numbers: let p = p α1 1 p α2 2 · · · p αr r . It follows that p 2 = p 2 α1 1 p 2 α2 2 · · · p 2 αr r . The exponents are all even. In particular, if a factor of p is equal to 2, then this factor will also have a corresponding even exponent. Now, we decompose q in prime factors: q = q β1 1 q β2 2 . . . q βs s . Then, 2 q 2 = 2 q 2 β1 1 q 2 β2 2 . . . q 2 βs s . It follows that the decomposition of p 2 = 2 q 2 contains the prime factor 2 with an odd exponent. We obtained a contradiction with Theorem 7. 2.6 Maximum/minimum, bounds, supremum/infimum We introduce some notions connected with the ordering of R. Definition 8 [Maximum and Minimum] Let A ⊆ R and let M ∈ R. We say that M is the maximum of A if it satisfies the two conditions: (a) M ∈ A; (b) a ≤ M for all a ∈ A. In this case, we write M = max A. Likewise, we say that m is the minimum of A if it satisfies: Page 45 of 175 2.6 Maximum/minimum, bounds, supremum/infimum MATH1017 (c) m ∈ A; (d) a ≥ m for all a ∈ A. In this case, we write m = min A. For example, if A = {−1, 2, 4}, then max A = 4 and min A = −1. Not every set has a maximum or a minimum. For example, if A = N, we do not have a maximum, but we have a minimum (which is 0). What enabled us to define “the” maximum and “the” minimum of a set A was a simple result that says that a maximum, if it exists (we saw that it will not always exist, unfortunately), is unique; the same is true for a minimum. In other words, a set can possess at most one maximum and one minimum. To verify this, suppose that both M1 and M2 satisfy (a-b), i.e., they are both maxima of A. Since M1 ∈ A, then M1 ≤ M2. Since M2 ∈ A, then M2 ≤ M1. The two inequalities M1 ≤ M2 and M2 ≤ M1 can be satisfied simultaneously if and only if M1 = M2. In other words, we showed that if A has two maxima, these must be coincide, which is just another way of saying that the maximum of a set A, if it exists, is unique. We now define the notion of upper bound and lower bound. Definition 9 [Upper and Lower Bound] Let A ⊆ R and let u, ℓ ∈ R. We say that u is an upper bound of A if ∀ a ∈ A, a ≤ u. We say that ℓ is a lower bound of A if ∀ a ∈ A, a ≥ ℓ. The maximum of A, if it exists, is an upper bound of A. However, upper bounds are never unique. In fact, if u is an upper bound of A, then every u ′ ≥ u is also an upper bound of A (and analogous considerations hold for lower bounds). Example Consider the set A = {x ∈ R | x ≤ 0}. Then, A has a maximum, and the maximum is 0: we can write max A = 0. Let us denote by U the set of upper bounds of A. We have U = {y ∈ R | y ≥ 0}. Even if this fact seems obvious, we want to give a precise justification: let u be an upper bound of A. There must hold 0 ≤ u. Conversely, if y ≥ 0, for every a ∈ A we have y ≥ 0 ≥ a, so that y ≥ a. Example Consider the set B = {x ∈ R | x < 0}. Then, B does not have a maximum: notice that 0 is not the maximum, because the maximum, if it exists, must belong to B. Page 46 of 175 2.6 Maximum/minimum, bounds, supremum/infimum MATH1017 To convince ourselves beyond any reasonable doubt that B does not have a maximum, suppose by contradiction that the maximum exists and is denoted by M ∈ R, so that by definition M ∈ B. This implies that M < 0, and for every a < 0 we have a ≤ M. On the other hand, since M < 0, we have 1 2 < 1 ⇒ M < M 2 . This is a contradiction because we found an element M/2 of B (because it is still negative) which is greater than the maximum. Hence, B does not have a maximum. However, B has upper bounds. Indeed, the set of upper bounds is the same as U in the previous example: U = {y ∈ R | y ≥ 0}. Indeed, if y ≥ 0, then y is an upper bound of B. Conversely, with the same argument above we find that if d < 0, then d < d 2 < 0, which says that no number smaller than zero can be an upper bound of B. If an upper bound of A exists, we say that A is bounded from above, or upper bounded. Likewise, if a lower bound of A exists, we say that A is bounded from below, or lower bounded. We say that A is bounded if it is bounded from above and from below. Example Consider again the set B = {x ∈ R | x < 0}. We have seen that B admits upper bounds, and therefore B is bounded from above. It is easy to see that B is not lower bounded. In other words, no real number can be a lower bound of B. In fact, let ℓ ∈ R. If ℓ ≥ 0, then ℓ cannot be a lower bound of B since −1 ∈ B and −1 < ℓ. If ℓ < 0, then ℓ is not a lower bound of B since ℓ − 1 ∈ B and ℓ − 1 < ℓ. Verify that {x ∈ R | x > 0} is bounded from below but not from above, and that R is not bounded from below, and it is not bounded from above. Definition 10 [Supremum and Infimum] Let A ⊆ R be bounded from above. Let U denote the set of upper bounds of A. If the minimum of U exists and S = min U, we say that S is the supremum or least upper bound of A, and we write S = sup A. Let A ⊆ R be bounded from below. Let L denote the set of lower bounds of A. If the maximum of L exists and I = max L, we say that I is the infimum or greatest lower bound of A, and we write I = inf A. If the maximum of A exists and is denoted by M, then sup A exists and is equal to M, i.e., sup A = M. In fact, by definition M ∈ U. On the other hand, if u is an upper bound of A, since M ∈ A we have M ≤ u, which implies M = min U. Similarly, if the minimum of A exists, then inf A = min A. On the other hand, it is possible for sup A to exist even when max A does not exist. Page 47 of 175 2.6 Maximum/minimum, bounds, supremum/infimum MATH1017 Example Consider again the set B = {x ∈ R | x < 0}. We have seen that B does not have a maximum, but the set of its upper bounds is U = {y ∈ R | y ≥ 0}. This set has a minimum, which is 0. We conclude that sup B = 0. We did not introduce here all the axioms that define the set of real numbers. However, one of the fundamental axioms is the following: Axiom 1 [Axiom of the Upper/Lower Bound] Let A ⊆ R be non-empty and bounded from above. Then, the minimum of the set of its upper bounds exists. In other words, sup A exists. Let A ⊆ R be non-empty and bounded from below. Then, the maximum of the set of its lower bounds exists. In other words, inf A exists. This axiom is very important: it does not matter how complicated A is: to verify if it has a supremum, it is enough to show that A , ∅ and that it is upper bounded. Remark 14 The reason why we need to specify A , ∅ is because ∅ is bounded from above and from below. Indeed, every real number is an upper bound of ∅. In fact, this means that, given an arbitrary real number r, ∀ x ∈ ∅, x ≤ r. This is logically equivalent to the condition ∀ x, x ∈ ∅ ⇒ x ≤ r (remember the definition of ∀p{x}), and since the antecedent x ∈ ∅ is false (the empty set contains no elements), the implication is (vacuously) true. Example Let a and b be elements of R with a < b. Consider the interval A = (a, b) = {x ∈ R | a < x < b}. First, we observe that A , ∅. Again, this fact is intuitively obvious, but it is always a good idea to make sure that our intuition is not misleading us. To check if A , ∅, we must be able to produce at least an element that belongs to A. Clearly, we cannot take a or b, because the end-points of the interval are not part of the interval itself. An idea is to show that the middle point belongs to A. In fact, 2 a = a + a < a + b < b + b = 2 b ⇒ a < a + b 2 < b ⇒ a + b 2 ∈ A. Moreover, b is an upper bound of A, so that A is bounded from above. We verify that b = sup A. We have to show that b is the minimum of the set of upper bounds. In other words, if u ∈ R and u < b, then u is not an upper bound of A. This is obvious if u < a. If a ≤ u < b, we can take the real number u+b 2 . Indeed, u + b 2 ≥ a + b 2 > a, u + b 2 < 2 b 2 = b. Hence, u+b 2 ∈ A. On the other hand, u + b 2 > 2 u 2 = u. Page 48 of 175 2.6 Maximum/minimum, bounds, supremum/infimum MATH1017 Hence, there exists an element of A greater than u. We can conclude that u is not an upper bound of A. It follows that every upper bound of A is at least equal to b, so that sup A = b. Try to verify that A is lower bounded and inf A = a. 2.6.1 The absolute value We introduce the notion of absolute value (or modulus) of a real number. Definition 11 Let a ∈ R. The absolute value or modulus of a is the real number |a| defined as |a| def = ( a if a ≥ 0 −a if a < 0 (24) Remark 15 The cases a ≥ 0 and a ≤ 0 are not complementary: indeed, a = 0 satisfies both conditions. However, in this case if we replaced a < 0 with the condition a ≤ 0 we would not be making an error: we would obtain with both conditions |0| = 0. We now present some simple properties of the absolute value. Theorem 9 Let a ∈ R. Then, (i) |a| ≥ 0; (ii) | − a| = |a|; (iii) |a| = max{a, −a}. Proof The first statement is obvious. Consider the second. If a ≥ 0, then −a ≤ 0, so that | − a| = −(−a) = a = |a|. If a ≤ 0, then −a ≥ 0, so that | − a| = −a = |a|. The third follows from writing |a| = ( a if −a ≤ a −a if a ≤ −a (25) Theorem 10 Let a ∈ R ∗ + and x ∈ R. Then, the following conditions are equivalent: (i) |x| < a; (ii) −a < x < a. Proof Saying that (i) is equivalent to (ii) is the same as saying that |x| < a if and only if −a < x < a. We start proving that if |x| < a then −a < x < a. We therefore assume that |x| < a holds true. Consider the two possibilities: Page 49 of 175 2.6 Maximum/minimum, bounds, supremum/infimum MATH1017 • If x ≥ 0, then x < a. Since −a < 0, we have also −a < x. The two inequalities together read as −a < x < a; • If x < 0, then x < a. From (i) we have −x < a. Multiplying both sides by −1 yields x > −a. The two inequalities together read as −a < x < a. In both cases, (ii) holds. We now show that if −a < x < a then |x| < a. Suppose that −a < x < a, so that, in particular, x < a. Multiplying these two inequalities by −1 gives −a < −x < a. In particular, −x < a. Applying (iii) in Theorem 9, from x < a and −x < a, we find that max{x, −x} < a, so that |x| < a, and we obtain the conclusion. Theorem 11 Let a, b ∈ R. Then, |a b| = |a| |b|. Proof We have to consider the 4 cases: (i) a ≥ 0 and b ≥ 0. In this case, a b ≥ 0, so that |a b| = a b = |a| |b|. (ii) a ≥ 0 and b < 0. In this case, a b ≤ 0, so that |a b| = −a b = a (−b) = |a| |b|. (iii) a < 0 and b ≥ 0. It can be proved in the same way, swapping the roles of a and b; (iv) a < 0 and b < 0. In this case, a b > 0, so that |a b| = a b = (−a)(−b) = |a| |b|. The following theorem presents a property of the absolute value that plays a central role in mathematical analysis. Theorem 12 [Triangle Inequality] Let a, b ∈ R. Then, |a + b| ≤ |a| + |b|. Proof We have to consider the following cases: (i) a ≥ 0 and b ≥ 0. In this case, a + b ≥ 0, so that |a + b| = a + b = |a| + |b|. (ii) a ≥ 0 and b < 0. Here, we have two possibilities: either a + b ≥ 0 or a + b < 0. (a) a + b ≥ 0. Then |a + b| = a + b = |a| + b. From (iii) in Theorem 9, it follows that b ≤ |b|, so that |a| + b ≤ |a| + |b|. (b) a + b < 0. Here, |a + b| = −(a + b) = (−a) + (−b) = (−a) + |b|. Page 50 of 175 2.6 Maximum/minimum, bounds, supremum/infimum MATH1017 Since −a ≤ |a|, we find (−a) + |b| ≤ |a| + |b|. (iii) a < 0 and b ≥ 0. This case is analogous to the previous one: we can simply swap a and b. (iv) a < 0 and b < 0. Then, a + b < a + 0 = a < 0, so that |a + b| = −(a + b) = (−a) + (−b) = |a| + |b|. Example Determine {x ∈ R | |x − 1| ≤ |x + 2|}. (26) We begin by distinguishing between the two cases x−1 ≥ 0 and x−1 < 0. This means that the set in (26) is the union of the set of solutions of the system ( x − 1 ≥ 0 x − 1 ≤ |x + 2| (27) with the set of solutions of the system ( x − 1 < 0 1 − x ≤ |x + 2|. (28) We solve (27). Distinguishing the cases x + 2 ≥ 0 and x + 2 < 0, this gives rise to the two systems    x − 1 < 0 x + 2 ≥ 0 1 − x ≤ |x + 2|. (29) and    x − 1 < 0 x + 2 < 0 1 − x ≤ |x + 2|. (30) Consider (29). In particular, let us consider the first equation x − 1 ≥ 0. (31) Adding 1 to both sides yields x ≥ 1. (32) This step is reversible: indeed, adding −1 to both sides of (32), we re-obtain (31). Hence, the first condition of (29) is satisfied if and only if x belongs to the set {x ∈ R | x ≥ 1}. (33) Likewise, the second is satisfied if and only if x belongs to the set {x ∈ R | x ≥ −2}. (34) The third condition in (29) is satisfied for any real number, since −1 < 2. Therefore, the set of solutions of (29) is the intersection of the sets (33) and (34), which coincides with (33). Page 51 of 175 2.7 Powers and roots MATH1017 Now we consider (30). This system has no solutions. Indeed, the first two inequalities imply x ≥ 1 and x < −2. It follows that the set of solutions of (27) coincides with (33). Now, we consider the system in (28). This can be divided into the two systems    x − 1 < 0 x + 2 ≥ 0 1 − x ≤ x + 2. (35) and    x − 1 < 0 x + 2 < 0 1 − x ≤ −x − 2. (36) Consider the third inequality of (35). Adding first x and then −2 to both sides (both these operations are reversible) we obtain −1 ≤ 2 x. Multiplying both sides by 1 2 (which is positive), we obtain − 1 2 ≤ x. We can obviously go back, by multiplying both sides by 2. Thus, (35) is equivalent to    x < 1 x ≥ −2 − 1 2 ≤ x, (37) and its set of solutions is ( x ∈ R     − 1 2 ≤ x < 1 ) . (38) Finally, consider (36). This system has no solutions, because from 1 > −2 we obtain 1 − x > −2 − x for every x ∈ R. To conclude, the set (26) coincides with {x ∈ R | x ≥ 1} ∪ ( x ∈ R     − 1 2 ≤ x < 1 ) = ( x ∈ R     x ≥ − 1 2 ) . 2.7 Powers and roots If a ∈ R and n ∈ N, we have defined a n = a · a · . . . · a | {z } n times . (39) This is not a rigorous definition, because we have not given a mathematical meaning to the expression “times”. It is sufficient to say that the induction is at the basis of a more precise definition. We now present the fundamental properties of the power. Theorem 13 Let a, b ∈ R. Let n, m ∈ N ∗ . Then: (i) a m a n = a m+n ; (ii) (a m ) n = a m n; (iii) (a b) n = a n b n . Page 52 of 175 2.7 Powers and roots MATH1017 Partial proof The proof follows directly from (39). Consider for example the first: a m a n = a · a · . . . · a | {z } m times · a · a · . . . · a | {z } n times = a · a · . . . · a | {z } n + m times Our aim is now to define the power with integer exponent. The idea is to extend the definition given for natural exponent in a way that ensures that properties (i-iii) of Theorem 13 are preserved as much as possible. Let a ∈ R ∗ (i.e., a is real and different from 0). Then, a 0 must be such that for every n ∈ N we have a n a 0 = a n+0 = a n . Since a n , 0 for every n ∈ N (because all the factors that define a n coincide with a, and are therefore non-zero), the only possible definition is a 0 def = 1. Now, we want to define a −n for n ∈ N ∗ . We want to have a −n a n = a n−n = a 0 = 1, and therefore we must define a −n def = (a n ) −1 . This motivates the following definition. Definition 12 Let a ∈ R ∗ . We define: (i) a 0 def = 1; (ii) a −n def = (a n ) −1 for all n ∈ N ∗ . Once again, Definition 12 is well posed because a n , 0 for all n ∈ N. With this definition, we obtain the following extension to Theorem 13. Theorem 14 Let a, b ∈ R ∗ . Let n, m ∈ Z. Then: (i) a m a n = a m+n ; (ii) (a m ) n = a m n; (iii) (a b) n = a n b n . We observe that, from (X) in Theorem 5, if a and b are both non-zero, then a b , 0. Thus, (a b) n is well defined for every n ∈ Z. We now examine how the power with natural exponent interacts with the order relation. Theorem 15 Let a, b ∈ R ∗ satisfy 0 < a < b. Then: (i) for all n ∈ N ∗ , we have 0 < a n < b n ; (ii) if a > 1, then for all n ∈ N ∗ , we have 1 < a n < a n+1 ; Page 53 of 175 2.7 Powers and roots MATH1017 (iii) if 0 < a < 1, then for all n ∈ N ∗ , we have 1 > a n > a n+1 . Partial proof The case n = 2 of the first point is contained in (III) of Theorem 6. We do not prove the other cases. Consider the second point. Since a > 1 and a n > 0, we have a n+1 = a an > 1 · a n = a n . Consider the third point. Since a < 1 and a n > 0 we have a n+1 = a an < 1 · a n = a n . Remark 16 If we keep the exponent fixed and the base grows (keeping it in R+), the power grows. If we keep the base fixed and we let the exponent grow, the power decreases or increases, depending on whether 0 < a < 1 holds or a > 1 holds. For example, 4 = 2 2 < 2 3 = 8, 1 4 = 1 2 !2 > 1 2 !3 = 1 8 . 1 1 f(x) = x n n = 1 red n = 2 blue n = 3 green n = 4 black n = 5 brown We stress also that we are considering only the case where the base is positive. For example, the first point of Theorem 15 with a = −2 and b = 1 gives a < b. However, a 2 = 4, b 2 = 1, but b 2 < a 2 . We now consider a classical problem. Given a ∈ R and n ∈ N, can we determine ξ ∈ R such that ξ n = a? The fundamental result in this regard is the following: Theorem 16 Let a ∈ R+ and n ∈ N ∗ . Then, there exists one and only one real number ξ ≥ 0 such that ξ n = a. With Theorem 8 we have shown that the analogous result is false in Q. Theorem 16 then justifies the preference of R over Q. When we discussed this issue, we claimed that the non-existence of a root was linked to the fact that in Q the supremum axiom does not hold. We want to give an idea on the role played by this axiom in the proof of Theorem 16. The fundamental idea is the following. We define A = {x ∈ R | x ≥ 0 and x n ≤ a}. It is easy to see that A , ∅ (it contains 0) and it is upper bounded. From the supremum axiom, we can define ξ def = sup A. It is possible to show that such ξ is the solution that we were looking for. Page 54 of 175 2.7 Powers and roots MATH1017 Definition 13 Let a ∈ R+ and n ∈ N ∗ . We denote by √n a the unique non-negative real number ξ such that ξ n = a, and we call it n-th principal root of a. If n = 2, we write simply √ a. Remark 17 If a ≥ 0, then √n a is not necessarily the only real number which satisfies (√n a) n = a, but it is the only non-negative real number such that (√n a) n = a. For example, for a = 2 and n = 2, (− √ 2)2 = ( √ 2)2 = 2. Clearly − √ 2 , √ 2, since √ 2 , 0. We now consider the equation x n = a with a ∈ R and n ∈ N. Theorem 17 Let a ∈ R and n ∈ N ∗ . Consider the equation x n = a. (40) Then: (i) if n is odd, (40) has, for every a ∈ R, the unique real solution x = ( √n a if a ≥ 0 − √n |a| if a < 0; (41) (ii) if n is even and a > 0, (40) has two real distinct solutions √n a and − √n a; (iii) if n is even and a = 0, (40) has only one solution, and this solution is = 0; (iv) if n is even and a < 0, (40) has no solutions. Proof We begin observing that for every n ∈ N we have (−1)n = ( −1 if n is odd 1 if n is even. (42) In fact, if n = 2 m + 1 with m ∈ N (which means that n is a generic odd natural number), (−1)n = (−1)2 m+1 = (−1)2 m (−1) = −1. If n = 2 m with m ∈ N (which means that n is a generic even natural number), (−1)n = (−1)2 m = (−1)2 m = 1. We now prove (i). If a ≥ 0, by definition √n a is solution of (40). If a < 0, we have (− pn |a|) n = (−1)n |a| = −|a| = a. To prove the uniqueness of the solution, we first consider the case a ≥ 0. From Theorem 16 we know that there are no solutions ≥ 0 different from √n a. We ask ourselves if there could be negative solutions, i.e., we consider the case Page 55 of 1 2.7 Powers and roots MATH1017 where x < 0. We have x n = (−|x|) n = (−1)n |x| n = −|x| n < 0 because n is odd, and thus 0 < x n = a ≥ 0, which is false. Hence, we have uniqueness if a ≥ 0. We now consider the case a < 0. If x ≥ 0, we have also x n ≥ 0, and we conclude that 0 ≤ x n = a < 0. Therefore, there cannot be solutions ≥ 0. Let x < 0 be such that x n = a, so that also |x n | = |a|. Then, by Theorem 11 we have |x n | = |x| n , and therefore |x| n = |a|. This implies, from what we have just seen, that |x| = √n |a|. Thus, we must have x = − √n |a|. Now, we prove (ii). In this case (n is even and a > 0) there is only one non-negative solution, which is √n a. Let x < 0 be such that x n = a. With the same calculation done before, |x| = √n |a| = √n a. The only negative solution can only be − √n a. This is indeed a solution, since (− √n a) n = (−1)n a = a. We now prove (iii). If x n = 0, then 0 = |x n | = |x| n , so that |x| = 0 by Theorem 16. We conclude that, if a = 0, we only have the solution x = 0. Finally, we prove (iv). If x ∈ R and n = 2 m with m ∈ N, x n = (x 2 ) m ≥ 0 from (II) of Theorem 6. In the graph below we show the solutions of x 3 = a, with a1 = 2 and a2 = −3. A solution always exists, because there is an intersection of f(x) = x 3 with any horizontal line: x y a1 √3 a1 a2 − 3 p |a2| In the graph below we show the solutions of x 4 = a, with a = 2. In this case, a solution exists if and only if a ≥ 0, because there is are no intersections of f(x) = x 4 with horizontal lines that correspond to a < 0: Page 56 of 175 2.7 Powers and roots MATH1017 x y a √4 − a √4 a Both graphs confirm that we have one and only one real non-negative solution to the equation x n = a when a ≥ 0. Remark 18 We can now give an example of a real number which is not rational: √ 2. Recall Theorem 7. We now define powers with positive rational exponent of a non-negative real number. Definition 14 Let a ∈ R+ and q ∈ Q. Let n, m ∈ N be such that q = m n (so that q > 0). We define a q def = √n a m. Remark 19 Since a ≥ 0, we have also a m ≥ 0, and therefore √n a m is defined. We observe, however, that the representation of the rational number q as the ratio m/n, with m, n ∈ N (and n , 0) is not unique. For example, we could take q = 2 m 2 n . Therefore, to verify that Definition 14 is independent from the representation we choose, we have to prove the following statement: let a ≥ 0. Let m, n, p,r ∈ N with n,r , 0 be such that m n = p r . Then, √n a m = √r a p . This is easy to see. For example, if a ≥ 0, we have √ a = √4 a 2 . Indeed, ( √ a) 4 = ( √ a) 2 2 = a 2 , and since √ a ≥ 0 and from the uniqueness in Theorem 16 we can conclude. We now present the definition of power with negative rational number for a real positive number. Definition 15 Let a ∈ R ∗ + , q ∈ Q and q > 0. We define a −q def = (a q ) −1 . Remark 20 Definition 15 is clearly inspired by Definition 12. We observe also that if a > 0, then a m > 0 and √n a m > 0, and therefore this definition is well posed. Definitions 14 and 15 have been given to extend the results of Theorems 13 and 14. Page 57 of 17 2.7 Powers and roots MATH1017 Theorem 18 Let a, b ∈ R ∗ + . Let q,r ∈ Q. Then: (i) a q a r = a q+r ; (ii) (a q ) r = a q r; (iii) (a b) q = a q b q . We now consider the second degree algebraic equation (also known as quadratic equation) a x2 + b x + c = 0, (43) where a, b, c ∈ R and a , 0. We define the discriminant ∆ def = b 2 − 4 a c. (44) Theorem 19 Let a, b, c ∈ R and a , 0. Let ∆ be the discriminant of (43). Then: (i) if ∆ > 0, (43) has two real distinct solutions −b± √ ∆ 2 a ; (ii) if ∆ = 0, (43) has only one real solution − b 2 a ; (iii) if ∆ < 0, (43) does not have real solutions. Proof Eq. (43) has the same solutions of x 2 + b a x + c a = 0. Using a technique known as “completion of the square”, we have x 2 + b a x + c a = x 2 + 2 b 2 a x + b 2 4 a 2 ! − b 2 − 4 a c 4 a 2 = x + b 2 a !2 − ∆ 4 a 2 . Hence, (43) is equivalent to (in the same that it has the same set of solutions of) the equation x + b 2 a !2 − ∆ 4 a 2 = 0 ⇔ x + b 2 a !2 = ∆ 4 a 2 . If ∆ < 0, then ∆ 4 a 2 < 0. From Theorem 17, the equation does not have solutions. If ∆ = 0, we find x + b 2 a !2 = 0, which is satisfied if and only if x + b 2 a = 0, i.e., x = − b 2 a . Finally, consider the case ∆ > 0. Then, ∆ 4 a 2 > 0, and by Theorem 17, x + b 2 a = r ∆ 4 a 2 or x + b 2 a = − r ∆ 4 a 2 , Page 58 of 175 2.7 Powers and roots MATH1017 and we obtain the two solutions − b 2 a + r ∆ 4 a 2 and − b 2 a − r ∆ 4 a 2 . If a > 0, we have r ∆ 4 a 2 = √ ∆ 2 a , so that − b 2 a + r ∆ 4 a 2 = −b + √ ∆ 2 a and − b 2 a − r ∆ 4 a 2 = −b − √ ∆ 2 a . If a < 0, r ∆ 4 a 2 = − √ ∆ 2 a , so that − b 2 a + r ∆ 4 a 2 = −b − √ ∆ 2 a and − b 2 a − r ∆ 4 a 2 = −b + √ ∆ 2 a . The geometric interpretation of this result can be achieved by considering that y = a x2 + b x + c is the equation of a parabola with axis of symmetry parallel to the y axis: when a > 0, the opening is to the top, while when a < 0 the opening is to the bottom, and the vertex is at x = − b 2 a . 20 The ordinate of the vertex is y = a b 2 4 a 2 + b − b 2 a ! + c = −a b2 + 4 a 2 c 4 a 2 = − ∆ 4 a . Hence, when ∆ > 0 and a > 0, we have y < 0 (so the vertex is in the third or fourth quadrant) and since the opening is at the top, we will have two intersections with the x-axis. When a > 0, the graphs for different values of ∆ are given in the figure: x y ∆ < 0 x y ∆ = 0 x y ∆ > 0 The case where a < 0 is shown in the figure: x y ∆ < 0 x y ∆ = 0 x y ∆ > 0 20The abscissa of the vertex can be found by setting to zero the first derivative, while the convexity can be deduced using the second derivative of f(x) = a x2 + b x + c, which is 2 a. Page 59 of 175 2.7 Powers and roots MATH1017 We now want to study the sign of the expression P(x) = a x2 + b x + c. The previous figures can be used to interpret the various cases in the following result (try!). Theorem 20 Let a, b, c ∈ R and a > 0. Let P(x) = a x2 + b x + c. Let ∆ = b 2 − 4 a c. Then: (i) if ∆ < 0, then P(x) > 0 for all x ∈ R; (ii) if ∆ = 0, then P(x) > 0 for all x ∈ R such that x , − b 2 a ; (iii) if ∆ > 0, we have: • P(x) > 0 if x < −b− √ ∆ 2 a or if x > −b+ √ ∆ 2 a ; • P(x) < 0 if −b− √ ∆ 2 a < x < −b+ √ ∆ 2 a . Proof With the same calculations of the proof of Theorem 19, we find P(x) = a   x + b 2 a !2 − ∆ 4 a 2   . From this expression, if ∆ < 0, then P(x) > 0 for all x ∈ R. If ∆ = 0, then P(x) = a x + b 2 a !2 . If follows that P(x) is zero if x = − b 2 a . In all the other cases, P(x) is positive. Finally, let ∆ > 0. From y 2 − z 2 = (y + z)(y − z), which holds for every y,z ∈ R, we obtain P(x) = a   x + b 2 a + r ∆ 4 a 2     x + b 2 a − r ∆ 4 a 2   = a  x + b + √ ∆ 2 a    x + b − √ ∆ 2 a   . Hence, P(x) > 0 if x + b+ √ ∆ 2 a and x − b+ √ ∆ 2 a have the same sign, and P(x) < 0 if x + b+ √ ∆ 2 a and x − b+ √ ∆ 2 a have opposite sign. The first condition is satisfied if x < −b− √ ∆ 2 a or if x > −b+ √ ∆ 2 a , and the second is satisfied if −b− √ ∆ 2 a < x < −b+ √ ∆ 2 a (why?). Prove the following analogous result as an exercise. Theorem 21 Let a, b, c ∈ R and a < 0. Let P(x) = a x2 + b x + c. Let ∆ = b 2 − 4 a c. Then: (i) if ∆ < 0, then P(x) < 0 for all x ∈ R; (ii) if ∆ = 0, then P(x) < 0 for all x ∈ R such that x , − b 2 a ; (iii) if ∆ > 0, we have: • P(x) < 0 if x < −b+ √ ∆ 2 a or if x > −b− √ ∆ 2 a ; Page 60 of 175 2.7 Powers and roots MATH1017 • P(x) > 0 if −b+ √ ∆ 2 a < x < −b− √ ∆ 2 a . In this case, since a < 0, we have −b+ √ ∆ 2 a < −b− √ ∆ 2 a . Example Determine ( x ∈ R     x + 1 x − 1 ≤ x x + 2 ) . (45) This expression is defined if and only if x − 1 , 0 and x + 2 , 0, i.e., if and only if (x − 1)(x + 2) , 0. We distinguish the two cases (x − 1)(x + 2) > 0 and (x − 1)(x + 2) < 0. In the first case, multiplying both sides by (x − 1)(x + 2), the inequality is preserved, while in the second case we will obtain the opposite inequality. Hence, (45) coincides with S 1 ∪ S 2, where S 1 = {x ∈ R | (x − 1)(x + 2) > 0 and (x − 1)(x + 2) ≤ x (x − 1)} S 2 = {x ∈ R | (x − 1)(x + 2) < 0 and (x − 1)(x + 2) ≥ x (x − 1)} . The set S 1 coincides with the set of solutions of the system ( (x − 1)(x + 2) > 0 x 2 + 3 x + 2 ≤ x 2 − x ⇔ ( (x − 1)(x + 2) > 0 x ≤ −1 2 . (46) The first condition is satisfied if and only if x > 1 or x < −2. The first is not consistent with x ≤ −1 2 . The second implies x ≤ −1 2 . Hence, S 1 = {x ∈ R | x < −2}. We now find S 2, which coincides with the set of solutions of the system ( (x − 1)(x + 2) > 0 x 2 + 3 x + 2 ≥ x 2 − x ⇔ ( −2 < x < 1 x ≥ −1 2 , (47) which set of solutions is n x ∈ R | − 1 2 ≤ x < 1 o . It follows that the set (45) is {x ∈ R | x < −2} ∪ ( x ∈ R | − 1 2 ≤ x < 1 ) . Example Find {x ∈ R | √ 1 − x 2 ≤ 2 x}. (48) First, we need to find for which x ∈ R the expression in (48) is defined. We must clearly have 1 − x 2 ≥ 0, i.e., x 2 ≤ 1, which is equivalent to −1 ≤ x ≤ 1. Notice that, if −1 ≤ x < 0, we have 2 x < 0, while by definition √ 1 − x 2 ≥ 0. It follows that (48) is the set of solutions of ( 0 ≤ x ≤ 1 √ 1 − x 2 ≤ 2 x (49) Applying the first statement of Theorem 15 (we can apply it because 2 x ≥ 0), we obtain 1 − x 2 ≤ 4 x 2 . This step is reversible. Indeed, if we had √ 1 − x 2 > 2 x, applying again the first statement of Theorem 15 we would obtain 1 − x 2 > 4 x 2 . In the end, we find ( 0 ≤ x ≤ 1 5 x 2 − 1 ≥ 0, (50) Page 61 of 175 2.8 Exponentials and logarithms MATH1017 which gives {x ∈ R | 0 ≤ x ≤ 1} ∩ ( x ∈ R     x ≤ − 1 √ 5 ) ∪ ( x ∈ R     x ≥ 1 √ 5 ) which is the same as  x ∈ R     1 √ 5 ≤ x ≤ 1  . 2.8 Exponentials and logarithms Let a ∈ R ∗ + . For any element q ∈ Q, we have defined a q . We observe that a q > 0 for any q ∈ Q. We want to extend the definition of a c when a > 0 and c ∈ R. We start with the following result. Lemma 1 Let q, q1, q2 ∈ Q with q1 < q2. Then: (i) if 0 < a < 1, we have 0 < a q2 < a q1 ; (ii) if a = 1, then aq = 1; (iii) if a > 1, we have 0 < a q1 < a q2 . Proof Before we see the proof, let us make the following considerations. From Definition 14 and 15, if a > 0 and q ∈ Q, then a q > 0. Let a > 1. We want to show that if q > 0, we have a q > 1. We proceed by steps: • For every n ∈ N ∗ we have √n a > 1. In fact, assuming by contradiction that √n a ≤ 1, applying (i) in Theorem 15 we would find a = ( √n a) n ≤ 1 n = 1, against the assumption that a > 1. • Now, we show that if a > 1, q ∈ Q and q > 0, we have a q > 1. In fact, if q = m/n where m, n ∈ N ∗ , from (i) in Theorem 15 we have a m > 1 m = 1, so that using the result of the previous point on a m we obtain a q = √n a m > 1. We are now ready to proceed with the proof. From these considerations, (ii) follows immediately. Statement (iii) follows from observing that a q1 < a q1 a q2−q1 = a q2 , since a q1 > 0 and a q2−q1 > 1. Finally, (i) can be proved considering that, if 0 < a < 1 and q > 0, then 0 < a q < 1, and continuing as above (try!). We now define a c in the case where a ∈ R ∗ + and c ∈ R. Definition 16 Let c ∈ R and a ∈ R ∗ + . We define: (i) 1 c = 1; (ii) if a > 1, we define ac def = sup{a q | q ∈ Q and q ≤ c}; (iii) if 0 < a < 1, we define ac def = inf{a q | q ∈ Q and q ≥ c}. Page 62 of 175 2.8 Exponentials and logarithms MATH1017 Remark 21 Definition 16 is well posed. In fact, consider first the case a > 1. Let A = sup{a q | q ∈ Q and q ≤ c}. The set A is upper bounded: from Lemma 1, any real number in the form a d , with d ∈ Q and c ≤ d, is an upper bound of A. Moreover, if c ∈ Q, the set A has a maximum, which is exactly a c (in the sense of Definitions 14 and 15). In this case, Definition 16 coincides with the previous ones. If 0 < a < 1, the set B = inf{a q | q ∈ Q and q ≥ c} is lower bounded: any real number in the form a d , with d ∈ Q and c ≥ d, is a lower bound of B. Moreover, if c ∈ Q, the set B has a minimum, and the minimum is a c (again, in the sense of Definitions 14 and 15). Again, Definition 16 coincides with the previous ones for the case of rational exponent. Theorem 18 can be generalised as follows. Theorem 22 Let a, b ∈ R ∗ + . Let ℓ, m ∈ R. Then: (i) a ℓ a m = a ℓ+m ; (ii) (a ℓ ) m = a ℓ m ; (iii) (a b) ℓ = a ℓ b ℓ . Let a ∈ R ∗ + . Consider the function fa : R −→ R x 7→ a x . This function is called exponential function with base a. This function enjoys the following properties: Theorem 23 The following properties hold: (i) if a = 1, then fa(x) = 1 for all x ∈ R; (ii) if a ∈ R ∗ + \ {1}, the image of fa is R ∗ + ; (iii) if a > 1, if x, y ∈ R and x < y, then fa(x) < fa(y); (iv) if 0 < a < 1, if x, y ∈ R and x < y, then fa(x) > fa(y). a > 1 1 a = 1 1 0 < a < 1 1 From Theorem 23, if a ∈ R ∗ + \ {1}, the function fa is injective and its inverse is well defined (as long as we replace the codomain R with the image R ∗ + ). Page 63 of 175 2.8 Exponentials and logarithms MATH1017 Definition 17 Let a ∈ R ∗ + \ {1}. We define loga the inverse of fa : R −→ R ∗ + x 7→ a x , and we call it logarithm of base a. Hence, the function “logarithm of base a” is the function loga : R ∗ + −→ R x 7→ loga (x). For a ∈ R ∗ + \ {1}, from this definition we observe that y = loga x is the unique real solution of the equation a y = x in the unknown y ∈ R. The following theorem contains some important properties of the function loga . Theorem 24 Let a, b ∈ R ∗ + \ {1}. Then: (i) the domain of loga is R ∗ + , and its image is R; (ii) if a > 1, if x, y ∈ R ∗ + and x < y, then loga (x) < loga (y); (iii) if 0 < a < 1, if x, y ∈ R ∗ + and x < y, then loga (x) > loga (y); (iv) if x, y ∈ R ∗ + , then loga (x y) = loga (x) + loga (y); (v) if x ∈ R ∗ + and y ∈ R, then loga (x y ) = y loga (x); (vi) for all x ∈ R ∗ + , logb (x) = logb (a) loga (x); (vii) loga (1) = 0 and loga (a) = 1. Proof (i) follows from the fact that the domain of f is R and the image is R ∗ + . (ii). Suppose by contradiction that loga (x) ≥ loga (y). From Theorem 23 we have fa(loga (x)) ≥ fa(loga (y)), i.e., x ≥ y, which is a contradiction. In the same way we can prove (iii). (iv). loga (x y) is the unique solution in R of the equation a z = x y in the unknown z. It is sufficient to verify that loga (x) + loga (y) is solution of the same equation. In fact a loga (x)+loga (y) = a loga (x) a loga (y) = x y. (v). As in (iv), we observe that z = loga (x y ) is the unique solution of a z = x y , and so a loga (x y ) = x y . We show that Page 64 of 175 2.8 Exponentials and logarithms MATH1017 y loga (x) is solution of the same equation, i.e., a y loga (x) = x y . Indeed, a y loga (x) = a loga (x) y = x y . (vi). We have x = a loga (x) = (b logb (a) ) loga (x) = b logb (a) loga (x) . Therefore, logb x = logb b logb (a) loga (x)  ⇒ logb x = logb (a) loga (x). (vii) follows from a 0 = 1 and a 1 = 1. Remark 22 Property (vi) in Theorem 24 can be used as follows: suppose your calculator “knows” to compute logarithms only with base 2, but you need to compute log3 (x). You can use the expression log3 (x) = log2 (x) log2 (3) . The graphs of loga are given below, in the case of a > 1 and in the case 0 < a < 1: a > 1 1 0 < a < 1 1 For any a ∈ R, the function ga : R ∗ + −→ R x 7→ x a is well defined. We present some important properties of these functions. Theorem 25 The following properties hold: (i) g0(x) = 1 for all x ∈ R ∗ + ; (ii) if a ∈ R \ {0}, the function ga is injective and its image is R ∗ + ; (iii) if x, y ∈ R satisfy 0 < x < y, then: (a) if a > 0, then ga(x) < ga(y); (b) if a < 0, then ga(x) > ga(y). Page 65 of 1 2.8 Exponentials and logarithms MATH1017 Proof The first statement is obvious. Consider (ii). We know that for all x ∈ R ∗ + we have x a > 0. Therefore, the image of ga is contained in R ∗ + . On the other hand, if y ∈ R ∗ + , the equation x a = y (51) has, in R ∗ + , the unique solution x = y 1 a . Let us prove (iii)-(a). Let the symbol Log denote log10. We have ga(x) = f10 Log(x a )  = f10 a Log(a)  for all x ∈ R ∗ + . From (iii) in Theorem 24, we find Log(x) < Log(y), so that a Log(x) < a Log(y), and the conclusion follows from (ii) in Theorem 23. We leave the proof of (iii)-(b) to the readers. The following figures show the graph of ga for different values of a: a > 1 1 1 a = 1 1 1 0 < a < 1 1 1 a = 0 1 1 −1 < a < 0 1 1 a = −1 1 1 a < −1 1 1 We will see later on that property (iii) in Theorem 25 says that the function ga is increasing when a > 0, and is decreasing when a < 0, as the graphs show. Functions of this type are also called monotonic. Page 66 of 1 2.9 Complex numbers MATH1017 In what follows, we define for convenience 0 a def = 0 ∀ a ∈ R ∗ + , (52) so that when a > 0 the domain of ga can be considered to be R+ instead of R ∗ + . 2.9 Complex numbers A polynomial function with real coefficients in the indeterminate x is a function P : R −→ R in the form P(x) = a0 + a1 x + a2 x 2 + . . . + an x n , (53) where n ∈ N, and a0, a1, . . . , an ∈ R. We can write (53) also as P(x) = a0 + Xn k = 1 ak x k . It is possible to prove that the coefficients ak determine the function P uniquely. If an , 0, we say that n is the degree of P. In the case where a0 , 0 and a1 = a2 = . . . = an = 0, we say that the polynomial has degree equal to 0 (this is the case of non-zero constant functions). If the coefficients are all zero (this is the case where the function is identically zero) we say, by convention, that the degree is −∞ (“minus infinity”). In many problems in mathematics, the problem is to determine the real numbers x that satisfy P(x) = 0, (54) where P is a polynomial function. We have already seen that, given a polynomial P, (54) does not necessarily have real solutions, see Theorem 19. Consider, for example, the case P(x) = x 2 + 1. We now construct an extension of R where every polynomial equation possesses solutions: this extension is called field of “complex numbers”, and we denote it by C. To this end, we begin considering the set R × R of ordered pairs of real numbers. We define C def = R × R. We now introduce two operations that we call, respectively, addition and multiplication in C. Let a, b, c, d ∈ R. We define (a, b) C + (c, d) def = (a + c, b + d), (55) (a, b) C · (c, d) def = (a c − b d, a d + b c). (56) We used the superscript C to distinguish these two operations from the usual operations for real numbers. Theorem 26 The set C, with the operations of addition and multiplication defined in (55-56), is a field. The “zero” element for which (FA4) holds is the pair (0, 0). The element “one” for which (FA5) holds is the pair (1, 0). Page 67 of 175 2.9 Complex numbers MATH1017 Proof We need to verify that the properties (FA1)-(FA7) are satisfied. We limit ourselves to (FA3), (FA6) and (FA7), and leave the remaining ones as exercises. Consider (FA3). Let z = (a, b),w = (c, d) and u = (e, f), where a, b, c, d, e, f ∈ R. Then, z C · (w C + u) = (a, b)(c + e, d + f) = a (c + e) − b (d + f), a (d + f) + b (c + e)  = (a c + a e − b d − b f, a d + a f + b c + b e) and z C · w C + z C · u = (a c − b d, a d + b c) + (a e − b f, a f + b e) = (a c + a e − b d − b f, a d + a f + b c + b e) Consider now (FA6). Given v = (a, b), where a, b ∈ R, it is sufficient to define z = −(a, b). Clearly, z C + (−z) = (0, 0). Now, we prove (vii). Let z = (a, b) , (0, 0). We have to determine (x, y) such that (a, b) C · (x, y) = (1, 0). (57) Eq. (57) is equivalent to the system ( a x − b y = 1 b x + a y = 0. (58) Since z , (0, 0), at least one of the two real numbers a and b is different from 0. Suppose for example that a , 0. Then, (58) has the solution (x, y) = a a 2 + b 2 , − b a 2 + b 2 ! . If we assume b , 0, we re-obtain the same solution (why?). The rest of the proof is left as an exercise. Let z ∈ C, where z = (a, b) (and a, b ∈ R). We define −z def = (−a, −b), (59) and, if z , (0, 0), z −1 def = a a 2 + b 2 , − b a 2 + b 2 ! . (60) Since C has been shown to be a field, Theorem 5 holds for C. We now want to explain in which sense C, with the operations introduced here, is an extension of R. In other words, we want to be able to write the inclusion R ⊂ C. On the other hand, the definition we provided of C as R×R does not allow to write such inclusion; it makes no sense to say that an element of R is also an element of C, because the elements of C are pairs of real numbers. However, we can still achieve this goal if we identify R with the subset of C such that the second component is zero. In other words, we consider the subset R ′ of C defined by R ′ = {(x, 0) ∈ R 2 | x ∈ R}, Page 68 of 17 2.9 Complex numbers MATH1017 which comprises all the pairs where the second element is zero. The geometric interpretation is simple: the set C = R × R = R 2 can be visualized as the set of points in the plane, and R ′ can be thought of as the points of the x-axis: R ′ C • (a, 0) • (b, 0) R • a • b • 0 Intuitively, we can “forget” that the points of R ′ are pairs in the form (x, 0), and just think about them as “regular” real numbers x ∈ R. Moreover, the operations that we carry out in C are consistent with the operations we carry out in R, in the sense that, given a, b ∈ R, we have (a, 0) C + (b, 0) = (a + b, 0) (a, 0) C · (b, 0) = (a b − 0 · 0, a · 0 + 0 · b) = (a b, 0). In other words, the usual operations of addition and multiplication in R can be thought of as a particular case of the new operations C + and C · that we have introduced for complex numbers. To make this discussion rigorous, we show that there is a bijection α : R −→ R ′ that maps a real number x ∈ R into the complex number α(x) = (x, 0) ∈ R ′ , and which commutes with the operations of addition and multiplication in R and R ′ , as shown in the following theorem; these properties can be equivalently expressed by saying that α is an isomorphism between the triples (R, +, ·) and (R ′ , C +, C ·). Theorem 27 Let R ′ = {(x, 0) ∈ R 2 | x ∈ R} and α : R −→ R ′ , x 7→ (x, 0). Then: (i) α is bijective; (ii) for all x, y ∈ R there holds α(x + y) = α(x) C + α(y); (iii) for all x, y ∈ R there holds α(x · y) = α(x) C · α(y). Page 69 of 175 2.9 Complex numbers MATH1017 Proof It is trivial to see that α is bijective (try!). Let us prove the second and third points. Let x, y ∈ R. Then α(x + y) = (x + y, 0) = (x, 0) C + (y, 0) = α(x) C + α(y). and α(x · y) = (x · y, 0) = (x, 0) C · (y, 0) = α(x) C · α(y). The previous result ensures that, if we identify the real numbers with the subset of the complex numbers whose second component is zero, the operations of addition C + and multiplication C · in C are consistent with the operations of addition + and multiplication · in R. The identification of a real number x with the complex number (x, 0), which allows us to write x = (x, 0), is consistent with • the equality: for all x, y ∈ R, we have x = y if and only if (x, 0) = (y, 0); • the negation: for all x, y ∈ R, we have x = −y if and only if (x, 0) = −(y, 0); • the addition: for all x1, x2, x3 ∈ R, we have x1 + x2 = x3 if and only if (x1, 0) C + (x2, 0) = (x3, 0); • the multiplication: for all x1, x2, x3 ∈ R, we have x1 x2 = x3 if and only if (x1, 0) C · (x2, 0) = (x3, 0). The first two are a result of the properties of pairs. The last two are a consequence of Theorem 27. For this reason, from now on, with some abuse of notation we will use the convention of indicating the set R ′ with the symbol R; hence, we will denote with x the complex number (x, 0). We will also omit the superscripts in the operations of addition and multiplication in C, and we will use the usual symbols + and · both for the addition and multiplication in R and in C, as we no longer need to distinguish between the addition of real numbers and the addition of complex numbers (and similarly for the multiplication). For example, we can determine 2 (1, 4) by identifying the real number 2 with the complex number (2, 0), and then using the definition of multiplication of complex numbers to find (2, 0) · (1, 4) = (2 · 1 − 0 · 4, 2 · 4 + 0 · 1) = (2, 8). In particular, α(0) = (0, 0) and α(1) = (1, 0), so that we can write 0 in place of (0, 0) and 1 in place of (1, 0). We define i def = (0, 1). (61) We observe that i 2 = (0, 1) · (0, 1) = (−1, 0), which, using the previously explains identification, can be written as i 2 = −1. If (a, b) ∈ C, we have (a, b) = (a, 0) + (0, b) = (a, 0) + (b, 0) · (0, 1) = a + i b, where, once again, we have used the identification of (a, 0) with a and (b, 0) with b. We will call a + i b the algebraic form (or Cartesian form) of the complex number (a, b). Every complex number z can therefore be written in a unique way in the form a + i b. The convention of writing (a, b) as a + i b is particularly convenient, because, from the fact that (C, +, ·) is a field, addition and multiplication of complex numbers Page 70 of 175 2.9 Complex numbers MATH1017 behave consistently with the usual rules of addition and multiplication of real numbers, and with in addition the possibility of replacing i 2 with −1. Thus, given a, b, c, d ∈ R, we have (a, b) + (c, d) = a + i b + c + i d = a + c + i (b + d) = (a + c, b + d) (a, b) · (c, d) = (a + i b) · (c + i d), = a c + i (b c + a d) + i 2 b d = a c − b d + i (b c + a d) = (a c − b d, b c + a d). We observe that the addition and multiplication of complex numbers behave in the same way of the addition and multiplication of polynomials with real coefficients in the indeterminate i, with the additional property i 2 = −1. Remark 23 We used the notation i 2 to denote i · i. More in general, it is possible to extend the notion of power with natural exponent to the complex case, and all the properties of Theorem 13 continue to hold for this case. We notice also that, as in the real case, if z ∈ C and z , 0, for every n ∈ N ∗ we have z n , 0. We can therefore extend also the notion of power with integer exponent to the complex case (see Definition 12), and all the properties of Theorem 14 still hold. We now introduce two useful notations. Definition 18 [Real and Imaginary Parts of a Complex Number] Let z ∈ C. Let a, b ∈ R such that z = a + i b. We define Re{z} def = a and Im{z} def = b. The real number Re{z} is called the real part of z. The real number Im{z} is called the imaginary part of z. Real numbers can be considered as a subset of C, i.e., as the complex numbers with imaginary part equal to zero. Real numbers can be represented as points on a straight line (called the real line). A complex number can be viewed as a point in a two-dimensional Cartesian coordinate system, called the complex plane or Gauss plane or Argand diagram. The numbers are conventionally plotted using the real part as the horizontal component, and imaginary part as vertical. These two values used to identify a given complex number are therefore called its Cartesian coordinates. In this way, the real line coincides with the horizontal axis (abscissa), while the points in the vertical axis (ordinate) are the purely imaginary numbers, i.e., those with zero real part. Clearly, 0 is the only number that is real and purely imaginary. Page 71 of 175 2.9 Complex numbers MATH1017 z = a + i b Re{z} = a Im{z} = b Definition 19 [Conjugate of a Complex Number] Let z ∈ C. Let a, b ∈ R be such that z = a + i b. We define z¯ def = a − i b. We call z the ¯ conjugate of z. Geometrically, ¯z is the reflection of z about the real axis. z = a + i b z¯ = a − i b The following theorem lists useful properties of complex numbers. For example, conjugating twice gives the original complex number: z¯¯ = z. Moreover, conjugation distributes over the addition and multiplication. Finally, the real and imaginary parts of a complex number can be extracted using the conjugate. Theorem 28 [Properties of Conjugate] Let z,w ∈ C. The following statements hold: (i) z¯¯ = z; (ii) z = z¯ ⇔ z ∈ R; (iii) zz¯ = Re{z} 2 + Im{z} 2 ∈ R+; (iv) z + w = z¯ + w;¯ (v) z w = z¯ w;¯ (vi) 1/z = 1/z;¯ Page 72 of 1 2.9 Complex numbers MATH1017 (vii) Re{z} = z + z¯ 2 ; (viii) Im{z} = z − z¯ 2 i . The proof is left as an exercise. As a hint, try to express the complex number z in Cartesian form. Remark 24 We have not introduced an ordering in C. In fact, it is not possible to introduce an order relation in C that satisfies the properties (OA1)-(OA6). To see this, suppose i > 0: then, i 2 = i · i = −1 violates (vii) in Theorem 6. Suppose i < 0. Then, −i > 0 and (−i)(−i) = −1, violating (vii) in Theorem 6 again. From (OA4), we conclude that i = 0, which we know is false because i = (0, 1) , (0, 0). Hence, it is entirely meaningless to write, for example, z < w with z,w ∈ C. We now introduce the modulus, or absolute value, of a complex number. The definition that we gave of absolute value for a real number x |x| = ( x if x ≥ 0 −x if x < 0 cannot be extended directly to complex numbers, because it makes no sense to say that a complex number is positive or negative. We can still define the absolute value of a complex number by generalising the expression |x| = √ x 2 . Definition 20 [Modulus of a Complex Number] Let z ∈ C. Let a, b ∈ R such that z = a + i b. We define |z| = √ a 2 + b 2 to be the modulus, or magnitude, or absolute value of z. Clearly, if z is a real number (i.e., if b = 0), then |z| = |a|. Intuitively, the modulus of a complex number z is the distance of z from the origin. z |z| We start presenting some simple properties: Theorem 29 Let z,w ∈ C and λ ∈ R. Then: Page 73 of 175 2.9 Complex numbers MATH1017 (i) |z| = √ zz;¯ (ii) |z| = |z¯|; (iii) |z| ≥ |Re{z}| ≥ Re{z}; (iv) |z| ≥ |Im{z}| ≥ Im{z}; (v) Re{λ z} = λ Re{z}; (vi) Im{λ z} = λ Im{z}. Partial proof We prove (iii). If z = a + i b, where a, b ∈ R, we have immediately |z| = √ a 2 + b 2 ≥ √ a 2 = |a| ≥ a. The proof of the other statements is left as an exercise. Theorem 30 Let z,w ∈ C. Then: (i) max  |Re{z}|, |Im{z}| ≤ |z| ≤ |Re{z}| + |Im{z}|; (ii) |z w| = |z| |w|; (iii) |z + w| ≤ |z| + |w|. Proof (i). From (iii) and (iv) in Theorem 29 we see that |Re{z}| ≤ |z| and |Im{z}| ≤ |z|, from which we find immediately that max  |Re{z}|, |Im{z}| ≤ |z|. We only need to show that |z| ≤ |Re{z}| + |Im{z}|. Let z = a + i b, where a = Re{z} and b = Im{z}, so that we must prove that |z| ≤ |a| + |b|, i.e., √ a 2 + b 2 ≤ |a| + |b|, i.e., a 2 + b 2 ≤ (|a| + |b|) 2 . This inequality holds since a 2 + b 2 ≤ a 2 + b 2 + 2 |a| |b| = (|a| + |b|) 2 . (ii). Let z = a + i b and w = c + i d, where a, b, c, d ∈ R. Then, |z w| = |(a c − b d) + i (a d + b c)| = p (a c − b d) 2 + i (a d + b c) 2 = √ a 2 c 2 + b 2 d 2 − 2 a b c d + a 2 d 2 + b 2 c 2 + 2 a b c d = p (a 2 + b 2 )(c 2 + d 2 ) = √ a 2 + b 2 √ c 2 + d 2 . (iii). From Theorem 29, |z + w| 2 = (z + w)(z + w) = (z + w) (¯z + w¯) = |z| 2 + |w| 2 + zw¯ + wz¯. Using (i), zw¯ + wz¯ = zw¯ + zw¯ = 2 Re{zw¯} ≤ 2 |Re{zw¯}| ≤ 2 |zw¯| = 2 |z| |w¯| = 2 |z| |w|. We conclude that |z + w| 2 ≤ |z| 2 + |w| 2 + 2 |z| |w| = (|z| + |w|) 2 , Page 74 of 175 2.9 Complex numbers MATH1017 and taking the square root on both sides gives the result. Remark 25 We know that, differently from what happens in R, the equation z 2 + 1 = 0 (62) has solutions in C. We claimed that every polynomial equation with complex coefficients possesses complex solutions. We will not prove this result (known as “fundamental theorem of algebra”) in all its generality in this unit. Example We want to describe the set n z ∈ C | Re n 1 z o = 0 o . Let z = x + i y, where x, y ∈ R. To make sure that 1 z makes sense, we must assume that at least one between x and y is non-zero. Under this condition, multiplying numerator and denominator by ¯z and using (i) in Theorem 29, we obtain Re ( 1 z ) = Re ( z¯ |z| 2 ) = x |z| 2 , which becomes 0 if and only if x = 0. We obtain the set {z ∈ C | Re{z} = 0 and z , 0}. This is, in essence, the imaginary axis without the origin. Remark 26 If we have two complex numbers z = a + i b and w = c + i d, where a, b, c, d ∈ R, a simple geometric construction shows (with the application of Pythagora’s theorem) that |z − w| represents the distance between z and w: |z − w| = |(a − c) + i (b − d)| = p (a − c) 2 + (b − d) 2 . This simple construction is shown in the figure: • • z w a c b d • • z w a c b d c − a b − d |z − w| Try to convince yourself that this continues to be true, graphically, also when z and w are not necessarily both in the first quadrant. Page 75 of 175 2.9 Complex numbers MATH1017 2.9.1 Goniometric functions Let S = {z ∈ C | |z| = 1}, usually referred to as the unit circle. In the complex plane, S is the circle of radius 1 centred at the origin. Let us fix z ∈ S . We denote by A(z) the arc of S described by a point that moves in a counter-clockwise direction along S starting from (1, 0) up until it reaches z. (1, 0) • z • A(z) We now define the length ℓ(z) of A(z). Definition 21 Let z ∈ S . We define ℓ(z) def = sup    Xn j = 1 |zj − zj−1|     n ∈ N ∗ , z0 = 1, zn = z, zj−1 ∈ A(zj) ∀ j ∈ {1, . . . , n}    . Remark 27 We now explain the meaning of Definition 21. Once z ∈ S is chosen, we choose z0, . . . ,zn in A(z) arbitrarily, starting from 1 (i.e., (1, 0)) and ending with z, by moving in a counter-clockwise direction: this is the meaning behind the request zj−1 ∈ A(zj) ∀ j ∈ {1, . . . , n}, which can be expanded into zn−1 ∈ A(zn), zn−2 ∈ A(zn−1), . . . , z1 ∈ A(z2), z0 ∈ A(z1), the last of which is redundant. The points z0, . . . ,zn are therefore the vertexes of a polygonal line inscribed in A(z). The sum Xn j = 1 |zj − zj−1| represents the length of this polygonal line. Hence, ℓ(z) is defined as the supremum of all the lengths of all the polygonal lines inscribed in A(z). z0 • z2 • • • z1 z3 • z4 It is possible to prove that this definition is well posed, in the sense that the this set is upper bounded. Once again, the axiom of the supremum allows us to conclude that the set possesses a supremum. Page 76 of 175 2.9 Complex numbers MATH1017 Definition 22 We define π as ℓ(−1). We also present the following result, without proof. Theorem 31 We have ℓ(z) < 2 π for all z ∈ S . Moreover, let x ∈ R with 0 ≤ x < 2 π. Then, there exists one and only one z ∈ S such that ℓ(z) = x. In other words, the function ℓ : S −→ [0, 2 π) is a bijection, and therefore we can compute its inverse, which is the function ℓ −1 : [0, 2 π) −→ S that maps x ∈ [0, 2 π) into a complex number ℓ −1 (x) on the unit circle. The real part of this complex number is the cosine of x, and the imaginary part is the sine of x: cos : [0, 2 π) −→ R x 7→ Re ℓ −1 (x) and sin : [0, 2 π) −→ R x 7→ Im ℓ −1 (x) Definition 23 Let x ∈ R with 0 ≤ x < 2 π. Let z ∈ S be such that ℓ(z) = x. We define cos(x) def = Re{z} (63) sin(x) def = Im{z}. (64) We call cos(x) and sin(x) the “cosine” and the “sine” of x, respectively. For now cos and sin are defined only over [0, 2 π) = {x ∈ R | 0 ≤ x < 2 π}. Now we wish to extend them over R as periodic functions with period 2 π. In other words, if x ∈ [0, 2 π), we define, for every k ∈ Z, cos(x + 2 k π) = cos(x) and sin(x + 2 k π) = sin(x). In this way, the cosine and the sine can be regarded as functions: cos : R −→ R x 7→ cos(x) and sin : R −→ R x 7→ sin(x). We will often write cos x and sin x instead of cos(x) and sin(x), respectively, if the meaning is clear from the context. Page 77 of 175 2.9 Complex numbers MATH1017 Example Simple geometric considerations show that ℓ(i) = π 2 (65) ℓ   √ 3 2 + i 2   = π 6 (66) ℓ   1 2 + i √ 3 2   = π 3 (67) ℓ 1 √ 2 + i 1 √ 2 ! = π 4 , (68) from which we find cos π 2  = 0, cos π 6  = √ 3 2 , cos π 3  = 1 2 , cos π 4  = 1 √ 2 = √ 2 2 , (69) sin  π 2  = 1, sin  π 6  = 1 2 , sin  π 3  = √ 3 2 , sin  π 4  = 1 √ 2 = √ 2 2 , (70) The periodicity yields cos − 3 π 2 ! = cos π 2  = cos 5 π 2 ! = 0 (71) sin − 3 π 2 ! = sin  π 2  = sin 5 π 2 ! = 1. (72) We now present some important properties of the cosine and of the sine. Theorem 32 The following properties hold: (i) sin2 x + cos2 x = 1; (ii) the cosine is an even function, i.e., ∀ x ∈ R, cos(−x) = cos x; (iii) the sine is an odd function, i.e., ∀ x ∈ R, sin(−x) = − sin x; (iv) cos(x + y) = cos x cos y − sin x sin y for all x, y ∈ R; (v) sin(x + y) = sin x cos y + sin y cos x for all x, y ∈ R; (vi) cos x − cos y = −2 sin  x+y 2  sin  x−y 2  and sin x − sin y = 2 cos x+y 2  sin  x−y 2  (prosthaphaeresis formulae); (vii) cos2  x 2  = 1+cos x 2 and sin2  x 2  = 1−cos x 2 . Page 78 of 175 2.9 Complex numbers MATH1017 Partial proof We prove (i). If x ∈ [0, 2 π), we have cos x = Re{z} and sin x = Im{z} for some z ∈ S , which immediately gives (i). We prove (vi). From x = x+y 2 + x−y 2 and y = x+y 2 − x−y 2 , we find cos x = cos x + y 2  cos x − y 2  − sin  x + y 2  sin  x − y 2  cos y = cos x + y 2  cos − x − y 2  − sin  x + y 2  sin  − x − y 2  = cos x + y 2  cos x − y 2  + sin  x + y 2  sin  x − y 2  , and by difference we obtain the first one. The second can be obtained similarly (try!). We prove (vii). We have cos x = cos x 2 + x 2  = cos2  x 2  − sin2  x 2  = 2 cos2 x 2 − 1, which leads to the first. The second can be obtained by sin2  x 2  = 1 − cos2  x 2  = 1 − 1 + cos x 2 = 1 − cos x 2 . 2.9.2 Roots of a complex number In this section we want to study the solutions of the equation z n = w, (73) where n ∈ N ∗ and w is a given complex number. Here, z denotes the indeterminate, which is assumed to live in C. Differently from the equation x n = a, this equation always has solutions in C. This is a particular case of an aforementioned general property called fundamental theorem of algebra. We will start introducing a useful notation. Definition 24 Let x ∈ R. We define e i x = cos x + i sin x. Theorem 33 Let x, y ∈ R and let n ∈ Z. Then: (i) |e i x| = 1; (ii) e i x e i y = e i (x+y) ; (iii) (e i x) −1 = e i (−x) ; (iv) (e i x) n = e i n x; (v) if x, y ∈ R, then ei x = e i y if and only if there exists k ∈ Z such that x − y = 2 k π. Proof We prove (i). We find immediately |e i x| = p cos2 x + sin2 x = 1. Page 79 of 175 2.9 Complex numbers MATH1017 (ii) From Theorem 32 e i x e i y = (cos x + i sin x)(cos y + i sin y) = cos x cos y − sin x sin y + i (cos x sin y + cos y sin x) = cos(x + y) + i sin(x + y) = e i (x+y) . (iii) From (ii) e i x e i (−x) = cos 0 + i sin 0 = 1. (iv) If n ∈ N, from (ii) (e i x) 2 = e i x e i x = e i 2 x (e i x) 3 = (e i x) 2 e i x = e i 2 x e i x = e i 3 x . . . Moreover, (e i x) 0 = 1 = e i 0 = e i 0 x . Finally, from (iii), if n = −m with m ∈ N, we have (e i x) n = (e i x) m −1 = (e i m x) −1 = e i (−m x) = e i n x . (v). We have e i x = e i y if and only if e i (x−y) = 1, by multiplying both sides by e i (−y) and applying (ii). This means cos(x − y) = 1 and sin(x − y) = 0, which allow us to conclude. Let z ∈ C and z , 0. The complex number ζ = z |z| has modulus equal to 1 from (ii) in Theorem 62. If x = ℓ(ζ), then x is solution of the equation e i x = ζ. (74) Eq. (74) has infinite solutions because sin and cos are periodic. More precisely, the real solutions of (74) are the numbers in the form x + 2 k π with k ∈ Z (and only those). We could represent z in the form z = |z| e i y (75) for infinite choices of y ∈ R: two arbitrary choices will differ by an integer multiple of 2 π. We will call trigonometric form (or polar form) of z any form of the type (75). The real numbers y for which (75) holds are a subset of R that we call argument of z, and we will denote this set by arg z. Since two arguments of the same complex number z ∈ C ∗ differ by a multiple of 2 π, there is only one argument in the interval (−π, π]. We call this particular element of arg z the principal argument of z, and we denote it by Arg z. Example Let z = √ 3 + i. We want to obtain a trigonometric form of z. We have |z| = √ 3 + 1 = 2. We define ζ = z |z| = √ 3 2 + i 2 = e i π 6 . Thus, √ 3 + i = 2 e i π 6 . In this case, arg( √ 3 + i) =  π 6 + 2 k π     k ∈ Z  . We also have Arg( √ 3 + i) = π 6 . Page 80 of 17 2.9 Complex numbers MATH1017 Example Let z = −3 i. We want to obtain a trigonometric form of z. We have |z| = 3. We define ζ = z |z| = −i = e i 3 2 π , since cos 3 2 π  = 0 and sin  3 2 π  = −1. Thus, −3 i = 3 e i 3 π 2 . Alternatively, −3 i = 3 e −i π 2 . Why? It follows also that arg(z) =  3 2 π + 2 k π     k ∈ Z  =  − π 2 + 2 k π     k ∈ Z  . However, we only have one principal argument, which is Arg(z) = − π 2 , because 3 2 π < (−π, π]. Example Let z = −5. We want to obtain a trigonometric form of z. We have |z| = 5. We define ζ = z |z| = −1 = e i π . Thus, −5 = 5 e i π . Alternatively, −5 = 5 e −i π . Why? It follows also that arg(z) = {π + 2 k π | k ∈ Z} = {−π + 2 k π | k ∈ Z}. We have Arg(z) = π, because −π < (−π, π]. Example Let z = 1 + i. We want to obtain a trigonometric form of z. We have |z| = √ 1 + 1 = √ 2. We define ζ = z |z| = 1 √ 2 + i √ 2 = e i π 4 . Thus, 1 + i = √ 2 e i π 4 . In this case, arg(1 + i) =  π 4 + 2 k π     k ∈ Z  . We have in particular Arg(1 + i) = π 4 . Example The trigonometric form of a complex number is particularly convenient for finding powers and products. Let us find, for example (1 + i) 7 . We have already seen that 1 + i = √ 2 e i π 4 . Thus, using (iv) in Theorem 33 (1 + i) 7 = √ 2 e i π 4 7 = ( √ 2)7 e i 7 π 4 . Suppose that we are required to determine the Cartesian form of (1 + i) 7 . Noting that ( √ 2)7 = 8 √ 2 and cos 7 π 4 ! = cos 2 π − π 4  = cos − π 4  = cos π 4  = 1 √ 2 sin 7 π 4 ! = sin  2 π − π 4  = sin  − π 4  = − sin  π 4  = − 1 √ 2 , we obtain (1 + i) 7 = 8 √ 2 1 √ 2 − i √ 2 ! = 8 − 8 i. We are now ready to study the solutions of the equation (73). We will start with an informal example to guide our intuition: let us assume that we want to find the 6-th root of i, i.e., we want to solve the equation z 6 = i in the unknown z ∈ C. At this stage we are not even certain that that complex number that does this job exists. The search for a complex number whose 6-th power gives us i can start either by expressing this unknown number using the Cartesian or the polar form. Let us go with the first, and we assume that there is a complex number, say z = x + i y (where x, y ∈ R) such that z 6 = i, i.e., (x + i y) 6 = i. (76) Page 81 of 17 2.9 Complex numbers MATH1017 We want to find if we can solve this equation for x and y: if such values do not exist, we cannot find a complex number which raised to the 6-th power gives i. Using the binomial formula to compute the 6-th power in (76) leads to a very complicated system of equations, even by considering the rules of exponentation of i, which are fairly simple.21 In fact, we find x 6 − 15 x 4 y 2 + 15 x 2 y 4 − y 6 + i (6 x 5 y − 20 x 3 y 3 + 6 x y5 ) = i, which leads to the system ( x 6 − 15 x 4 y 2 + 15 x 2 y 4 − y 6 = 0 6 x 5 y − 20 x 3 y 3 + 6 x y5 = 1. Finding the set of solutions to this system of algebraic equations is not a straightforward task. Instead of assuming the solution to be expressed as a complex number in Cartesian form, we show that using the polar form of a complex number leads immediately to the solution. A polar form of i is i = 1 · e i π 2 . Let us assume now that the number z whose 6-th power is equal to i can be written in polar form as z = |z| e i t , where t ∈ arg(z). The equation z 6 = i becomes |z| 6 e i 6 t = i, Since i = 1 · e i π 2 , we obtain |z| 6 e i 6 t = 1 · e i π 2 . This is an equality involving complex numbers. Two complex numbers are equal if and only if they have the same magnitude and their arguments differ by integer multiples of 2 π. We obtain the system ( |z| 6 = 1 6 t = π 2 + 2 k π, k ∈ Z. The equation |z| 6 = 1 is the same as the equation x n = a with a ≥ 0, where x is a real unknown, and we have seen that there is only one non-negative solution, which is the principal 6-th root of 1, so that we obtain    |z| = √6 1 t = π 2 +2 k π 6 , k ∈ Z, which is the same as ( |z| = 1 t = π 12 + π 3 k, k ∈ Z, We obtain the angles t = π 12 , 5 π 12 , 9 π 12 , 13 π 12 , 17 π 12 , 21 π 12 , 25 π 12 , · · · (77) 21When we raise i to a power, we obtain i 2 = i · i = −1, i 3 = i · i · i = −1 i = −i, i 4 = i 2 · i 2 = (−1)(−1) = 1, i 5 = i 2 · i 3 = (−1) (−i) = i, i 6 = i 4 · i 2 = (1)(−1) = −1, i 7 = i 4 · i 3 = (1)(−i) = −i, . . . which says that even powers of i are real, and odd powers are imaginary. Page 82 of 175 2.9 Complex numbers MATH1017 The angle t = π 12 gives rise to the same complex number as t = 25 π 12 , since they differ by 2 π: 25 π 12 = π 12 + 2 π. In the same way, 29 π 12 gives me the same complex number as 5 π 12 , since 29 π 12 = 5 π 12 + 2 π. In other words, continuing to find further values of t in (77) does not add any new complex numbers: we re-obtain the same complex numbers because the new angles that we find differ by the previous 6 by integer multiples of 2 π. Geometrically, for the value t = π 12 , we obtain z0 = 1 · e i π 12 : it is a point of the unit circle (in particular, its angle with respect to the real axis is 15◦ ). z 6 = i 1 z0 z1 z2 z3 z4 z5 π/12 Geometrically, the 6th roots of i are all equally spaced points along the circle at 60◦ intervals. We are now ready to introduce the concept of complex root, by generalizing the ideas of the previous example. Let n ∈ N ∗ . Let z,w ∈ C. An n-th root of a complex number w is a complex number z such that z n = w. If w = 0, we have a unique n-th root of w, given by 0. In other words, z is an n-th root of 0 if and only if z = 0. Let us now consider w , 0. Let z ∈ C ∗ . Let θ ∈ argw and t ∈ arg z, so that we can exploit the polar representations of z and w, i.e., z = |z| e i t and w = |w| e i θ . We have z n = w if and only if |z| n e i n t = |w| e i θ , i.e. if and only if ( |z| n = |w| ∃ k ∈ Z : n t = θ + 2 k π ⇔ ( |z| n = |w| ∃ k ∈ Z : t = θ+2 k π n i.e., if and only if there exists k ∈ Z such that z = √n |w| e i θ+2 k π n . We now want to show that we can replace the condition k ∈ Z with the condition k ∈ {0, 1, . . . , n − 1}, i.e., that we do not miss any solution by Page 83 of 175 2.9 Complex numbers MATH1017 considering k ∈ {0, 1, . . . , n − 1}. For every k ∈ Z, let zk = pn |w| e i θ+2 k π n . This means that z0 = pn |w| e i θ n z1 = pn |w| e i θ+2 π n = pn |w| e i( θ n + 2 π n ) . . . zn−1 = pn |w| e i θ+2 (n−1)π n = pn |w| e i  θ n + 2 (n−1)π n  zn = pn |w| e i θ+2 nπ n = pn |w| e i( θ n + 2 nπ n ) = pn |w| e i( θ n +2 π) = z0 zn+1 = pn |w| e i θ+2 (n+1) π n = pn |w| e i( θ n + 2 π n +2 π) = z1 . . . All the solutions have the same modulus √n |w|, and they therefore located in the region S = {z ∈ C | |z| = pn |w|}. The set S is the circle centred at 0 and with radius √n |w|. An argument of z0 is θ n . Thus, z0 is the point of S such that the angle between the positive x-axis and the half-line 0 z0 (in radians) is θ n . An argument of z1 is θ n + 2 π n . Thus, z1 can be obtained by rotating the point of z0 on S by 2 π n . An argument of z2 is θ n + 2 2 π n . Thus, z2 can be obtained by rotating the point of z1 on S by 2 π n . We proceed in this way up to the point zn−1. If we construct zn by rotating the point zn−1 on S by 2 π n , we re-obtain z0. It follows that the n n-th roots z0,z1, . . . ,zn−1 of w for n > 2 are the vertexes of a regular polygon with n edges inscribed in the circle S . If n = 2, the roots z0 and z1 are symmetric with respect to the origin. z n = w √n |w| θ/n n = 7 z 2 = w √ |w| z0 z1 n = 2 Considering values of k ∈ Z greater than n − 1 (or smaller than 0) does not yield additional solutions, but only causes to determine a solution already obtained by considering k ∈ {0, 1, . . . , n − 1}. Page 84 of 175 2.9 Complex numbers MATH1017 Theorem 34 The following results hold: (i) if w = 0, (73) has only the solution z = 0 in C; (ii) If w , 0, (73) has n distinct complex solutions, given by z = pn |w| e i θ+2 k π n , k ∈ {0, . . . , n − 1}, where θ ∈ arg(w). Proof If z is a solution of (73), from (ii) in Theorem 30 |z| n = |z n | = |w|. Since |z| is a non-negative real number, we must have |z| = pn |w|. (78) In the case w = 0, we obtain |z| = 0, which implies z = 0. Let us now assume that w , 0. Let w = |w| e i θ and z = |z| e i t . We know that (78) must hold, and therefore we must only determine t. We must have |w| e i θ = z n = pn |w| e i tn = |w| e i n t . Since |w| , 0 (because w , 0), we obtain e i θ = e i n t . (79) Equation (79) implies that n t − θ is an integer multiple of 2 π, i.e., there exists k ∈ Z such that n t = θ + 2 k π. (80) Hence, t = θ + 2 k π n . It follows that z is necessarily in the form zk = pn |w| e i θ+2 k π n (81) for some k ∈ Z. Conversely, if z is in this form, we obtain z n = pn |w| e i θ+2 k π n n = |w| e i (θ+2 k π) = |w| e i θ = w. Let us now consider the complex numbers in the form (81). It is easy to see that they are not all distinct. For example, zn = pn |w| e i θ+2 n π n = pn |w| e i( θ n +2 π) = pn |w| e i θ n = z0 zn+1 = pn |w| e i θ+2 (n+1) π n = pn |w| e i( θ+2 π n +2 π) = pn |w| e i θ+2 π n = z1 z−1 = pn |w| e i θ−2 π n = pn |w| e i( θ−2 π n +2 π) = pn |w| e i θ+2 (n−1) π n = zn−1. Page 85 of 175 2.9 Complex numbers MATH1017 It is not difficult to see that, for every k ∈ Z, there exists h ∈ {0, . . . , n−1} such that zk = zh (writing k = α n+h, where α ∈ Z and h ∈ {0, . . . , n − 1}). We have therefore at most n distinct solutions: z0, . . . ,zn−1. We only need to verify that these are pairwise distinct. Let ℓ, h be integers such that 0 ≤ ℓ ≤ h ≤ n − 1. Then, zh = zℓ implies e i( θ+2 h π n ) = e i( θ+2 ℓ π n ) , and from (v) in Theorem 33 θ + 2 h π n − θ + 2 ℓ π n = 2 (h − ℓ) π n = 2 k π for some k ∈ Z. Thus, k = h − ℓ n , which implies that h−ℓ n is integer. on the other hand, 0 ≤ h − ℓ n < n n = 1 ⇒ h − ℓ n = 0 ⇒ ℓ = h. Example Consider the equation z 2 = −1. We have −1 = e i π . We obtain the two solutions z0 = e i π 2 = i and z1 = e i π+2 π 2 = e i 3 2 π = −i. Example Consider the equation z 3 = 1 − i. We have |1 − i| = √ 1 + 1 = √ 2 ⇒ 1 − i |1 − i| = 1 √ 2 − i √ 2 . We want θ such that e i θ = 1 √ 2 − i √ 2 , i.e., cos θ = 1 √ 2 and sin θ = − 1 √ 2 . We can take, for example, θ = − π 4 . We obtain the three solutions zk = √6 2 e i − π 4 +2 k π 3 , k ∈ {0, 1, 2}. We want to represent the solutions in Cartesian form. We find z0 = √6 2  cos − π 12 + i sin  − π 12 = √6 2  cos π 12 − i sin  π 12. We have cos2  π 12 = 1 + cos π 6 2 = 1 + √ 3 2 2 = 2 + √ 3 4 . Since 0 < π 12 < π 2 , we have cos π 12  > 0, so that cos π 12 = s 2 + √ 3 4 = q 2 + √ 3 2 . Similarly, since sin  π 12  > 0, we obtain sin  π 12 = q 2 − √ 3 2 . Page 86 of 175 2.9 Complex numbers MATH1017 It follows that z0 = √6 2   q 2 + √ 3 2 − i q 2 − √ 3 2   . Moreover, z1 = √6 2 e i 7 π 12 = √6 2 e i π 2 e i π 12 = √6 2 i   q 2 + √ 3 2 + i q 2 − √ 3 2   = √6 2   − q 2 − √ 3 2 + i q 2 + √ 3 2   . Finally, z2 = √6 2 e i 5 π 4 = √6 2 e i π e i π 4 = − √6 2 1 √ 2 + i √ 2 ! . z0 z1 z2 • • • √6 2 z0 = √6 2 √ 2+ √ 3 2 − i √ 2− √ 3 2 ! z1 = √6 2 − √ 2− √ 3 2 + i √ 2+ √ 3 2 ! z2 = − √6 2  1 √ 2 + i √ 2  . Remark 28 As an example on how this consideration might be useful, consider the so-called roots of unity, i.e., the solutions of the complex equation z n = 1. If n is odd, the polygon has an odd number of edges, and therefore it intersects the real axis only at 1. Then, 1 is the only real root, and we have n−1 2 pairs of distinct complex conjugate roots. If n is even, ±1 are the two real solutions because the polygon has an even number of fPage 101 of 175 3.1 Monotonic functions MATH1017 • (n+1)2  n ∈ N . The terms of the subsequence are 1, 4, 9, 16, . . ., and therefore the subsequence is the composition of the original sequence with the (strictly increasing) sequence n : N −→ N defined by ni = i + 1. Page 102 of 17 MATH1017 4 Limits, convergence, continuity We introduce the most important concept of real analysis: the notion of limit. This notion is central because other crucial notions (e.g. the notion of derivative, series and integral) are all defined in terms of limits. 4.1 Definition of Limit We begin by attempting to give an intuitive idea of the notion of limit. We want to study what happens to the following 6 functions as x gets closer and closer to 0. 3 x 3 + 2 x + 1 x 4 + 1 sin x x 1 2 + cos 1 x 1 x 2 2 π arctan 1 x 1 x x = −1 −2 0.8414709 0.5403023 1 −0.5 −1 x = −0.5 −0.3529411 0.9588510 −0.4161468 4 −0.7048327 −2 x = −0.2 0.5750798 0.9933466 0.2836621 25 −0.8743340 −5 x = −0.1 0.7969203 0.9983341 −0.8390715 100 −0.9365489 −10 x = −0.05 0.8996193 0.9995833 0.4080820 400 −0.9681954 −20 x = −0.02 0.9599758 0.9999333 0.9649660 2500 −0.9872693 −50 x = −0.01 0.9799969 0.9999833 0.8623188 10000 −0.9936340 −100 x = −0.001 0.9979999 0.9999998 0.5623790 1000000 −0.9993633 −1000 x = −0.0001 0.9997999 0.9999999 −0.9521553 100000000 −0.9999363 −10000 x = 0.0001 1.0002000 0.9999999 −0.9521553 100000000 0.9999363 10000 x = 0.001 1.0020000 0.9999998 0.5623790 1000000 0.9993633 1000 x = 0.01 1.0200029 0.9999833 0.8623188 10000 0.9936340 100 x = 0.02 0.02 0.9999333 0.9649660 2500 0.9872693 50 x = 0.05 1.1003681 0.9995833 0.4080820 400 0.9681954 20 x = 0.1 1.2028797 0.9983341 −0.8390715 100 0.9365489 10 x = 0.2 1.4217252 0.9933466 0.2836621 25 0.8743340 5 x = 0.5 2.2352941 0.9588510 −0.4161468 4 0.7048327 2 x = 1 3 0.8414709 0.5403023 1 0.5 1 We notice a remarkable difference in behaviour as x approaches 0. The first function gets closer and closer to the value 1 as x tends to 0, both from the left and from the right. It is not a coincidence, as we will see that 1 is also the value that the function takes at x = 0. The second function also wants to approach the value 1 as x approaches 0 from the left and from the right. However, in this case we certainly cannot claim that this value is the value the function takes at x = 0, because at x = 0 the function is not even defined! The third function does not seem to have a pattern that we can easily recognize. In fact, as x moves towards 0 from the left and from the right, we continue to have a behavior that looks oscillatory. This is a case where the limit does not exist. The fourth case is also an example of a limit that does not exist. In this case it is not, however, because of an oscillatory behavior, but, rather, because the function tends to increase unboundedly as x approaches zero In the fifth case the function does not have a limit because, approaching zero from the left and from the right gives two different behaviors for the values of the function. In the last case, the function tends to Page 103 of 175 4.1 Definition of Limit MATH1017 approach −∞ if we approach 0 from the left and +∞ if we approach 0 from the right. x y 1 −1 3 −2 x y −1 1 1 x y −1 1 1 x y −1 1 1 x y 1 −1 1 −1 x y 1 −1 1 In the first two cases, we can say that the limit (as x goes to 0) exists (in R) and it is equal to 1, and this is true whether or not the function is defined at x = 0. In the fourth case, we can say that the limit as x → 0 is +∞, because, regardless of the direction along which x approaches 0, the function tends to “diverge” to +∞. In the fifth case, the “left limit” is equal to −1 and the “right limit” is equal to +1: indeed, in this case, the value to which f(x) tends as x → 0 depends on the direction that we choose to approach 0. This is also true in the last case, even if in this case the “left limit” is equal to −∞ and the “right limit” is equal to +∞. Even if in all the last three cases the limit does not exist in R, we can say that the limit exists in R = [−∞, +∞], which is also known as “extended real line”. The case for which the limit cannot be defined to exist is the third: the behavior of the function as x gets closer to 0 cannot be captured in any meaningful way. How did we choose 0 as a value on the x-axis in a neighborhood of which we wanted to study the behavior of the graph? Consider for example the behavior of the function f : R ∗ + −→ R that maps x into f(x) = log2 (x), as x approaches the point −1. Since in a small interval around −1 the function is not defined, it should not make any sense to find the limit as x approaches −1. This begs the question: for which values of x0 does it make sense to study the behavior of a function as x approaches x0? It is not enough to choose x0 to belong to the Page 104 of 175 4.1 Definition of Limit MATH1017 domain of f , because, as we have seen, it makes sense to find the limit of sin x x as x → 0 (i.e., as x tends to 0) even if the function is not defined at x = 0. However, we can study the behavior of the function around x0 only when x can approach x0 while remaining in the domain (i.e., while remaining in a range of points where the function is defined). This leads to the notion of “limit point” (or “accumulation point”): we will only define the notion of limit for accumulation points of a function, and an accumulation point is – loosely speaking – a point that x can reach while remaining in the domain. We begin by giving the definition of accumulation point. Let x0 ∈ R and r ∈ R ∗ + . We define Br(x0) def = {x ∈ R | |x − x0| < r} (91) = {x ∈ R | x0 − r < x < x0 + r}. The set Br(x0) is called “ball” centred at x0 with radius r. Definition 28 Let A ⊆ R and x0 ∈ R. We say that x0 is an accumulation point or limit point for A if, for all r > 0, the set A ∩ Br(x0) contains some elements distinct from x0, i.e., ∀ r > 0, ∃ x ∈ A ∩ Br(x0) : x , x0. The set of limit points of A is denoted by D(A), and it is called derived set of A. The condition in Definition 28 can be written in an equivalent way as ∀ r > 0, A ∩ Br(x0)  \ {x0} , ∅. Example Recall the definition of intervals (2-9). Let a < b. Then D [a, b)  = [a, b]. In fact, let x0 < a. Then, x0 < D [a, b)  . Indeed, if 0 < r < a − x0, we have (x0 − r, x0 + r) ∩ [a, b) = ∅. Let x0 > b. Then, x0 ∈ D [a, b)  . Indeed, if 0 < r < x0 − b, then (x0 − r, x0 + r) ∩ [a, b) = ∅. Let a ≤ x0 < b. Then, x0 ∈ D [a, b)  . Indeed, let r > 0. If r ≤ b − x0, we can take x = x0 + r 2 ; then x ∈ Br(x0) = (x0 − r, x0 + r) and it is different from x0. Moreover, a ≤ x0 < x = x0 + r 2 ≤ x0 + b − x0 2 < x0 + (b − x0) = b. It follows that x ∈ [a, b). If r > b − x0, take r1 > 0 with r1 ≤ b − x0. Then, from the previous argument, there exists x distinct from x0 and which belongs to [a, b) ∩ Br1 (x0). Since Br1 (x0) ⊆ Br(x0), then x also belongs to [a, b) ∩ Br(x0). Finally, we show that b ∈ D [a, b)  , Let r > 0. If r ≤ b − a, then x = b − r 2 is distinct from b, and it belongs to [a, b) ∩ Br(x0) = [a, b) ∩ (x0 − r, x0 + r). If r > b − a, we repeat the same argument above: we take r1 > 0 with r1 ≤ b − a and we take x in [a, b) ∩ Br1 (b) = [a, b) ∩ (b − r1, b + r1) distinct from b. Then, x ∈ [a, b) ∩ Br(b). We also give the definition of “isolated point”. Definition 29 Let A ⊆ R and x0 ∈ A. We say that x0 is an isolated point of A if there exists r > 0 such that A ∩ Br(x0) = {x0}, i.e., ∃ r > 0 : A ∩ Br(x0) = {x0}. (92) Page 105 4.1 Definition of Limit MATH1017 Clearly, an isolated point of A cannot be a limit point of A, because (92) says that it is not true that for every r > 0 the set A ∩ Br(x0) contains other points of A other than x0. Example Let a, b, c ∈ R and let a < b < c. Let A = [a, b) ∪ {c}. The point c is an isolated point. In fact, for every r ∈ (0, c − b), the ball Br(c) contains only one element of A: the point c. Using the same arguments of the previous exercise, it is easy to see that D(A) = [a, b]. Example We show that D(N) = ∅. Let x0 ∈ R. If x0 < 0, we take r > 0, and r ≤ −x0. Then, N∩Br(x0) = N∩(x0−r, x0+r) = ∅. Let x0 ∈ N and 0 < r ≤ 1. Then, N ∩ Br(x0) = N ∩ (x0 − r, x0 + r) = {x0}. This intersection does not contain elements which are distinct from x0. Let x0 > 0 and x0 < N. Then, there exists p ∈ N such that p < x0 < p + 1. We take 0 < r < min{x0 − p, p + 1 − x0}. Then, N ∩ Br(x0) = ∅. We are ready to present the definition of limit. Definition 30 Let A ⊆ R. Let f : A −→ R. Let x0 ∈ D(A) and ℓ ∈ R. We write lim x → x0 f(x) = ℓ (93) if ∀ ε > 0, ∃ δ > 0 : ∀ x ∈ A \ {x0}, |x − x0| < δ ⇒ | f(x) − ℓ| < ε We will say that “ f tends to ℓ as x tends to x0”. If (93) holds, we also say that f is “convergent as x tends to x0”. The condition in Definition 30 can be written in a number of different ways. For example, ∀ ε > 0, ∃ δ > 0 : ∀ x ∈ A ∩ Bδ(x0)  \ {x0}, f(x) ∈ Bε(ℓ) or ∀ ε > 0, ∃ δ > 0 : ∀ x ∈ A, 0 < |x − x0| < δ ⇒ | f(x) − ℓ| < ε Remark 30 The meaning of Definition 30 is the following: as x approaches x0, the value of the function f(x) approaches ℓ. More precisely, f(x) can be made as close as ℓ as we desire, by making x sufficiently close to x0. This last statement can be made precise by saying that, chosen an arbitrary ε > 0, it is always possible to determine δ > 0 (which in general depends on ε) such that, if x ∈ Bδ(x0) ∩ A and x , x0, then f(x) ∈ Bε(ℓ). We stress the fact that Definition 30 requires x , x0. a It also requires x0 to be a limit point.b a If this is not the case, then |x − x0| = 0 < δ is always satisfied for x = x0, and therefore using x = x0 in | f(x) − ℓ| < ε we obtain | f(x0)−ℓ| < ε. Saying that for every ε > 0 the inequality | f(x0)−ℓ| < ε holds is a fancy way of saying that f(x0) = ℓ, which is too restrictive. bFirst, it seems silly to consider points that are not close to the domain: think about the limit of the function f(x) = log x, as x → −1: it makes little sense to study the behaviour of the logarithm close to x0 = −1. But the real problem is that in this case every ℓ is a limit. In fact, choosing δ < 1 2 , the set A \ {−1} = R ∗ + does not contain points x such that |x − x0| < δ, and therefore we will not be able to find x for which the condition in Definition 30 is false, which means that any ℓ is the limit. Page 106 of 17 4.1 Definition of Limit MATH1017 Consider a function like the one shown below, which has a very regular, smooth graph: x y x0 δ δ ε ε ℓ If we want f(x) to be as close to ℓ as we like, we need x to be sufficiently close to x0. If the function has a jump at x0, as x approaches x0, then f(x) cannot be made arbitrarily close to a specific value by choosing x to be sufficiently close to x0: x0 ℓ δ δ ε ε In this case the limit does not exist. However, we will see that we have a left limit and a right limit, and they do not coincide. Example Let a, b ∈ R. Consider the so-called affine function f : R −→ R x 7→ a x + b. We notice that D(R) = R. Indeed, given x0 ∈ R and r > 0, we have x0 + r 2 ∈ Br(x0) = (x0 − r, x0 + r), and it is distinct from x0. We verify that lim x → x0 f(x) = a x0 + b. First, suppose a = 0. In this case, f is constant: ∀ x ∈ R, we have f(x) = b. Thus, | f(x) − b| = 0 for all x ∈ R. Let therefore ε > 0. Given any δ > 0, for every x ∈ Bδ(x0) and x , x0 we find | f(x) − b| = 0 < ε. Page 107 of 175 4.1 Definition of Limit MATH1017 Therefore, in this special case δ can be chosen arbitrarily. Let a , 0. Let ε > 0. Then | f(x) − a x0 − b| < ε ⇔ |a x + ✁b − a x0 − ✁b| < ε ⇔ |a (x − x0)| < ε ⇔ |x − x0| < ε |a| = δ. (the inequality holds also for x = x0, but this is irrelevant). Hence, given an arbitrary ε > 0, we found a value of δ dependent upon ε (and this value is equal to ε |a| ) such that, if |x − x0| < δ, we are guaranteed that | f(x) − ℓ| < ε. Example Consider the function f : R −→ R defined by x y f(x) = • ( 0 if x , 0 1 if x = 0. We show that lim x → 0 f(x) = 0. Let ε > 0. If δ > 0, given x ∈ Bδ(0) with x , 0, we have | f(x) − 0| = 0 < ε. Therefore, this is another special example where δ can be chosen arbitrarily. In this example we notice that the condition x , x0 in the definition of limit is essential. If we drop it, we would have in this case ∀ ε > 0, ∃ δ > 0 : ∀ x ∈ R, |x − x0| < δ ⇒ | f(x) − ℓ| < ε. If x is allowed to be equal to x0, then |x − x0| = 0 < δ is always satisfied, and therefore the inequality | f(x) − ℓ| < ε must hold for x = x0 as well. However, in this case this inequality becomes, at x0 = 0, equal to |1−0| < ε, which says that ε cannot be chosen arbitrarily small. Example Consider the so-called sign function (or signum function) f : R −→ R defined by x y • 1 −1 f(x) =    −1 if x < 0 1 if x > 0 0 if x = 0 We show that the limit as x → 0 does not exist. Suppose by contradiction that ℓ ∈ R exists which satisfies Definition 30. Let ε = 1. Then, there exists δ > 0 such that, for all x ∈ Bδ(0) with x , 0 there holds | f(x) − ℓ| < 1. In particular, this inequality is satisfied for x = δ 2 and for x = − δ 2 . Therefore, 2 =      f  δ 2  − f  − δ 2      =       f  δ 2  − ℓ  −  f  − δ 2  − ℓ      ≤      f  δ 2  − ℓ      +      f  − δ 2  − ℓ      < 1 + 1 = 2. We obtained 2 < 2, which is a contradiction. Remark 31 We have seen that the limit as x approaches a limit point x0 might not exist. Notice that there is a difference between saying that the limit does not exist (as in the previous example) and saying Page 108 of 175 4.1 Definition of Limit MATH1017 that the limit is not defined. For example, the limit lim x → −1 log2 (x) is ill defined, because −1 is not a limit point for the domain of the function log2 . We can say also that we cannot write this limit, or that this limit does not make sense. The difference between these two situations mirrors what happens with equations: the equation x 2 + 1 = 0 does not have real solutions, whereas the equation x 0 + 5 = 0 is ill-defined. 4.1.1 Uniqueness of the limit We are not authorised to call ℓ in (93) the limit (but only a limit), until the following result of uniqueness is established. Theorem 35 [Uniqueness of the Limit] Let A ⊆ R. Let f : A −→ R. Let x0 ∈ D(A) and ℓ1, ℓ2 ∈ R are such that lim x → x0 f(x) = ℓ1 and lim x → x0 f(x) = ℓ2. Then, ℓ1 = ℓ2. Proof Suppose by contradiction that ℓ1 , ℓ2, so that |ℓ1 − ℓ2| 3 > 0. Let us take ε = |ℓ1−ℓ2| 3 . Therefore, we can use Definition 30 with this value of ε, and we find that there exists δ1 > 0 such that ∀ x ∈ A \ {x0} |x − x0| < δ1 ⇒ | f(x) − ℓ1| < ε. Likewise, there exists δ2 > 0 such that ∀ x ∈ A \ {x0} |x − x0| < δ2 ⇒ | f(x) − ℓ2| < ε. Taking |x − x0| < min{δ1, δ2}, the inequalities | f(x) − ℓ1| < ε and | f(x) − ℓ2| < ε hold simultaneously. Thus, using the triangle inequality 3 ε = |ℓ1 − ℓ2| = |ℓ1 − f(x) + f(x) − ℓ2| ≤ |ℓ1 − f(x)| + | f(x) − ℓ2| = | f(x) − ℓ1| + | f(x) − ℓ2| < 2 ε. From 3 ε < 2 ε, recalling that ε > 0, we obtain 3 < 2, which is false. Theorem 36 [Sign Permanence] Let A ⊆ R. Let f : A −→ R. Let x0 ∈ D(A) and ℓ ∈ R, and such that lim x → x0 f(x) = ℓ. Let ℓ ′ , ℓ′′ ∈ R with ℓ ′ < ℓ < ℓ′′. Then, there exists δ > 0 such that for all A ∩ Bδ(x0) different from x0 there holds ℓ ′ < f(x) < ℓ′′. In symbols ∃ δ > 0 : ∀ x ∈ A ∩ Bδ(x0), x , x0 ⇒ ℓ ′ < f(x) < ℓ′′ . Proof Let ε > 0 be such that ℓ ′ < ℓ − ε < ℓ + ε < ℓ′′ (it is sufficient to choose ε to satisfy 0 < ε < min{ℓ − ℓ ′ , ℓ′′ − ℓ}). Page 109 of 175 4.1 Definition of Limit MATH1017 Then, there exists δ > 0 such that for all x ∈ A ∩ Bδ(x0)  \ {x0} there holds | f(x) − ℓ| < ε, which implies ℓ ′ < ℓ − ε < f(x) < ℓ + ε < ℓ′′ , which leads to the conclusion. The previous result holds also if we have only ℓ ′ or ℓ ′′. For example, suppose that we know that ℓ > 0, and we want to show that there exists δ > 0 such that for all x ∈ A ∩ Bδ(x0)  \ {x0} we have f(x) > 0. Then, we take ℓ ′ = 0, and choosing 0 < ε < ℓ we immediately see that there exists δ > 0 such that for all x ∈ A ∩ Bδ(x0)  \ {x0} we have 0 < ℓ − ε < f(x) < ℓ + ε. We also have the following corollary. Theorem 37 Let A ⊆ R. Let f : A −→ R. Let x0 ∈ D(A) and ℓ ∈ R, and such that lim x → x0 f(x) = ℓ. Let m ∈ R. Then: ∀ x ∈ A, f(x) ≤ m ⇒ ℓ ≤ m; ∀ x ∈ A, f(x) ≥ m ⇒ ℓ ≥ m. Proof Assume f(x) ≤ m for all x ∈ A, Suppose by contradiction that ℓ > m. Let us take ℓ ′ ∈ (m, ℓ) (i.e., m < ℓ′ < ℓ). From Theorem 36, there exists δ > 0 such that for all x ∈ A ∩ Bδ(x0)  \ {x0} there holds ℓ ′ < f(x) < ℓ, and for these values of x we have in particular f(x) > ℓ′ > m, and this is a contradiction. The case f(x) ≥ m for all x ∈ A can be dealt with similarly. Theorem 38 Let A ⊆ R. Let f, g : A −→ R. Let x0 ∈ D(A) and ℓ, m ∈ R, and such that lim x → x0 f(x) = ℓ and lim x → x0 g(x) = m. Then: (i) the limit lim x → x0 f(x) + g(x)  exists and it is equal to ℓ + m; (ii) the limit lim x → x0 f(x) g(x)  exists and it is equal to ℓ m; (iii) if g(x) , 0 for all x ∈ A and m , 0, then lim x → x0 f(x) g(x) exists and it is equal to ℓ m . Proof (i). Let ε > 0. We have to show that there exists δ > 0 such that, for every x ∈ A ∩ Bδ(x0)  \ {x0}, there holds |(f + g)(x) − (ℓ + m)| < ε, i.e.,    f(x) + g(x)  − (ℓ + m)    < ε. Since lim x → x0 f(x) = ℓ, there exist δ1 > 0 such that, if x ∈ A ∩ Bδ1 (x0) and x , x0, then | f(x) − ℓ| < ε 2 . Likewise, since lim x → x0 g(x) = m, there exists δ2 > 0 such that x ∈ A ∩ Bδ2 (x0) and x , x0, then |g(x) − m| < ε 2 . Let δ = min{δ1, δ2}. We want to show that this δ does the job. We have the chain of implications δ ≤ δ1 ⇒ Bδ(x0) ⊆ Bδ1 (x0) ⇒ Bδ(x0) ∩ A ⊆ Bδ1 (x0) ∩ A ⇒ Bδ(x0) ∩ A  \ {x0} ⊆ Bδ1 (x0) ∩ A  \ {x0}. Page 4.1 Definition of Limit MATH1017 Likewise, δ ≤ δ2 ⇒ Bδ(x0) ⊆ Bδ2 (x0) ⇒ Bδ(x0) ∩ A ⊆ Bδ2 (x0) ∩ A ⇒ Bδ(x0) ∩ A  \ {x0} ⊆ Bδ2 (x0) ∩ A  \ {x0}. Hence, if x ∈ A ∩ Bδ(x0)  \ {x0}, it follows also that x ∈ A ∩ Bδ1 (x0)  \ {x0} and x ∈ A ∩ Bδ2 (x0)  \ {x0}, so that for these values of x the inequalities | f(x) − ℓ| < ε 2 and |g(x) − m| < ε 2 hold simultaneously. Using the triangle inequality, we find    f(x) + g(x)  − (ℓ + m)    =    f(x) − ℓ  + g(x) − m     ≤    f(x) − ℓ    +   g(x) − m    < ε 2 + ε 2 = ε, as required. We now prove (ii). We have to show that there exists δ > 0 such that, for every x ∈ A ∩ Bδ(x0)  \ {x0}, there holds |(f g)(x) − ℓ m| < ε, i.e., | f(x) g(x) − ℓ m| < ε. Let ε > 0. Let M > 0 be such that −M < m < M. From Theorem 36, there exists δ1 > 0 such that for all x ∈ A ∩ Bδ1 (x0)  \ {x0} we have −M < g(x) < M, which can be re-written as |g(x)| < M. With this choice of x, using the triangle inequality we have | f(x) g(x) − ℓ m| =    f(x) − ℓ  g(x) + ℓ g(x) − m     ≤ | f(x) − ℓ| |g(x)| + |ℓ| |g(x) − m| ≤ M | f(x) − ℓ| + |ℓ| |g(x) − m|. Let η > 0. From lim x → x0 f(x) = ℓ and lim x → x0 g(x) = m, we know that there exist δ2 > 0 and δ3 > 0 such that: • ∀ x ∈ A ∩ Bδ2 (x0)  \ {x0}, | f(x) − ℓ| < η; • ∀ x ∈ A ∩ Bδ3 (x0)  \ {x0}, |g(x) − m| < η. If δ = min{δ1, δ2, δ3} and x ∈ A ∩ Bδ(x0)  \ {x0}, then | f(x) g(x) − ℓ m| ≤ M | f(x) − ℓ| + |ℓ| |g(x) − m| ≤ (M + |ℓ|) η. Let us choose η such that (M + |ℓ|) η < ε (or, equivalently, η < ε M+|ℓ| ), so that for all x ∈ A ∩ Bδ(x0)  \ {x0} we have | f(x) g(x) − ℓ m| < ε. (iii). Since f(x) g(x) = f(x) · 1 g(x) , from (ii) we can limit ourselves to considering the case where f(x) = 1 for all x ∈ A (why?). Thus, we have to show that ∀ ε > 0, ∃ δ > 0 : ∀ x ∈ Bδ(x0) ∩ A  \ {x0},      1 g(x) − 1 m      = |g(x) − m| |g(x)| |m| < ε. Let ε > 0. We now use Theorem 36. Since m = lim x → x0 g(x), we can define m ′ = m − |m| 2 and m ′′ = m + |m| 2 , so that m ′ < m < m ′′. Hence, Theorem 36 guarantees that there exists δ1 > 0 such that for all x ∈ Bδ1 (x0) ∩ A  \ {x0} there holds m ′ < g(x) < m ′′ ⇔ m − |m| 2 < g(x) < m + |m| 2 ⇔ − |m| 2 < g(x) − m < |m| 2 ⇔ |g(x) − m| < |m| 2 . Then, for all x ∈ Bδ1 (x0) ∩ A  \ {x0} |m| =    m − g(x)  + g(x)    ≤ |m − g(x)| + |g(x)| < |m| 2 + |g(x)| ⇒ |g(x)| > |m| 2 . With this choice of x we find      1 g(x) − 1 m      = |g(x) − m| |g(x)| |m| < 2 |g(x) − m| m2 4.1 Definition of Limit MATH1017 Again, since m = lim x → x0 g(x), there exists δ2 > 0 such that, for all x ∈ A ∩ Bδ2 (x0)  \ {x0} we have |g(x) − m| < m 2 ε 2 . Then, if δ = min{δ1, δ2}, and for x ∈ A ∩ Bδ(x0)  \ {x0}, we have      1 g(x) − 1 m      < 2 |g(x) − m| m2 < 2 m2 m 2 ε 2 = ε. Example We have shown that lim x → x0 (a x + b) = a x0 + b. Applying Theorem 38 repeatedly, it is easy to se that, if P : R −→ R is a polynomial function, then for all x0 ∈ R the limit lim x → x0 P(x) exists and it is equal to P(x0). Theorem 39 Let a ∈ R. • If a > 0, let ga : [0, +∞) −→ R x 7→ x a . Then, for all x0 ∈ [0, +∞), we have lim x → x0 ga(x) = ga(x0). • If a < 0, let ga : (0, +∞) −→ R x 7→ x a . Then, for all x0 ∈ (0, +∞), we have lim x → x0 ga(x) = ga(x0). Partial proof We prove the result for a > 0 and x0 = 0. Since ga(0) = 0, we must show that, for all ε > 0, there exists δ > 0 such that, for all x ∈ [0, +∞) ∩ Bδ(0) different from x0, there holds −ε < x a < ε. (94) The first inequality in (94) is satisfied for all x > 0, since x a > 0 > −ε. Since a > 0, also 1/a > 0, and the function x 7→ x 1 a is strictly increasing, so that the inequality x a < ε is satisfied if 0 < x < ε1/a . Thus, we can take δ = ε 1/a . We can write the result of Theorem 39 as lim x → x0 x a = x a f0 . Remark 32 Notice that D [0, +∞)  = D (0, +∞)  = [0, +∞). We will not prove the following two results. Page 112 of 4.1 Definition of Limit MATH1017 Theorem 40 Let a ∈ R ∗ + . Let fa : R −→ R x 7→ a x . Then, for all x0 ∈ R, we have lim x → x0 fa(x) = fa(x0). We can write the result of Theorem 40 as lim x → x0 a x = a x0 . Theorem 41 Let a ∈ R ∗ + and a , 1. Let ha : R ∗ + −→ R x 7→ loga (x). Then, for all x0 ∈ R ∗ + , we have lim x → x0 ha(x) = ha(x0). We can write the result of Theorem 41 as lim x → x0 loga (x) = loga (x0). Theorem 42 For all x ∈ R, |sin x| ≤ |x|. Proof Let x ∈ h 0, π 2  . Recall that in a right triangle the length of any of the two catheti is smaller than the length of the hypotenuse, so that sin x ≤ |e i x − 1|. 1 • e i x • Since the length of the arc with end-points 1 and e i x is x, we find also |e i x − 1| ≤ x. The result has been proved for x ∈ h 0, π 2  . It also holds for x ≥ π 2 , since |sin x| ≤ 1 ≤ π 2 ≤ x. Page 113 of 175 4.1 Definition of Limit MATH1017 We need to prove it for x < 0, and we will exploit what we found for the case x > 0. Since the sine is odd, if x < 0 |sin x| = |sin(−x)| ≤ −x = |x|. Theorem 43 Let x0 ∈ R. Then lim x → x0 cos x = cos(x0) and lim x → x0 sin x = sin(x0), Proof From (i) in Theorem 32, Theorem 42 and the fact that |sin(x)| ≤ 1 for all x ∈ R, we find that for all x ∈ R | cos x − cos(x0)| =      −2 sin x + x0 2 sin x − x0 2      ≤ 2 · 1 ·      x − x0 2      = |x − x0|. Let ε > 0. Thus, if |x − x0| < ε and x , x0, | cos x − cos(x0)| ≤ |x − x0| < ε. The other can be proved in a similar way (try!). 4.1.2 Limit equal to ±∞ Definition 31 Let A ⊆ R. Let f : A −→ R and x0 ∈ D(A). We write lim x → x0 f(x) = +∞ and we say that f diverges to +∞ or that f tends to +∞ as x → x0 if ∀ M ∈ R, ∃ δ > 0 : ∀ x ∈ A \ {x0}, |x − x0| < δ ⇒ f(x) > M. (95) Remark 33 As x gets closer to x0, the value of the function f(x) becomes greater than any pre-assigned value M. In other words, if we fix M arbitrarily, provided we choose x sufficiently close to x0, f(x) is greater than M. Notice that we can write (95) alternatively as ∀ M ∈ R, ∃ δ > 0 : ∀ x ∈ A, 0 < |x − x0| < δ ⇒ f(x) > M or ∀ M ∈ R, ∃ δ > 0 : ∀ x ∈ A ∩ Bδ(x0)  \ {x0}, f(x) > M, or ∀ M ∈ R, ∃ δ > 0 : ∀ x ∈ A, 0 < |x − x0| ≤ δ ⇒ f(x) ≥ M Page 114 of 17 4.1 Definition of Limit MATH1017 or ∀ M > 0, ∃ δ > 0 : ∀ x ∈ A, 0 < |x − x0| < δ ⇒ f(x) > M. Definition 32 Let A ⊆ R. Let f : A −→ R and x0 ∈ D(A). We write lim x → x0 f(x) = −∞ and we say that f diverges to −∞ or that f tends to −∞ as x → x0 if ∀ M ∈ R, ∃ δ > 0 : ∀ x ∈ A \ {x0}, |x − x0| < δ ⇒ f(x) < M. (96) Example Consider the function x y f : R ∗ + −→ R x 7→ x −1 We show that lim x → 0 f(x) = +∞. Let M ∈ R. If M ≤ 0, then f(x) > M for all x ∈ R ∗ + . In this case we can take δ to be any arbitrary positive quantity. If M > 0, then f(x) > M if and only if 0 < x < M−1 . A possible choice of δ is therefore δ = M−1 , since BM−1 (0) ∩ R ∗ + = (0, M−1 ). Example Consider the function x y f : (−∞, 0) −→ R x 7→ x −1 We show that lim x → 0 f(x) = −∞. Let M ∈ R. If M ≥ 0, then f(x) < M for all x ∈ (−∞, 0). In this case we can take δ to be any arbitrary positive quantity. If M < 0, then f(x) < M if and only if M−1 < x < 0. A possible choice of δ is therefore δ = |M−1 |, since B|M−1 | (0) ∩ (−∞, 0) = (M−1 , 0). The first of these two examples can be generalised as follows. Page 115 of 175 4.1 Definition of Limit MATH1017 Theorem 44 Let a ∈ R and a < 0. Let ga : (0, +∞) −→ R x 7→ x a . Then, lim x → 0 ga(x) = +∞. We now consider the logarithms. Theorem 45 Let a ∈ R ∗ + and a , 1. Then: (i) if a > 1, we have lim x → 0 loga (x) = −∞; (ii) if 0 < a < 1, we have lim x → 0 loga (x) = +∞. Proof Consider (ii). Let M ∈ R. When do we have loga (x) > M? We have loga (x) = M if x = a M. Since loga is decreasing, we have loga (x) > M if x ∈ (0, a M). We can take δ = a M. We introduce the following notation, where ±∞ are thought of as two distinct objects which do not belong to R, and which satisfy ∀ a ∈ R, −∞ < a < +∞. Definition 33 We define the “extended real” line as [−∞, +∞] def = R ∪ {−∞, +∞}. (97) We also use the symbol R def = [−∞, +∞]. It is convenient, sometimes, to treat ±∞ as if they were real numbers. However, we must pay a lot of attention to this! Remark 34 If the limit of f is equal to +∞ or −∞, we have said previously that the limit does not exist. Now, we want to be more specific. We say that the limit exists in R (but it still does not exist in R). Hence, whenever we talk about existence or non-existence of a limit, we should always specify if we mean that the limit is allowed to exist in R. With these conventions, the theorem of uniqueness of the limit (Theorem 35) can be generalized as follows. Theorem 46 [Uniqueness of the Limit] Let A ⊆ R. Let f : A −→ R. Let x0 ∈ D(A) and ℓ1, ℓ2 ∈ R are such that lim x → x0 f(x) = ℓ1 and lim x → x0 f(x) = ℓ2. Page 116 of 175 4.1 Definition of Limit MATH1017 Then, ℓ1 = ℓ2. We are not proving this result because we are going to prove the uniqueness in an even more general framework in Theorem 53. Theorem 38 can be complemented as follows. Theorem 47 Let A ⊆ R. Let f, g : A −→ R. Let x0 ∈ D(A) and ℓ ∈ R, and such that lim x → x0 f(x) = ℓ. Then: (i) if ℓ ∈ (−∞, +∞] and lim x → x0 g(x) = +∞, then the limit lim x → x0 f(x) + g(x)  exists and it is equal to +∞; (ii) if ℓ ∈ [−∞, +∞) and lim x → x0 g(x) = −∞, then the limit lim x → x0 f(x)+g(x)  exists and it is equal to −∞. Partial proof Consider for example the case where ℓ ∈ R and m = +∞. We need to show that lim x → x0 f(x) + g(x)  exists in R and it is equal to +∞, i.e., ∀ M ∈ R, ∃ δ > 0 : ∀ x ∈ Bδ(x0) ∩ A  \ {x0} ⇒ f(x) + g(x) > M. (98) Let M ∈ R. Since lim x → x0 f(x) = ℓ ∈ R, there exists λ ∈ R such that ℓ > λ, and so from Theorem 36 that there exists δ1 > 0 such that, for all x ∈ Bδ1 (x0) ∩ A  \ {x0}, we have f(x) > λ. Moreover, since lim x → x0 g(x) = +∞, there exists δ2 > 0 such that, for all x ∈ Bδ2 (x0) ∩ A  \ {x0}, there holds g(x) > M − λ. Taking δ = min{δ1, δ2}, for all x ∈ Bδ(x0) ∩ A  \ {x0}, f(x) + g(x) > µ + M − µ = M. The case where ℓ = +∞ is even simpler: we still need to show (98), and we fix M ∈ R. Take an arbitrary M1 ∈ R. Since ℓ = +∞, ∃ δ1 > 0 : ∀ x ∈ Bδ1 (x0) ∩ A  \ {x0} ⇒ f(x) > M1. Take M2 = M − M1, and since lim x → x0 f(x) = +∞, ∃ δ2 > 0 : ∀ x ∈ Bδ2 (x0) ∩ A  \ {x0} ⇒ g(x) > M2 = M − M1. Choosing δ = min{δ1, δ2}, ∀ x ∈ Bδ1 (x0) ∩ A  \ {x0} ⇒ f(x) + g(x) < M1 + M − M1 = M. These results can be visualised with the following table, where the question mark says that the knowledge of ℓ and m does not allow us to get to any conclusion about the limit of the sum. m = −∞ −∞ < m < +∞ m = +∞ ℓ = −∞ −∞ −∞ ? −∞ < ℓ < +∞ −∞ ℓ + m +∞ ℓ = +∞ ? +∞ +∞ We now consider the product. Page 4.1 Definition of Limit MATH1017 Theorem 48 Let A ⊆ R. Let f, g : A −→ R. Let x0 ∈ D(A) and ℓ, m ∈ R, and such that lim x → x0 f(x) = ℓ and lim x → x0 g(x) = m. Then: (i) if 0 < ℓ ≤ +∞ and m = +∞, the limit lim x → x0 f(x) g(x) exists in R and it is equal to +∞; (ii) if −∞ ≤ ℓ < 0 and m = +∞, the limit lim x → x0 f(x) g(x) exists in R and it is equal to −∞; (iii) if 0 < ℓ ≤ +∞ and m = −∞, the limit lim x → x0 f(x) g(x) exists in R and it is equal to −∞; (iv) if −∞ ≤ ℓ < 0 and m = −∞, the limit lim x → x0 f(x) g(x) exists in R and it is equal to +∞. Partial proof We prove that lim x → x0 f(x) = ℓ > 0 and lim x → x0 g(x) = +∞, then lim x → x0 f(x) g(x) = +∞. We have to show that for all M ∈ R there exists δ > 0 such that, for all x ∈ Bδ(x0) ∩ A  \ {x0}, we have f(x) g(x) > M. Let M ∈ R. Since ℓ > 0 and lim x → x0 f(x) = ℓ, there exists δ1 > 0 such that, for all x ∈ Bδ1 (x0) ∩ A  \ {x0}, we have | f(x) − ℓ| < ℓ 2 , which is equivalent to − ℓ 2 < f(x) − ℓ < ℓ 2 , so that in particular f(x) > ℓ 2 . Since g is positively divergent as x → x0, there exists δ2 of x0 such that, for all x ∈ Bδ2 (x0) ∩ A  \ {x0}, we have g(x) > 2 M ℓ . Taking δ = min{δ1, δ2}, for all x ∈ Bδ(x0) ∩ A  \ {x0}, we have f(x) g(x) > ℓ 2 · 2 M ℓ = M. If, instead, ℓ < 0, we take ε = − ℓ 2 , and there exists δ1 > 0 such that, for all x ∈ Bδ1 (x0)∩A  \ {x0}, we have | f(x)−ℓ| < − ℓ 2 , which is equivalent to 3 2 ℓ < f(x) < ℓ 2 < 0. Defining as above δ, we find that for all x ∈ Bδ(x0) ∩ A  \ {x0} f(x) < ℓ 2 and g(x) > 2 M ℓ . Since f(x) < 0, we have g(x) > 2 M ℓ ⇒ f(x) g(x) < f(x) 2 M ℓ < ℓ 2 2 M ℓ = M. Now, we prove that if ℓ = +∞ and m = −∞, then f g is convergent w.r.t. R and lim x → x0 f(x) g(x) = −∞. Hence, we show that ∀ M < 0, ∃ δ > 0 : ∀ x ∈ A \ {0}, |x − x0| < δ ⇒ f(x) g(x) < M. Since (1, +∞) is a neighborhood of ℓ, there exists δ1 > 0 such that for all x ∈ Bδ1 (x0)∩A  \{0}, we have f(x) ∈ (1, +∞), i.e., f(x) > 1. Since lim x → x0 g(x) = −∞, there exists δ2 > 0 such that for all x ∈ Bδ2 (x0) ∩ A  \ {0}, we have g(x) < M. Thus, defining δ = min{δ1, δ2}, for all x ∈ Bδ(x0) ∩ A  \ {0}, we have f(x) g(x) < f(x) M < M, since M < 0. Page 1 4.1 Definition of Limit MATH1017 For the product, we have the table m = −∞ −∞ < m < 0 m = 0 0 < m < +∞ m = +∞ ℓ = −∞ +∞ +∞ ? −∞ −∞ −∞ < ℓ < 0 +∞ ℓ m 0 ℓ m −∞ ℓ = 0 ? 0 0 0 ? 0 < ℓ < +∞ −∞ ℓ m 0 ℓ m +∞ ℓ = +∞ −∞ −∞ ? +∞ +∞ We now consider the quotient. Theorem 49 Let A ⊆ R. Let f, g : A −→ R. Let x0 ∈ D(A) and ℓ, m ∈ R, and such that lim x → x0 f(x) = ℓ and lim x → x0 g(x) = m. Let g(x) , 0 for all x ∈ A. Then: (i) if ℓ ∈ R and m = ±∞, the limit lim x → x0 f(x)/g(x) exists and is equal to 0; (ii) if ℓ = +∞ and 0 < m < +∞, the limit lim x → x0 f(x)/g(x) exists in R and is equal to +∞; (iii) if ℓ = +∞ and −∞ < m < 0, the limit lim x → x0 f(x)/g(x) exists in R and is equal to −∞; (iv) if ℓ = −∞ and 0 < m < +∞, the limit lim x → x0 f(x)/g(x) exists in R and is equal to −∞; (v) if ℓ = −∞ and −∞ < m < 0, the limit lim x → x0 f(x)/g(x) exists in R and is equal to +∞; (vi) if 0 < ℓ ≤ +∞ and m = 0, and g(x) > 0 for all x ∈ A, the limit lim x → x0 f(x)/g(x) exists in R and is equal to +∞; (vii) if 0 < ℓ ≤ +∞ and m = 0, and g(x) < 0 for all x ∈ A, the limit lim x → x0 f(x)/g(x) exists in R and is equal to −∞; (viii) if −∞ ≤ ℓ < 0 and m = 0, and g(x) > 0 for all x ∈ A, the limit lim x → x0 f(x)/g(x) exists in R and is equal to −∞; (ix) if −∞ ≤ ℓ < 0 and m = 0, and g(x) < 0 for all x ∈ A, the limit lim x → x0 f(x)/g(x) exists in R and is equal to +∞. Partial proof Consider the case where f(x) = 1 and g(x) < 0 for all x ∈ A, and lim x → x0 g(x) = 0. We show that lim x → x0 f(x) g(x) = −∞, i.e., ∀ M < 0, ∃ δ > 0 : ∀ x ∈ Bδ(x0) ∩ A  \ {x0}, 1 g(x) < M. Page 119 of 17 4.1 Definition of Limit MATH1017 Let M < 0. Let ε = − 1 M > 0. Since lim x → x0 g(x) = 0, there exists δ > 0 such that, for all x ∈ Bδ(x0) ∩ A  \ {x0}, we have |g(x)| < ε = − 1 M ⇔ −g(x) < − 1 M ⇔ g(x) > 1 M ⇔ 1 g(x) < M. The other statements are proved in a similar way. For example, we show that if f(x) = 1 and lim x → x0 g(x) = +∞, then lim x → x0 f(x) g(x) = 0. In other words, we show that for all ε > 0, there exists δ > 0 such that, for all x ∈ Bδ(x0) ∩ A  \ {x0}, we have     1 g(x)     < ε. Let ε > 0. Let M = 1/ε. Since lim x → x0 g(x) = +∞, there exists δ > ˜ 0 such that for all x ∈ Bδ˜(x0) ∩ A  \ {x0}, we have g(x) > M, i.e., 1 g(x) < 1 M = ε. Thus, we have also     1 g(x)     < ε. We have the following table for the quotient: the symbol 0− denotes the fact that the limit is 0 and the function is negative, while 0+ denotes the fact that the limit is 0 and the function is positive. m = −∞ −∞ < m < 0 m = 0 − m = 0 + 0 < m < +∞ m = +∞ ℓ = −∞ ? +∞ +∞ −∞ −∞ ? −∞ < ℓ < 0 0 ℓ/m +∞ −∞ ℓ/m 0 ℓ = 0 0 0 ? ? 0 0 0 < ℓ < +∞ 0 ℓ/m −∞ +∞ ℓ/m 0 ℓ = +∞ ? −∞ −∞ +∞ +∞ ? Remark 35 The three tables that we presented contain question marks in those cases where knowing only ℓ and m does not allow us to conclude anything about the existence of the limit nor its value when it exists. Let us see some examples: (i) Consider the limits in the form ∞ − ∞. • Let A = R ∗ + , c ∈ R, f, g : A −→ R defined by f(x) = 1 x + c and g(x) = − 1 x . Then, lim x → 0 f(x) = +∞, lim x → 0 g(x) = −∞ and lim x → 0 f(x) + g(x)  = c. If f goes to +∞ and g to −∞ as x → 0, then f + g can have any real number as its limit (because c can be assigned to any real number). However, the limit of the sum can also be +∞ or −∞. In fact: • If A = R ∗ + , f, g : A −→ R defined by f(x) = 1 x 2 and g(x) = − 1 x , then f(x) + g(x) = 1 x 2 − 1 x = 1 x 1 x − 1 ! , whose limit is +∞. • If f(x) = 1 x and g(x) = − 1 x 2 , then f(x) + g(x) = 1 x − 1 x 2 = −∞. Page 120 of 4.1 Definition of Limit MATH1017 (ii) Consider the limits in the form 0 · (±∞). • Let A = R ∗ + , f, g : A −→ R defined by f(x) = c x and g(x) = − 1 x , then lim x → 0 f(x) g(x) = c. • If A = R ∗ + , f, g : A −→ R defined by f(x) = c x and g(x) = 1 x 2 , then lim x → 0 f(x) g(x) = lim x → 0 c x , and this limit is +∞ if c > 0, and −∞ if c < 0. (iii) Consider the limits in the form ∞ ∞ . • Let A = R ∗ + , c ∈ R, f, g : A −→ R defined by f(x) = c x and g(x) = 1 x , then lim x → 0 f(x) g(x) = c, where lim x → 0 g(x) = +∞, while lim x → 0 f(x) is +∞ if c > 0 and −∞ if c < 0. • Let A = R ∗ + , f, g : A −→ R defined by f(x) = 1 x 2 and g(x) = 1 x . Then, lim x → 0 f(x) g(x) = +∞ with lim x → 0 f(x) = lim x → 0 g(x) = +∞. • Let A = R ∗ + , f, g : A −→ R defined by f(x) = 1 x and g(x) = 1 x 2 , then lim x → 0 f(x) g(x) = 0, where lim x → 0 f(x) = lim x → 0 g(x) = +∞. (iv) Consider the limits in the form 0 0 . • Let A = R ∗ + , f, g : A −→ R defined by f(x) = c x and g(x) = x. Then, lim x → 0 f(x) g(x) = c with lim x → 0 f(x) = lim x → 0 g(x) = 0. • Let A = R ∗ + , f, g : A −→ R defined by f(x) = x and g(x) = x 2 . Then, lim x → 0 f(x) g(x) = +∞. • Let A = R ∗ + , f, g : A −→ R defined by f(x) = x 2 and g(x) = x. Then, lim x → 0 f(x) g(x) = 0. In some cases, the limit of a product can exist even if the limit of one of the factors does not exist. Theorem 50 Let A ⊆ R. Let f, g : A −→ R, and let x0 ∈ D(A). Suppose that lim x → x0 f(x) = 0 and g is bounded. Then, the limit lim x → x0 f(x) g(x) exists and is equal to 0. Proof Let M > 0 be such that |g(x)| ≤ M for all x ∈ A. Let ε > 0. Then, there exists δ > 0 such that, if x ∈ A ∩ Bδ(x0)  \ {x0}, we have | f(x)| < ε M . It follows that | f(x) g(x)| ≤ M | f(x)| < M ε M = ε. Page 121 of 17 4.1 Definition of Limit MATH1017 Example Let f : R ∗ −→ R x 7→ x sin 1 x . Since lim x → 0 x = 0 and the function R ∗ −→ R x 7→ sin 1 x is bounded (    sin 1 x     ≤ 1 for all x ∈ R ∗ ), applying Theorem 50 we can conclude that lim x → 0 f(x) = 0. Notice that the limit lim x → 0 sin 1 x does not exist (in fact, for all r > 0, it is easy to see that there exist x1, x2 ∈ Br(0) such that f(x1) = −1 and f(x2) = 1: try!). x y 4.1.3 Limits as x → ±∞ Let A ⊆ R be not bounded from above. This means that A does not have upper bounds, or, in other words, for all M ∈ R, there exists a ∈ A with a > M. To indicate this fact, we will use the notation sup A = +∞. (99) Similarly, if A is not bounded from below, we write inf A = −∞. (100) Definition 34 Let A ⊆ R not be bounded from above. Let f : A −→ R and ℓ ∈ R. Then, we write • lim x → +∞ f(x) = ℓ if ∀ ε > 0, ∃ N ∈ R : ∀ x ∈ A, x > N ⇒ | f(x) − ℓ| < ε; • lim x → +∞ f(x) = +∞ if ∀ M ∈ R, ∃ N ∈ R : ∀ x ∈ A, x > N ⇒ f(x) > M; Page 122 of 175 4.1 Definition of Limit MATH1017 • lim x → +∞ f(x) = −∞ if ∀ M ∈ R, ∃ N ∈ R : ∀ x ∈ A, x > N ⇒ f(x) < M. Definition 35 Let A ⊆ R not be bounded from below. Let f : A −→ R and ℓ ∈ R. Then, we write • lim x → −∞ f(x) = ℓ if ∀ ε > 0, ∃ N ∈ R : ∀ x ∈ A, x < N ⇒ | f(x) − ℓ| < ε; • lim x → −∞ f(x) = +∞ if ∀ M ∈ R, ∃ N ∈ R : ∀ x ∈ A, x < N ⇒ f(x) > M; • lim x → −∞ f(x) = −∞ if ∀ M ∈ R, ∃ N ∈ R : ∀ x ∈ A, x < N ⇒ f(x) < M. Remark 36 Theorems 35, 38, 46, 47, 48, 49 have obvious counterparts by substituting x0 with ±∞, and the three tables continue to hold. Theorem 36 has the following extension: the proof is essentially identical (can you see why?). Theorem 51 Let A ⊆ R not be bounded from above. Let f : A −→ R and ℓ ∈ R. Let lim x → +∞ f(x) = ℓ. Let ℓ ′ , ℓ′′ ∈ R with ℓ ′ < ℓ < ℓ′′. Then, there exists N ∈ R such that for all x ∈ A with x > N, ℓ ′ < f(x) < ℓ′′ . Example Let a ∈ R with a > 0, and let x y f : [0, +∞) −→ R x 7→ x a Then, lim x → +∞ f(x) = +∞. Indeed, let M ∈ R. If M ≤ 0, we have f(x) > M for all x ∈ (0, +∞). In this case, we can select N = 0. If M > 0, then f(x) > M reads as x a > M. Since 1/a > 0, the exponential function x 7→ x 1 a is monotonically increasing, applying this function on both sides of the inequality x a > M preserves the direction of the inequality, and gives x > M 1 a . We can therefore take N = M 1 a . Page 123 of 175 4.1 Definition of Limit MATH1017 Example Let a ∈ R with a < 0, and f : (0, +∞) −→ R x 7→ x a . Then, lim x → +∞ f(x) = 0. Indeed, let ε > 0. We ask ourselves when the inequality −ε < x a < ε holds. The first inequality holds for any x > 0. The second holds if x > ε 1 a , because, since 1/a < 0, the exponential function x 7→ x 1 a is monotonically decreasing. We can therefore take N = ε 1 a . Example Let a ∈ R with a > 1, and f : R −→ R x 7→ a x . Then, lim x → +∞ f(x) = +∞ and lim x → −∞ f(x) = 0. Let us verify the second limit. Given ε > 0, we must find for which values of x we have −ε < a x < ε. The first inequality is always satisfied. The second holds if x < loga ε (indeed, loga is strictly increasing if a > 1). We can take N = loga ε. If 0 < a < 1, it is possible to verify that lim x → +∞ f(x) = 0 and lim x → −∞ f(x) = +∞. Example Let a ∈ R ∗ + with a , 1, and f : R ∗ + −→ R x 7→ loga x. If a > 1, lim x → +∞ f(x) = +∞, while if 0 < a < 1 we have lim x → +∞ f(x) = −∞. Example We verify that the limit lim x → +∞ cos x does not exist. Let ℓ ∈ R. We prove that we cannot have lim x → +∞ cos x = ℓ. Let ε0 = max{|ℓ − 1|, |ℓ + 1|}. Since ℓ cannot coincide simultaneously with 1 and −1, we have ε0 > 0. Let ε ∈ R such that 0 < ε < ε0. We show that a value N ∈ R cannot be found such that for all x > N there holds | cos x − ℓ| < ε. Suppose for example ε0 = |ℓ − 1|. Let N ∈ R. Choose k ∈ N ∗ so that 2 k π > N. This is always possible by choosing k > N 2 π . Then, | cos(2 k π) − ℓ| = |1 − ℓ| = ε0 > ε. On the other hand, since the cosine is a bounded function, the limit cannot be ±∞. Example Let P : R −→ R x 7→ a0 + a1 x + a2 x 2 + . . . + an x n , (101) where n ∈ N and an , 0. We want to study the existence of lim x → ±∞ P(x). We begin by studying lim x → +∞ P(x). We start from the case P(x) = x n . From the table of the product, for all n ∈ N we have lim x → +∞ x n = +∞. Now we consider P(x) as in (101) with x > 0 (this is not restrictive because we are interested in the behavior of the polynomial function as x → +∞). We have P(x) = x n (an + an−1 x −1 + . . . + a0 x −n ). Page 124 of 175 4.1 Definition of Limit MATH1017 From the analogous of Theorem 38 we can say that lim x → +∞ (an + an−1 x −1 + . . . + a0 x −n ) = an. Since the limit of the product coincides with the product of the limits, we have lim x → +∞ P(x) = ( +∞ if an > 0 −∞ if an < 0. We now consider lim x → −∞ P(x). Let us now consider again first the case where P(x) = x n , i.e., we want to determine lim x → −∞ x n . We have lim x → −∞ x = −∞ (why? apply the definition to see it). Applying the table of the product, lim x → −∞ x n = ( +∞ if n is even −∞ if n is odd. It follows that lim x → −∞ P(x) = ( +∞ if n is even and an > 0, or if n is odd and an < 0 −∞ if n is even and an < 0 or if n is odd and an > 0. Example Let n, m ∈ N. Let P : R −→ R x 7→ a0 + a1 x + a2 x 2 + . . . + an x n and Q : R −→ R x 7→ b0 + b1 x + b2 x 2 + . . . + bm x m be polynomial functions with real coefficients. Let an , 0 and bm , 0. Let A = {x ∈ R | Q(x) , 0} and let f : A −→ R x 7→ P(x) Q(x) . We want to study the existence of lim x → ±∞ f(x). We begin observing that this makes sense because, since the set {x ∈ R | Q(x) = 0} is finite (it may be empty), A is not bounded from above nor from below. If x ∈ A and x , 0, we have f(x) = x n−m an + an−1 x −1 + . . . + a0 x −n bm + bm−1 x −1 + . . . + b0 x −m . We have lim x → +∞ x n−m =    +∞ if n > m 1 if n = m 0 if n < m, while lim x → +∞ an + an−1 x −1 + . . . + a0 x −n bm + bm−1 x −1 + . . . + b0 x −m = an bm . It follows that lim x → +∞ f(x) =    +∞ if n > m and an bm > 0 −∞ if n > m and an bm < 0 an bm if n = m 0 if n < m. Page 125 of 175 4.2 A more general definition of limit MATH1017 Conversely lim x → −∞ x n−m =    +∞ if n > m and n − m is even −∞ if n > m and n − m is odd 1 if n = m 0 if n < m, and, again, lim x → −∞ an + an−1 x −1 + . . . + a0 x −n bm + bm−1 x −1 + . . . + b0 x −m = an bm . We conclude that lim x → −∞ f(x) =    +∞ if n > m, n − m is even and an bm > 0 −∞ if n > m, n − m is even and an bm < 0 +∞ if n > m, n − m is odd and an bm < 0 −∞ if n > m, n − m is even and an bm < 0 an bm if n = m 0 if n < m. 4.2 A more general definition of limit In the previous sections we gave several definitions of limit, depending on whether the limit is a real number of ±∞, and depending on whether x → x0 ∈ R or x → ±∞. It is handy to have a single “unified” definition, that encompasses all the previous ones as particular cases. To this end, we must introduce the notion of neighborhood. Definition 36 [Neighborhood] Let U ⊆ R. Let x0 ∈ R. We say that the set U is a neighborhood of x0 if there exists r > 0 such that Br(x0) ⊆ U. Exercise Let A ⊆ R. Let x0 ∈ D(A). Let f : A −→ R and ℓ ∈ R. Show that f tends to ℓ as x tends to x0 if and only if, for every neighborhood U of ℓ, there exists a neighborhood V of x0 such that, for all x ∈ (V ∩ A) \ {x0}, we have f(x) ∈ U. Definition 37 [Neighborhoods of ±∞] Let U ⊆ R. Let x0 ∈ R. We say that U is a neighborhood of +∞ if there exists a ∈ R such that (a, +∞) ⊆ U. We say that U is a neighborhood of −∞ if there exists b ∈ R such that (−∞, b) ⊆ U. Exercise Let A ⊆ R. Let x0 ∈ D(A). Let f : A −→ R. Show that f tends to +∞ as x tends to x0 if and only if, for every neighborhood U of +∞, there exists a neighborhood V of x0 such that, for all x ∈ (V ∩ A) \ {x0}, we have f(x) ∈ U. The notion of derived set can equivalently be expressed in terms of neighborhood. Theorem 52 Let A ⊆ R and x0 ∈ R. Then, x0 is an accumulation point for A if and only if, for all neighborhoods V of x0, the set A ∩ V contains some elements distinct from x0, i.e., (A ∩ V) \ {x0} , ∅. Page 126 of 175 4.2 A more general definition of limit MATH1017 The proof is left as an exercise. This theorem gives us an idea: can we define an accumulation point for +∞ or −∞? Definition 38 Let A ⊆ R and x0 ∈ R. Then, x0 is a generalized accumulation point (or generalized limit point) for A if, for all neighborhoods V of x0, the set A ∩ V contains some element distinct from x0. We denote by D˜ (A) the set of generalized accumulation points of A, and we call it generalized derived set. Remark 37 If x0 ∈ R, then x0 ∈ D˜ (A) if and only if x0 ∈ D(A). We ask ourselves when +∞ ∈ D˜ (A). For this to be possible, it is necessary and sufficient that for all a ∈ R the set (a, +∞) ∩ A contains elements distinct from +∞. Since +∞ < (a, +∞) ∩ A, this happens if and only if (a, +∞) ∩ A , ∅. We found that +∞ ∈ D˜ (A) if and only ∀ a ∈ R, ∃ x ∈ A : x > a, and this is the same as requiring that A be not bounded from above. In the same way, we can see that −∞ ∈ D˜ (A) is equivalent to saying that A is not bounded from below. We can now give a definition of limit that encompasses all the previous ones. Definition 39 Let A ⊆ R. Let x0 ∈ D˜ (A). Let f : A −→ R and ℓ ∈ R. We say that f is convergent to ℓ as x tends to x0, and we write lim x → x0 f(x) = ℓ, if, for every neighborhood U of ℓ, there exists a neighborhood V of x0 such that, for all x ∈ (V ∩ A) \ {x0}, we have f(x) ∈ U. Remark 38 In Definition 39, if x0 = ±∞, the condition x ∈ (V ∩ A) \ {x0} can be simplified into x ∈ V ∩ A, because +∞ < V ∩ A. Theorem 53 [Uniqueness of the Limit] Let A ⊆ R. Let f : A −→ R. Let x0 ∈ D˜ (A) and ℓ1, ℓ2 ∈ R are such that lim x → x0 f(x) = ℓ1 and lim x → x0 f(x) = ℓ2. Then, ℓ1 = ℓ2. Proof Suppose by contradiction ℓ1 , ℓ2. There exist U1 neighborhood of ℓ1 and U2 neighborhood of ℓ2 such that U1 ∩ U2 = ∅. Indeed: • if ℓ1, ℓ2 are finite, we can take r = |ℓ1−ℓ2| 2 , and U1 = Br(ℓ1) and U2 = Br(ℓ2); • if ℓ1 is finite and ℓ2 = +∞, take 0 < r < |ℓ1|, U1 = Br(ℓ1) and U2 = (|ℓ1| + r, +∞); similar choices apply when Page 127 of 175 4.2 A more general definition of limit MATH1017 ℓ2 = −∞; • if ℓ1 = −∞ and ℓ2 = +∞. Choose M > 0 and U1 = (−∞, −M) and U2 = (M, +∞). Since lim x → x0 f(x) = ℓ1, there is a neighborhood V1 of x0 such that, for all x ∈ (V1 ∩ A) \ {x0}, we have f(x) ∈ U1. Likewise, since lim x → x0 f(x) = ℓ2, there is a neighborhood V2 of x0 such that, for all x ∈ (V2 ∩ A) \ {x0}, we have f(x) ∈ U2. Take V = V1 ∩V2. For all x ∈ (V ∩A) \ {x0}, we have f(x) ∈ U1 and f(x) ∈ U2, so that f(x) ∈ U1 ∩U2, which is a contradiction since U1 ∩ U2 = ∅. 4.2.1 Limits of restrictions We introduce the limit of the restriction. Definition 40 Let A, B,C be sets with A ⊆ B and f : B −→ C. We denote by f |A the function f |A : A −→ C x 7→ f(x). We say that f |A is the restriction of f to A. Theorem 54 [Limit of the Restriction – I] Let A, B ⊆ R be such that A ⊆ B. Let f : B −→ R. Let x0 ∈ R. Then: (i) if x0 ∈ D˜ (A), then x0 ∈ D˜ (B); (ii) if x0 ∈ D˜ (A), and if lim x → x0 f(x) exists (in R or in R), then lim x → x0 f |A(x) exists, and the two limits coincide. Proof The proof of the first point is straightforward: if x0 ∈ D˜ (A), for every neighborhood V of x0, the set V ∩ A contains elements distinct from x0. Since V ∩ A ⊆ V ∩ B, the same is true for V ∩ B. We prove the second point. If ℓ = lim x → x0 f(x) ∈ R, for every neighborhood U of ℓ there exists a neighborhood V of x0 such that, for all x ∈ V ∩ B, if x , x0 then f(x) ∈ U. This occurs, in particular, if x ∈ V ∩ A and x , x0. This proves (ii). The partial converse of Theorem 54 is the following. Theorem 55 [Limit of the Restriction – II] Let A, B ⊆ R be such that A ⊆ B. Let f : B −→ R. Let x0 ∈ D˜ (A) be such that there exists a neighborhood W of x0 such that (W ∩ B) \ {x0} ⊆ A. Let the limit lim x → x0 f |A(x) exist in R and be equal to ℓ. Then, lim x → x0 f(x) exists and it is equal to ℓ. Proof For every neighborhood U of ℓ, we must show that there exists a neighborhood V of x0 such that, for all x ∈ (V ∩ B) \ {x0}, there holds f(x) ∈ U. Let U be a neighborhood of ℓ. Since by assumption lim x → x0 f |A(x) = ℓ, there exists a neighborhood V′ of x0 such that, for all x ∈ (V′ ∩ A) \ {x0}, there holds f(x) ∈ U. Page 128 of 175 4.2 A more general definition of limit MATH1017 We show that taking V = V′ ∩ W solves the problem. Indeed, the intersection of two neighborhoods of x0 is a neighborhood of x0 (why?). Let x ∈ (V ∩ B) \ {x0} = (V′ ∩ W ∩ B) \ {x0}. Since (W ∩ B) \ {x0} ⊆ A, it follows that x ∈ A. Moreover, x ∈ V′ . Hence, x ∈ (V′ ∩ A) \ {x0}, and from what we have seen this guarantees that f(x) ∈ U. Example Let f : B −→ R. Let us assume that B is not bounded from above, or, stated differently, that +∞ ∈ D˜ (B). Let A = B ∩ (0, +∞). Then, if we define x0 = +∞, the assumption of Theorem 55 is satisfied with W = (0, +∞). Thus, lim x → +∞ f(x) exists if and only if lim x → +∞ f |A(x) exists, and the two limits are the same. Example Consider the function 1 2 3 f : [0, 1) ∪ (2, 3] −→ R x 7→ 1 2 x. We want to determine lim x → 1 f(x). It seems obvious that lim x → 1 f(x) = 1 2 , but this is only because we are implicitly using Theorem 55. Indeed, let B = [0, 1) ∪ (2, 3] and let A = [0, 1), so that indeed A ⊆ B. From the graph of f , we see that there exists a ball Br(1) such that Br(1) ∩ B  \ {1} ⊆ A, and therefore, from Theorem 55, since the limit of the restriction f |[0,1] as x → 1 is 1/2, the limit of f as x → 1 is also equal to 1/2, i.e., lim x → 1 f(x) = 1 2 . 4.2.2 Left and right limits We now present a significant case of limit of restrictions. Definition 41 Let A ⊆ R and x0 ∈ R. We say that x0 belongs to the right derived set of A, and we write x0 ∈ D+(A), if x0 ∈ D A ∩ (x0, +∞)  . Likewise, we say that x0 belongs to the left derived set of A, and we write x0 ∈ D−(A), if x0 ∈ D A ∩ (−∞, x0)  . Definition 42 Let A ⊆ R and f : A −→ R. • Let x0 ∈ D+(A). We say that f admits limit for x that tends to x0 to the right if the limit lim x → x0 f |A ∩ (x0,+∞)(x) exists. We denote this limit by lim x → x + 0 f(x). • Let x0 ∈ D−(A). We say that f admits limit for x that tends to x0 to the left if the limit lim x → x0 f |A ∩ (−∞,x0)(x) exists. We denote this limit by lim x → x − 0 f(x). Example Let A = R ∗ , and consider the function Page 129 of 4.2 A more general definition of limit MATH1017 x y f : R ∗ −→ R x 7→ x −1 We observe that the limit lim x → 0 f(x) does not exist: in every ball centred at the origin, there are values of f that are arbitrarily large and values that are arbitrarily small. However, we show that lim x → 0 + f(x) = +∞. This limit makes sense because 0 ∈ D R ∗ ∩ (0, +∞)  = D (0, +∞)  = [0, +∞). Let M ∈ R. If M ≤ 0, trivially f(x) > M for all x ∈ R ∗ + . In this case we can take δ to be any arbitrary positive quantity. If M > 0, then f(x) > M if and only if 0 < x < M−1 . A possible choice of δ is therefore δ = M−1 , since BM−1 (0) ∩ R ∗ + = (0, M−1 ). Notice that we have also lim x → 0 − f(x) = −∞. The following result relates Definition 42 with the definition of limit: essentially, the existence of a limit at a point is equivalent to the left and right limits to exist and be equal. Theorem 56 Let A ⊆ R. Let x0 ∈ D+(A) ∩ D−(A), and let f : A −→ R. The following conditions are equivalent: (i) the limit lim x → x0 f(x) exists; (ii) the limits lim x → x + 0 f(x) and lim x → x − 0 f(x) exist and they are equal. Proof The fact that (i) implies (ii) follows from Theorem 54. We show that (ii) implies (i). Let ℓ = lim x → x + 0 f(x) = lim x → x − 0 f(x). Let U be a neighborhood of ℓ. Then, there exist two neighborhoods V+ and V− of x0 such that, for all A ∩ V+ with x > x0, then f(x) ∈ U, and for all A ∩ V− with x < x0, then f(x) ∈ U. Let V = V+ ∩ V−. Then V is a neighborhood of x0. Let x ∈ V ∩ A with x , x0. If x > x0, then from x ∈ V+ ∩ A we have f(x) ∈ U. Vice-versa, if x < x0, then from x ∈ V− ∩ A it follows that f(x) ∈ U. Hence, (i) holds. Example Consider the limit lim x → 1 + sin x x − 1 . Since 1 ∈ h 0, π 2 i , we have sin 1 > 0. The denominator goes to 0, but from the right, so that x − 1 is a positive quantity Page 130 of 1 4.3 Landau symbols MATH1017 that goes to 0. These considerations suggest that the limit should be +∞. We now verify this, by defining the function f : (1, +∞) −→ R x 7→ sin x x − 1 , and interpreting the given limit as lim x → 1 f(x). To prove that the limit is +∞, we show that ∀ M > 0, ∃ δ > 0 : ∀ x ∈ (1, +∞), 0 < |x − 1| < δ ⇒ f(x) > M. Since x , 1 and x − 1 > 0, this condition becomes ∀ M > 0, ∃ δ > 0 : ∀ x ∈ (1, +∞), x − 1 < δ ⇒ sin x x − 1 > M. We have sin x x − 1 > M ⇒ M (x − 1) < sin x ⇒ x − 1 < sin x M ≤ 1 M , since sin x ≤ 1 for all x ∈ R. Thus, we can take δ = 1/M. Example Consider the limit lim x → 1 − sin x (x − 1)3 . As in the previous example, we have sin 1 > 0. The denominator goes to 0, but from the left, so that x−1 is a negative quantity that goes to 0. The limit should therefore be −∞. We now verify this, by defining the function f : (−∞, 1) −→ R x 7→ sin x (x − 1)3 , and interpreting the given limit as lim x → 1 f(x). To prove that the limit is −∞, we show that ∀ M < 0, ∃ δ > 0 : ∀ x ∈ (−∞, 1), 0 < |x − 1| < δ ⇒ f(x) < M. Since x , 1 and x − 1 < 0, this condition becomes ∀ M < 0, ∃ δ > 0 : ∀ x ∈ (−∞, 1), 1 − x < δ ⇒ sin x (x − 1)3 > M. Since sin x ≤ 1 for all x ∈ R and (x − 1)3 < 0 for all x ∈ (−∞, 1), we have 1 (x − 1)3 ≤ sin x (x − 1)3 < M ⇒ (x−1)3 > 1 M ⇒ |x−1| 3 < 1 |M| ⇒ |x−1| < 3 r 1 |M| ⇒ 1−x < 3 r 1 |M| . Thus, we can take 3 q 1 |M| . 4.3 Landau symbols Let A ⊆ R and x0 ∈ D˜ (A), and f, g : A −→ R. It is often useful to define the fact that f is negligible with respect to g as x → x0. Consider the functions Page 131 of 175 4.3 Landau symbols MATH1017 x y f2 f1 f1 : R ∗ + −→ R x 7→ x and f2 : R ∗ + −→ R x 7→ x 3 . Both functions go to 0 as x → 0. However, as x → 0, f2(x) = x 3 seems to go to 0 faster than f1(x) = x. As a result, in a neighborhood of 0 the function f2 is negligible compared to f1. We express this fact by writing lim x → 0 f2(x) f1(x) = lim x → 0 x 3 x = lim x → 0 x 2 = 0. This shows that not only does f2 go to zero as x → 0, but it goes to zero faster than f1. As a result, f2 is negligible with respect to f1: we also say that f2 is an “infinitesimal of higher order” than f1 (a function is infinitesimal as x → x0 if it goes to zero as x → x0). We notice that the behavior as x → +∞ is entirely different: in this case, both f1 and f2 go to +∞ as x → +∞, but f2 goes to +∞ faster than f1, and therefore f1 is negligible compared to f2. In this case we write lim x → +∞ f1(x) f2(x) = lim x → +∞ x x 3 = lim x → +∞ 1 x 2 = 0, and we say that f2 is an “infinite of higher order” than f1. In both cases, we have limits that are equal to zero, and the function in the numerator is negligible compared to the function in the denominator. Let us now consider the two functions x y g2 g1 g1 : R ∗ + −→ R x 7→ 1 x and g2 : R ∗ + −→ R x 7→ 1 x 2 . As x approaches 0, both functions tend to +∞, but g2 tends to infinity faster than g1, and as a result g1 is negligible as x → 0. We have lim x → 0 g1(x) g2(x) = lim x → 0 1 x 1 x 2 = lim x → 0 x = 0. Hence, g2 is an infinite of higher order than g1 as x → 0. As x approaches +∞, both functions tend to 0, but Page 132 of 175 4.3 Landau symbols MATH1017 g2 tends to infinity faster than g1, and as a result g2 is negligible as x → 0. We have lim x → +∞ g2(x) g1(x) = lim x → +∞ 1 x 2 1 x = lim x → +∞ 1 x = 0. Thus, g2 is an infinitesimal of higher order than g1 as x → +∞. Notice that, in these definitions, the fact that a function is negligible with respect to another function is not a consequence of the fact that its graph lies below the graph of the other function. For example, consider the functions x y h2 h1 h1 : R ∗ + −→ R x 7→ x and h2 : R ∗ + −→ R x 7→ 2 x. The graph of h1 lies below that of h2, but h1 is not negligible: indeed, the limit lim x → 0 h1(x) h2(x) = lim x → 0 x 2 x = 1 2 is not equal to zero (on the contrary, the fact that the limit is finite and different from zero says that h1 and h2 are infinitesimals of the same order as x → 0. Notice that they are also infinites of the same order as x → +∞: why?). With the following notation, we express the property of a function to be negligible with respect to another function. Definition 43 [“Little o” Notation] Let A ⊆ R and x0 ∈ D˜ (A), and f, g : A −→ R. We say that f is a “little o” of g as x tends to x0, and we write f = ox0 (g) or f(x) = ox → x0 g(x)  , if g(x) , 0 for all x ∈ A and lim x → x0 f(x) g(x) = 0. It is easy to see that Definition 43 can be generalised to the case where f and g may not have the same domain, but they are both defined in a neighborhood of x0, provided that g(x) , 0 in its domain. More importantly, this definition can be generalised to the case where the assumption g(x) , 0 for all x ∈ A is removed in a neighborhood of x0. This point will be dealt with in the complement section on asymptotic comparison of functions. The notation introduced in Definition 43 is often used without writing down the point x0 explicitly, so we will typically see the notation f = o(g) or f(x) = g(x)  , if this does not cause confusion.23 23We have to be careful about interpreting this notation: the equality in f = o(g) does not have its usual properties. For example, we will never write o(g) = f . For example, we have x 4 = o0(x 2 ) and x 3 = o0(x 2 ), but we cannot conclude that x 4 = x 3 . Page 133 of 1 4.3 Landau symbols MATH1017 Example Here we generalise the considerations we made in the beginning of this section. Let A = R ∗ + and f1 : A −→ R x 7→ x α and f2 : A −→ R x 7→ x β , where α, β ∈ R. Assume α < β. We verify that f2 = ox→0(f1). In fact, for x ∈ A f2(x) f1(x) = x β−α x→0 −−−−−−−→ 0, since β − α > 0 (see Theorem 39). We have f1 = ox→+∞(f2). Indeed, for x ∈ A, f1(x) f2(x) = x α−β x→0 −−−−−−−→ 0, since α − β < 0. The previous example shows that the definition of “little o” relies heavily on the choice of x0. The following result summarises some important properties of the o. Theorem 57 Let A ⊆ R and x0 ∈ D˜ (A), and f, f1, f2, g, h, k : A −→ R. Let g(x) , 0 and k(x) , 0 for all x ∈ A. Then: (i) if f1 = ox→x0 (g) and f2 = ox→x0 (g), then f1 + f2 = ox→x0 (g); (ii) if f = ox→x0 (g) and the limit lim x → x0 g(x) exists in R and is equal to ℓ, then lim x → x0 g(x) + f(x)  = ℓ; (iii) if f = ox→x0 (g) and h = ox→x0 (k), and lim x → x0 g(x) k(x) = m ∈ R, then, defining B = {x ∈ A | k(x) + h(x) , 0}, we have x0 ∈ D˜ (B). Moreover, the function B −→ R x 7→ g(x) + f(x) k(x) + h(x) admits limit as x → x0 and it is equal to m. Similarly, if in a formula the function f appears, and we know that f = o(g), we normally substitute o(g) with f . For example, we can write x 4 + x 3 = o0(x 2 ) + o0(x 2 ). The two little “o”’s in the right hand-side stand for different functions. Identities involving this notation must be read from the left to the right: for example, the identity o(x 3 ) = o(x 2 ) means “if f(x) = o(x 3 ), then f(x) = o(x 2 ), which is true. Therefore, the equality o(x 2 ) = o(x 3 ) is false. Another example, considering x0 → 0: the identity −3 o(x 3 ) = o(4 x 2 ) means “if a function f is negligible compared to x 3 , then −3 f is negligible with respect to 4 x 2 ”. The identity o(x 5 ) + o(x 4 ) = o(x 2 ) means: “if two functions f and g are, respectively, negligible compared to x 5 and x 4 then their sum f + g is negligible with respect to x 2 . Page 134 of 17 4.3 Landau symbols MATH1017 Proof We prove (i). We have lim x → x0 f1(x) + f2(x) g(x) = lim x → x0 f1(x) g(x) + f2(x) g(x) ! = 0 + 0 = 0; (ii). We find g(x) + f(x) = g(x) 1 + f(x) g(x) ! . The conclusion follows from the fact that lim x → x0 1 + f(x) g(x) ! = 1. (iii) For x ∈ A we have k(x) + h(x) = k(x) 1 + h(x) k(x) ! . Since lim x → x0 1 + h(x) k(x) ! = 1, from Theorem 36 we find that there exists a neighborhood V of x0 such that, for all x ∈ A ∩ V with x , x0, we have 1 + h(x) k(x) > 1 2 > 0. It follows that B contains (A ∩ V) \ {x0}. Hence, x0 ∈ D˜ (B). In fact, let W be a neighborhood of x0. The set V ∩ W is also a neighborhood of x0. Therefore, we can find x ∈ V ∩ W ∩ A with x , x0. This x belongs also to W ∩ (V ∩ A) \ {x0}  . Let x ∈ B. Then, g(x) + f(x) k(x) + h(x) = g(x) k(x) 1 + f(x) g(x) 1 + h(x) k(x) The first factor g(x) k(x) tends to m, the second tends to 1, leading immediately to the conclusion. The statements in Theorem 57 can be written more succinctly as (i) o(g) + o(g) = o(g); (ii) lim x → x0 g(x) + o(g(x)) = lim x → x0 g(x); (iii) lim x → x0 g(x) + o(g(x)) k(x) + o(k(x)) = lim x → x0 g(x) k(x) . The proof of the third point of Theorem 57 becomes particularly simple with this notation: lim x → x0 g(x) + o(g(x)) k(x) + o(k(x)) = lim x → x0 g(x) + g(x) o(1) k(x) + k(x)o(1) = lim x → x0 g(x) k(x) 1 + o(1) 1 + o(1) = lim x → x0 g(x) k(x) . In this notation, as is usually standard practice, the symbol f = ox→x0 (g) is simplified as f = o(g), since x0 is obvious from the context. If f(x) = g(x) + ox0 g(x)  , we write also f(x) x0∼ g(x), and we say that f and g are asymptotically equivalent as x → x0. The second point of Theorem 57, with this notation, becomes a principle of substitution: in a limit, as x → x0, involving a function f , we can replace f with any asymptotically equivalent function as x → x0. For example, in the limit lim x → +∞ 3 x 2 + 1 5 x 2 , Page 135 of 4.4 Continuous functions MATH1017 we can easily see that lim x → +∞ 1 3 x 2 = 0, so that 1 is negligible with respect to 3 x 2 as x → +∞, i.e., 3 x 2 + 1 = 3 x 2 + o(3 x 2 ), which says that 3 x 2 + 1 +∞ ∼ 3 x 2 . Hence, lim x → +∞ 3 x 2 + 1 5 x 2 = lim x → +∞ 3 x 2 5 x 2 = lim x → +∞ 3 5 = 3 5 . Example We reconsider a previous example. Let n, m ∈ N. Let P : R −→ R x 7→ a0 + a1 x + a2 x 2 + . . . + an x n and Q : R −→ R x 7→ b0 + b1 x + b2 x 2 + . . . + bm x m be polynomial functions with real coefficients. Let an , 0 and bm , 0. Let A = {x ∈ R | Q(x) , 0} and let f : A −→ R x 7→ P(x) Q(x) . We have ak x k = o(an x n ) (as x → +∞) for k ∈ {0, . . . , n − 1}, and bh x h = o(bm x m) for h ∈ {0, . . . , m − 1}. From (i) in Theorem 57, it follows that a0 + . . . + an−1 x n−1 = o(an x n ), while b0 + . . . + bm−1 x m−1 = o(bm x m). We conclude that lim x → +∞ P(x) Q(x) = lim x → +∞ an x n + o(an x n ) bm x m + o(bm x m) = lim x → +∞ an x n bm x m , using point (iii) in Theorem 57, and we find the same conclusions obtained previously. We can write also a0 + a1 x + a2 x 2 + . . . + an x n b0 + b1 x + b2 x 2 + . . . + bm x m +∞ ∼ an x n bm x m . 4.4 Continuous functions Intuitively, a continuous function is a function whose graph can be drawn with continuity, i.e., in such a way that the pen never leaves the paper. Obviously we must have a more rigorous definition at our disposal. Definition 44 [Continuity at a Point – Continuous Function] Let A ⊆ R. Let x0 ∈ A and let f : A −→ R. We say that f is continuous at x0 if ∀ ε > 0, ∃ δ > 0 : ∀ x ∈ A, |x − x0| < δ ⇒ | f(x) − f(x0)| < ε. We say that f is continuous if it is continuous at x0 for all x0 ∈ A. Remark 39 Definition 44 is very similar to Definition 30. The first difference is that we do not require x0 ∈ D(A), but x0 ∈ A. Page 136 of 175 4.4 Continuous functions MATH1017 Example Consider the function f : [0, 2] −→ R x 7→ ( x if x ∈ [0, 1] x + 1 if x ∈ (1, 2]. This function is not continuous at 1: 1 2 ε 1 2 3 Indeed, taking ε < 1, we see that we cannot find a ball centred at 1 such that every point in that ball are mapped into points whose distance from f(1) = 1 is smaller than ε: in fact, every point at the right of 1 are at a distance of at least 1 from f(1). Notice, however, that the function g : [0, 1) ∪ (1, 2] −→ R x 7→ ( x if x ∈ [0, 1) x + 1 if x ∈ (1, 2] is continuous. Indeed, it makes no sense to assess the continuity at x = 1, since this point is not in the domain of g. Theorem 58 [Convergence and Continuity] Let A ⊆ R. Let f : A −→ R. Let x0 ∈ A. Then: (i) If x0 ∈ A \ D(A) (i.e., if x0 is an isolated point of A), then f is continuous at x0; (ii) if x0 ∈ A ∩ D(A) (i.e., if x0 is not an isolated point of A), then f is continuous at x0 if and only if the limit lim x → x0 f(x) exists and it is equal to f(x0). Proof We prove the first. Since x0 ∈ A\D(A) is equivalent to saying that x0 is an isolated point of A, there exists r > 0 such that Br(x0) ∩ A = {x0}. We have to show that for all ε > 0, there exists δ > 0 such that, for all x ∈ Bδ(x0) ∩ A, there holds | f(x) − f(x0)| < ε. Let ε > 0. Let us choose δ = r. Clearly, x ∈ Bδ(x0) ∩ A implies x = x0, so that | f(x) − f(x0)| = | f(x0) − f(x0)| = 0 < ε, as required. We now prove the second claim. Let x0 ∈ A ∩ D(A). Let f be continuous at x0. Then, for all ε > 0, there exists δ > 0 such that, for all x ∈ Bδ(x0) ∩ A, there holds | f(x) − f(x0)| < ε. This is obviously still true if, in particular, we choose x ∈ Bδ(x0) ∩ A and x , x0. Therefore, the condition of Definition 30 is satisfied with ℓ = f(x0). Conversely, let lim x → x0 f(x) = f(x0). Given ε > 0, there exists δ > 0 such that, for all x ∈ Bδ(x0) ∩ A with x , x0, the inequality | f(x) − f(x0)| < ε holds. However, this inequality is also trivially satisfied for x = x0, and therefore it holds for all x ∈ Bδ(x0) ∩ A. Hence, the condition of Definition 44 is satisfied. Remark 40 From the re-formulation of the notions of limits using neighborhoods, we find that a function f : A −→ R, where A ⊆ R, is continuous at a point x0 ∈ A if and only if for every neighborhood U of f(x0) there exists a neighborhood V of x0 such that, for all x ∈ V ∩ A, we have f(x) ∈ U. Page 137 of 175 4.4 Continuous functions MATH1017 Example Let ℓ ∈ R ∗ + , and let f : [0, +∞) −→ R x 7→ x ℓ . From Theorems 39 and 58, f is continuous. Example Let ℓ ∈ R with ℓ < 0, and let f : (0, +∞) −→ R x 7→ x ℓ . From Theorems 39 and 58, f is continuous. Example Let a ∈ R ∗ + , and let f : R −→ R x 7→ a x . From Theorems 40 and 58, f is continuous. Example Let a ∈ R ∗ + \ {1}, and let f : R ∗ + −→ R x 7→ loga x. From Theorems 41 and 58, f is continuous. Example From Theorems 43 and 58, the cosine and sine functions are continuous. Moreover, from Theorem 58 the polynomial functions are continuous. Let A be a set (not necessarily a subset of R). Let f, g : A −→ R. We can define the new functions f + g and f g as f + g : A −→ R x 7→ f(x) + g(x) and f g : A −→ R x 7→ f(x) g(x), so that, for all x ∈ A, we can write (f +g)(x) = f(x)+g(x) and (f g)(x) = f(x) g(x). If g(x) = c for all x ∈ A, where c ∈ R, we denote the function f g by c f . If g(x) , 0 for all x ∈ A, we can also define the function f g : A −→ R x 7→ f(x) g(x) . The following result holds true. Theorem 59 Let A ⊆ R. Let f, g : A −→ R. Let x0 ∈ A and let f and g be continuous at x0. Then: (i) f + g is continuous at x0; Page 138 of 175 4.4 Continuous functions MATH1017 (ii) f g is continuous at x0; (iii) if g(x) , 0 for all x ∈ A, then f g is continuous at x0. Proof We prove (i). If x0 < D(A), the result follows from (i) in Theorem 58. If x0 ∈ A∩D(A), from (ii) in Theorem 58 we find lim x → x0 f(x) = f(x0) and lim x → x0 g(x) = g(x0). From (i) in Theorem 38 we obtain lim x → x0 f(x) + g(x)  = f(x0) + g(x0). The conclusion follows from (ii) in Theorem 58. The other statements can be proved in a similar manner. Example Let P and Q two polynomial functions with real coefficients. Let A = {x ∈ R | Q(x) , 0} and f : A −→ R x 7→ P(x) Q(x) . This function is referred to as “rational”. From (iii) in Theorem 59, every rational function is continuous in its domain. Example Let A = {x ∈ R | cos x , 0}. Since between 0 and 2 π the cosine is zero at π 2 and 3 2 π, we find A = R \  π 2 + k π     k ∈ Z  . If x ∈ A, we define the tangent of x as tan x def = sin x cos x . (102) and tan : A −→ R x 7→ tan x. From (iii) in Theorem 59, the tangent is continuous in its domain. We verify that it is an odd function. Indeed, if x ∈ A, we have −x ∈ A. Moreover, tan(−x) = sin(−x) cos(−x) = − sin x cos x = − tan x. Moreover, tan is a periodic function with period π. Indeed, A is the union of the intervals . . . , − π 2 − π, π 2 − π  ,  − π 2 , π 2  ,  − π 2 + π, π 2 + π  , . . . Hence, if x ∈ A, we have also x + π ∈ A, and tan(x + π) = sin(x + π) cos(x + π) = sin x cos π + cos x sin π cos x cos π − sin x sin π = − sin x − cos x = tan x. Page 139 of 17 4.5 Limit of the composition MATH1017 It is therefore sufficient to study the behaviour of the function in  − π 2 , π 2  , and use the periodicity to see how the function behaves on all other intervals. We observe that tan is increasing in h 0, π 2  . Indeed, if 0 ≤ x1 < x2 < π 2 , we have 0 ≤ sin x1 < sin x2 and cos x1 > cos x2 > 0, so that tan x1 < tan x2. In general, tan is increasing in  − π 2 , π 2  . Indeed, if − π 2 < x1 < x2 ≤ 0, we have π 2 > −x1 > −x2 ≥ 0, so that tan(−x1) > tan(−x2) and tan x1 < tan x2 using the fact that tan is odd. Finally, if x1 < 0 < x2, we have tan x1 < 0 and tan x2 > 0, which allows us to conclude. Finally, we observe that, since • cos x > 0 for all x ∈  − π 2 , π 2  • sin π 2 = 1 and sin  − π 2  = −1 • Theorem 49, we obtain lim x → π 2 − tan x = +∞ and lim x → − π 2 + tan x = −∞. 4.5 Limit of the composition Let A, B ⊆ R, let f : A −→ R and g : B −→ R, with f(A) ⊆ B, so that g ◦ f is defined. Let x0 ∈ D˜ (A). We want to give conditions for the existence of lim x → x0 (g ◦ f)(x). Let us start with an intuitive consideration. Suppose that y0 = lim x → x0 f(x) exists, that y0 ∈ D˜ (B) and that lim y → y0 g(y) = ℓ. If x approaches x0, then f(x) approaches y0, and therefore we expect that g ◦ f tends to ℓ. We will see that this conclusion is not always true. We start with two results that show that under some assumptions, this conclusion holds. Theorem 60 Let A ⊆ R and B ⊆ R. Let f : A −→ R and g : B −→ R, and f(A) ⊆ B. Let x0 ∈ D˜ (A), and suppose that lim x → x0 f(x) = y0. Moreover, let y0 ∈ B and let g be continuous at y0. Then, g ◦ f is convergent at x0 and lim x → x0 (g ◦ f)(x) = g(y0). (103) Proof We have to prove that for every neighborhood U of g(y0), there exists a neighborhood V of x0 such that, for all x ∈ V ∩ A, if x , x0 then g f(x)  ∈ U. Let U be a neighborhood of g(y0). From the continuity of g at y0, there exists a neighborhood W of y0 such that, for all y ∈ W ∩ B, we have g(y) ∈ U. Since f converges to y0 as x tends to x0, there exists a neighborhood V of x0 such that, for all x ∈ V ∩ A, if x , x0 we have f(x) ∈ W. On the other hand, we have also f(x) ∈ B (since f(A) ⊆ B), so that f(x) ∈ W ∩ B, and therefore we can take y = f(x), and we find that for all x ∈ V ∩ A, if x , x0 we have g(y) = g f(x)  ∈ U, as required. Page 140 of 1 4.5 Limit of the composition MATH1017 Example We want to evaluate the limit lim x → +∞ r 4 x + 1 x + 3 . First, to apply Theorem 60, we must define two functions f and g such that for all x in the domain of f we have (g ◦ f)(x) = g f(x)  = r 4 x + 1 x + 3 . While f could be defined as a function f : R \ {−3} −→ R that maps x into 4 x+1 x+3 , this choice would not guarantee that f(R) is contained in the domain of g (where g is the function that maps y into √ y). Hence, we must define f : (−∞, −3) ∪ h − 1 4 , +∞  −→ R x 7→ 4 x + 1 x + 3 and g : R+ −→ R y 7→ √ y. We have y0 = lim x → +∞ f(x) = lim x → +∞ 4 x + 1 x + 3 = 4. Hence, y0 is a limit point for R+. Finally, g is continuous at 4, so that lim x → +∞ r 4 x + 1 x + 3 = lim x → +∞ g f(x)  = g(4) = √ 4 = 2. Notice that (103) in Theorem 60 can be re-written as lim x → x0 g f(x)  = g  lim x → x0 f(x)  . In Theorem 60, g was assumed to be continuous at lim x → x0 f(x). The following result does not assume the continuity of g at lim x → x0 f(x), but only the convergence. Theorem 61 Let A ⊆ R and B ⊆ R. Let f : A −→ R and g : B −→ R, and f(A) ⊆ B. Let x0 ∈ D˜ (A), and suppose that lim x → x0 f(x) = y0, that y0 ∈ D˜ (B) \ B and suppose that ℓ = lim y → y0 g(y) exists in R. Then, g ◦ f is convergent at x0 and lim x → x0 (g ◦ f)(x) = ℓ. (104) Proof We have to prove that for every neighborhood U of ℓ, there exists a neighborhood V of x0 such that, for all x ∈ V∩A, if x , x0 then g f(x)  ∈ U. Let U be a neighborhood of ℓ. Since ℓ = lim y → y0 g(y), there exists a neighborhood W of y0 such that for all y ∈ W ∩ B we have g(y) ∈ U. It is not necessary to exclude y0, since by assumption y0 < B. Since lim x → x0 f(x) = y0 and f takes values in B, there exists a neighborhood V of x0 such that, for all x ∈ V ∩ A with x , x0, we have f(x) ∈ W ∩ B. With this choice of x we find (g ◦ f)(x) = g f(x)  ∈ U. We can re-write (104) as lim x → x0 g f(x)  = lim y → lim f(x) x → x0 g(y). Page 141 4.5 Limit of the composition MATH1017 Example We want to evaluate the limit lim x → +∞ s x 2 + 1 x + 3 . We define f : (−3, +∞) −→ R x 7→ x 2 + 1 x + 3 and g : R+ −→ R y 7→ √ y. Let y0 = lim x → +∞ f(x) = +∞. Since +∞ is a generalized limit point for R+ but not an element of R+, the assumption y0 ∈ D˜ (B) \ B is satisfied. Thus, lim x → +∞ s x 2 + 1 x + 3 = lim y → +∞ √ y = +∞. Notice that in this case we had to use Theorem 61 and not Theorem 60 because it makes no sense to talk about continuity at +∞. We now consider the following pathological example. Example Let f : R −→ R x 7→ 0 and g : R −→ R x 7→ ( 0 if x , 0 1 if x = 0 We have lim x → 0 f(x) = 0 and lim y → 0 g(y) = 0. On the other hand, (g ◦ f)(x) = 1 for all x ∈ R, so that lim x → 0 (g ◦ f)(x) = 1. The problem arises from the fact that, setting y0 = 0, we have g(y0) , ℓ def = lim y → y0 g(y). If f(x) = y0, then (g ◦ f)(x) can be “far away” from ℓ. The additional assumptions in Theorem 60 and in Theorem 61 avoid this phenomenon. In the second case, y0 < B, and therefore for every x we have f(x) , y0. In the first case g is continuous at y0, and therefore, if y is close to y0, then g(y) is close to g(y0). Theorem 62 Let A ⊆ R and B ⊆ R. Let f : A −→ R and g : B −→ R, and f(A) ⊆ B. Let x0 ∈ A. Let f be continuous at x0 and let g be continuous at f(x0). Then, g ◦ f is continuous at x0. Proof If x0 ∈ A \ D(A) (i.e., if x0 is an isolated point of A), the conclusion is trivial (in this case we do not even need Page 142 of 175 4.5 Limit of the composition MATH1017 to assume the continuity of g at f(x0)). Let x0 ∈ A ∩ D(A). We must show that lim x → x0 (g ◦ f)(x) = (g ◦ f)(x0). This follows immediately from Theorem 60. Theorem 63 Let A ⊆ R and B ⊆ R. Let f : A −→ R and g : B −→ R be both continuous, and f(A) ⊆ B. Then, g ◦ f is continuous. Proof This follows trivially from Theorem 62. Example Let h : R \ {1} −→ R x 7→ 2 x x−1 . Let f : R \ {1} −→ R x 7→ x x−1 and g : R −→ R y 7→ 2 y . Notice that h = g ◦ f . Moreover, f and g are continuous. From Theorem 63 we can say that h is continuous. We conclude this section by studying the limits of functions in the form h(x) = f(x) g(x) . Theorem 64 Let A ⊆ R. Let f, g : A −→ R with f(x) > 0 for all x ∈ A. Let x0 ∈ D˜ (A). Let lim x → x0 f(x) = ℓ ∈ [0, +∞] and lim x → x0 g(x) = m ∈ [−∞, +∞]. Then, the following table holds for lim x → x0 f(x) g(x) : m = −∞ −∞ < m < 0 m = 0 0 < m < +∞ m = +∞ ℓ = 0 +∞ +∞ ? 0 0 0 < ℓ < 1 +∞ ℓ m 1 ℓ m 0 ℓ = 1 ? 1 1 1 ? 1 < ℓ < +∞ 0 ℓ m 1 ℓ m +∞ ℓ = +∞ 0 0 ? +∞ +∞ Proof The proof follows by writing f(x) g(x) in the form 10g(x) Log f(x)  , and viewing it as the composition of A −→ R x 7→ g(x) Log f(x)  with R −→ R y 7→ 10y . Then, lim x → x0 Log f(x)  can be obtained from Theorem 60 or Theorem 61. Applying the table for the product, we can derive lim x → x0 g(x) Log f(x)  in many cases. A further application of Theorem 60 or Theorem 61 allows to conclude in Page 143 of 4.6 Some further results on continuous functions MATH1017 these cases. Consider for example ℓ = 0 and m = −∞. We have lim x → x0 Log f(x)  = −∞, lim x → x0 g(x) Log f(x)  = +∞, lim x → x0 10g(x) Log f(x)  = +∞. If, instead, ℓ = 0 and m = 0, the limit lim x → x0 g(x) Log f(x)  is an indeterminate form of the type 0 · (−∞). Finally, if ℓ = 0 and m = +∞, we have lim x → x0 Log f(x)  = −∞, lim x → x0 g(x) Log f(x)  = −∞, lim x → x0 10g(x) Log f(x)  = 0. Notice that, since f takes positive values, ℓ cannot be < 0. If we had ℓ < 0, we could apply Theorem 36 by taking ℓ < ℓ′′ < 0. Example We want to evaluate the limit lim x → 0 10 1 x . Since lim x → 0 + 1 x = +∞ and lim x → 0 − 1 x = −∞, from the table in Theorem 64 we obtain lim x → 0 + 10 1 x = +∞ and lim x → 0 − 10 1 x = 0, and therefore the given limit does not exist. Again, the case where a question mark appears in the table, the assumptions are not sufficient to ensure the existence of the limit (let alone its value). This does not mean that in those cases the limit does not exist, but also that we need a different kind of investigation to verify it. 4.6 Some further results on continuous functions We now present some important results. Definition 45 [Boundary] Let A ⊆ R. Let b ∈ R. We say that b is a boundary point of A if every ball centred at b contains both points of A and points that do not belong to A. We denote by ∂A the set of boundary points of A. We can re-phrase the condition in Definition 45 by saying that x0 is a boundary point of A if ∀ r > 0 : Br(x0) ∩ A , ∅ and Br(x0) ∩ (R \ A) , ∅. Example Let A = [0, 1). We want to show that ∂A = {0, 1}. We consider the following cases: (i) let b < 0. Then, if 0 < r < −b, the interval Br(b) = (b − r, b + r) does not contain points of A, so that b < ∂A. (ii) let b = 0. Let r > 0. The ball Br(0) = (−r,r) contains − r 2 , which is not in A. If r > 1 2 , the ball Br(0) = (−r,r) contains 1 2 , which is in A. If 0 < r < 1 2 , the ball Br(0) = (−r,r) contains r 2 , which belongs to A. Therefore, 0 ∈ ∂A. (iii) Let 0 < b < 1. Let 0 < r < min{b, 1 − b}. Then, Br(b) = (b − r, b + r) is contained in A. Indeed, if x ∈ Br(b), we have x > b − r > b − b = 0 and x < b + r < b + 1 − b = 1. Thus, b < ∂A. (iv) let b = 1. Let r > 0. The ball Br(1) = (1 − r, 1 + r) contains 1 + r 2 , which does not belong to A. If r > 1 2 , the Page 144 4.7 Extreme value theorem MATH1017 ball Br(1) = (1 − r, 1 + r) contains 1 2 , that belongs to A. If 0 < r < 1 2 , the ball Br(1) = (1 − r, 1 + r) contains 1 − r 2 , which is in A. Thus, 1 ∈ ∂A. (v) Let b > 1. If 0 < r < b − 1, the ball Br(1) = (1 − r, 1 + r) does not contain points of A. Indeed, if x ∈ Br(1) = (1 − r, 1 + r), we have x > b − r > b − (b − 1) = 1. Thus, b < ∂A. From the previous example, it is clear that the elements of ∂A can belong or not to A. Exercise Show that if A = (−∞, 2) ∪ {4}, then ∂A = {2, 4}. Definition 46 [Closed Set] Let A ⊆ R. We say that A is closed if ∂A ⊆ A. Example The set [0, 1) is not closed. The set [0, 1] is closed, since ∂ [0, 1] = {0, 1} ⊆ [0, 1]. The set R is closed, because ∂(R) = ∅ ⊂ R. Exercise Show that the sets (−∞, 0] and {−1} are also closed. Definition 47 [Compact Set] The set A ⊆ R is said to be compact if it is closed and bounded. Example Let a, b ∈ R with a ≤ b. The closed interval [a, b] is compact. The interval [a, b) is not compact because it is not closed, and the interval [a, +∞) is not compact because it is not bounded. 4.7 Extreme value theorem The following result is one of the fundamental theorems in Analysis. Theorem 65 [Extreme Value Theorem – Weierstrass Theorem] Let A ⊆ R be non-empty and compact. Let f : A −→ R be continuous. Then, f is bounded and it has maximum and minimum. Remark 41 It is interesting to see that none of the assumptions in Weierstrass theorem can be eliminated (but this does not mean that the assumptions are necessary!): (i) Consider the function f : [0, +∞) −→ R x 7→ x. In this case the domain is closed (because ∂ [0, +∞)  = {0}) and f is continuous. However, the domain is not bounded. In this case, f is not upper bounded, and therefore it does not have a Page 145 of 1 4.8 Bolzano’s theorem MATH1017 maximum; (ii) Consider the function f : (0, 1] −→ R x 7→ 1 x . In this case the domain is bounded, and f is continuous. However, the domain is not closed. In this case, f is not upper bounded, and therefore it does not have a maximum; (iii) Consider the function f : [0, 1] −→ R x 7→ ( x if x ∈ (0, 1) 1 2 if x ∈ {0, 1} In this case the domain is compact (it is bounded and closed), but f is not continuous. We have f([0, 1]) = (0, 1), and therefore f is bounded, but it does not have maximum nor minimum. 4.8 Bolzano’s theorem This is another fundamental result: it states that the image of an interval through a continuous function is an interval. Theorem 66 [Bolzano’s Theorem] Let I ⊆ R be an interval. Let f : I −→ R be continuous. Then, f(I) is an interval. As a simple consequence of Theorem 66, if we have a continuous function f defined over an interval I, if f takes two values f(a) and f(b) at two points a, b ∈ I, if we fix an arbitrary y ∈ f(a), f(b) , we can say that the equation f(x) = y has at least a solution in I. This is often referred to as intermediate value theorem: ∃ x ∈ [a, b] : f(x) = y. Setting y = 0, we obtain the following result on the zeros of a continuous function: if f : I −→ R is continuous, if a, b ∈ I are such that f(a) < 0 and f(b) > 0 or f(a) > 0 and f(b) < 0, then, ∃ x ∈ (a, b) : f(x) = 0. The assumption that I be an interval is essential for this conclusion. Indeed, if f : R \ {0} −→ R is f(x) = sgn(x), then f is continuous and takes the values 1 and −1, but it does not take the value 0. Example Let f : R −→ R x 7→ x 5 + x + 1. We can say that the equation f(x) = 0 in the unknown x ∈ R has solutions. Indeed, f(0) = 1 > 0 and f(−1) = −1 < 0, Page 146 of 175 4.8 Bolzano’s theorem MATH1017 and therefore there exists x ∈ (−1, 0) such that f(x) = 0. It follows that f(x) = 0 has solutions, and in (−1, 0) there is at least one solution. We now study an interesting application of Bolzano’s theorem. Example Let P be a polynomial function with real coefficients and degree n ≥ 1. We assume that n is odd. Then, the equation P(x) = 0 has at least a real solution. To verify this, we first assume with no loss of generality that an = 1. In fact, the polynomial function R −→ R x 7→ a −1 n P(x) has the same zeros of P. Then, we can assume P(x) = x n + an−1 x n−1 + . . . + a1 x + a0, where n is odd. We have seen that lim x → −∞ P(x) = −∞ and lim x → +∞ P(x) = +∞. Therefore, P takes both positive and negative values. From Bolzano’s theorem, we find that 0 belongs to the image of P. 4.8.1 Continuity of the inverse function Theorem 67 Let I be an interval of R. Let f : I −→ R be continuous and strictly monotonic. Then: (i) f(I) is an interval; (ii) f : I −→ f(I) is bijective and f −1 is strictly monotonic (of the same kind of f ); (iii) f −1 is continuous. Partial proof (i) follows from Bolzano’s theorem (and the monotonicity is not necessary). Consider (ii). Suppose that f is increasing. Suppose by contradiction that f −1 is not increasing, i.e., there exist y1, y2 ∈ f(I) with y1 < y2 and f −1 (y1) ≥ f −1 (y2). Since f is increasing, f f −1 (y1)  ≥ f f −1 (y2)  ⇒ y1 ≥ y2, which is a contradiction. Notice that in this argument we have not used the fact that I is an interval. We do not prove (iii), which is the most technical and delicate point. Remark 42 The inverse of an injective and continuous function is not necessarily continuous. Consider B = [0, 1] ∪ (2, 3] and f : B −→ [0, 2] x 7→ ( x if x ∈ [0, 1] x − 1 if x ∈ (2, 3]. Page 147 of 1 4.8 Bolzano’s theorem MATH1017 Using Theorem 55 and (ii) in Theorem 58, we see that f is continuous.a We have also f(A) = [0, 2] (so f is surjective), and f is injective. The inverse is f −1 : [0, 2] −→ B y 7→ ( y if y ∈ [0, 1] y + 1 if y ∈ (1, 2], which is not continuous. 1 2 3 1 2 3 1 2 3 1 2 3 Indeed, lim y → 1 + f −1 (y) = 2 , f −1 (1). a Indeed, defining A = [0, 1], from the graph it is clear that there exists a ball Br(1) such that Br(1) ∩ B  \ {1} ⊆ A, and therefore, from Theorem 55, since the limit of the restriction f |[0,1] as x → 1 is 1, the limit of f as x → 1 is also equal to 1, i.e., lim x → 1 f(x) = 1. On the other hand, 1 ∈ A ∩ D(A), and by (ii) in Theorem 58 the function is continuous at 1 if and only if the limit lim x → 1 f(x) exists and it is equal to f(1) = 1. Example Consider the restriction of the sine function to the interval h − π 2 , π 2 i . This function is continuous and increasing. Its image is [−1, 1]. x y π 2 − π 2 1 −1 Indeed, the image is contained in [−1, 1] from (i) in Theorem 32. Moreover, sin  − π 2  = −1 and sin  π 2  = 1, and from Bolzano’s theorem [−1, 1] ⊆ sin h− π 2 , π 2 i. We define the so-called “inverse sine” function arcsin def =  sin | [− π 2 , π 2 ] −1 . Its domain is [−1, 1] and its image is h − π 2 , π 2 i . From Theorem 67, the inverse sine function is increasing and continuous. Given y ∈ [−1, 1], it is convenient to think about arcsin y as the unique solution x belonging to the interval h − π 2 , π 2 i of the equation sin x = y. Thus, ∀ y ∈ [−1, 1], sin(arcsin y) = y. Page 148 of 17 4.8 Bolzano’s theorem MATH1017 The condition arcsin(sin x) = x holds only if x ∈ h − π 2 , π 2 i . Indeed, arcsin takes values only in this interval. For example, arcsin(sin π) = arcsin 0 = 0. x y π 2 − π 2 1 −1 Suppose that we want to find all the solutions to the equation sin x = y, where x in an unknown and y ∈ [−1, 1] (if y < [−1, 1], there are no real solutions because the image or the (real) sine is [−1, 1]). For example, sin x = 1 2 1 Then, x = arcsin(1/2) = π/6 is the solution in the interval h − π 2 , π 2 i , and the other one within (−π, π] is given by π − arcsin 1 2 = π − π 6 = 5 6 π. The set of solutions is  π 6 + 2 k π     k ∈ Z  ∪ ( 5 6 π + 2 k π     k ∈ Z ) . Example Consider the restriction of the cosine function to the interval [0, π]. This function is continuous and decreasing. Its image is [−1, 1]. x y π 2 π 1 −1 Indeed, the image is contained in [−1, 1] from (i) in Theorem 32. Moreover, cos 0 = 1 and cos π = −1 and from Page 149 of 175 4.8 Bolzano’s theorem MATH1017 Bolzano’s theorem [−1, 1] ⊆ cos([0, π]). We define the so-called “inverse cosine” function arccos def = cos|[0,π] −1 . Its domain is [−1, 1] and its image is [0, π]. From Theorem 67, the inverse cosine function is increasing and continuous. Given y ∈ [−1, 1], it is convenient to think about arccos y as the unique solution x belonging to the interval [0, π] of the equation cos x = y. Thus, ∀ y ∈ [−1, 1], cos(arccos y) = y. The condition arccos(cos x) = x holds only if x ∈ [0, π]. x y π 2 π −1 1 Example Recall the tangent function. π 2 f(x) = tan x Consider the restriction of the tangent function to the interval  − π 2 , π 2  . Page 150 of 17 4.9 Some important limits MATH1017 − π 2 π 2 This function is continuous and increasing. Moreover, lim x → − π 2 + tan x = −∞ and lim x → π 2 − tan x = +∞. From Bolzano’s theorem, the image of the restriction is an interval which is neither bounded from above nor from below. It is easy to see than tan − π 2 , π 2  = R. Indeed, given any y ∈ R, since the image is not bounded from above, there exists y2 ∈ tan − π 2 , π 2  with y ≤ y2. On the other hand, since tan − π 2 , π 2  is not bounded from below, there exists y1 ∈ tan − π 2 , π 2  with y1 ≤ y. Thus, from Bolzano’s theorem, y ∈ tan − π 2 , π 2 . We define the inverse tangent as arctan = tan | (− π 2 , π 2 ) −1 . From Theorem 67, the inverse tangent is increasing and continuous. Given y ∈ R, arctan y is the only solution x ∈  − π 2 , π 2  of the equation tan x = y. Thus, ∀ y ∈ R, tan(arctan y) = y, but arctan(tan x) = x holds only if x ∈  − π 2 , π 2  . π 2 − π 2 4.9 Some important limits In this section we consider some limits that are particularly important and useful. Example Consider the limit lim x → +∞ 1 + 1 x !x . (105) Page 151 of 17 4.9 Some important limits MATH1017 The natural domain of the function in the limit f(x) =  1 + 1 x x is defined by the condition 1 + 1 x > 0, i.e., x+1 x > 0. Hence, the natural domain of f is (−∞, −1) ∪ (0, +∞), and +∞ is a generalized limit point of this set. Thus, it makes sense to ask ourselves what the limit is. Since the domain is (−∞, −1) ∪ (0, +∞) and we are evaluating the limit as x → +∞, we can assume x > 0 (implicitly, we are using the theorem of the limit of the restriction). The table is not useful, because when ℓ = 1 and m = +∞ it shows a question mark ?. It is possible to show that this limit exists, and it is equal to a certain positive real number, that we call Euler’s constant or Napier’s constant e: e def = lim x → +∞ 1 + 1 x !x . (106) It is also possible to prove that 2 < e < 3 and e < Q. Before we proceed with the following examples, we recall the result of the limit of the composition Theorem 61. Let A ⊆ R and B ⊆ R. Let f : A −→ R and g : B −→ R, and f(A) ⊆ B. Let x0 ∈ D˜ (A), and suppose that lim x → x0 f(x) = y0, that y0 ∈ D˜ (B) \ B and suppose that ℓ = lim y → y0 g(y) exists in R. Then, g ◦ f is convergent at x0 and lim x → x0 (g ◦ f)(x) = ℓ. Example We show that lim x → +∞ 1 − 1 x !x = 1 e . (107) The natural domain of the function in the limit is the set of x ∈ R satisfying the condition 1 − 1 x > 0, i.e., x−1 x > 0. Hence, the natural domain is (−∞, 0) ∪ (1, +∞). However, since the limit is for x → +∞, we can assume x > 1. With this choice of x we have 1 − 1 x !x = x − 1 x !x =  x x − 1 x −1 = " 1 + 1 x − 1 !x #−1 =   1 + 1 x − 1 !x−1 1 + 1 x − 1 !  −1 x→+∞ −−−−−−−→ (e · 1)−1 = 1 e . In the last line, we have used Theorem 61 twice, without probably being aware of it: first when we assumed that lim x → +∞ 1 + 1 x − 1 !x−1 is the same as lim x → +∞ 1 + 1 x !x . This case involves writing  1 + 1 x−1 x−1 as g f(x)  . In this case, f(x) = x − 1 and g(y) =  1 + 1 y y . A more complete description is given as f : (−∞, 0) ∪ (1, +∞) −→ R x 7→ x − 1 and g : (−∞, −1) ∪ (0, +∞) −→ R y 7→  1 + 1 y y , where the domain of g has been obtained in the previous example and where the domain of f ensures that the image of f is contained in the domain of g. Notice that the domain of f is, once again, the natural domain of the function at hand. You can immediately see that y0 = lim x → +∞ f(x) = +∞, and therefore lim y → +∞ g(y) = e by definition of e. The second case is the interchange by the limit and the inverse. This is also a case where Theorem 61 has been implicitly used. Indeed, suppose that we have the limit lim x → +∞ α(x) −1 , where α : A −→ R. The natural domain of the function Page 152 of 1 4.9 Some important limits MATH1017 within the limit is A ∩ {x ∈ R | α(x) , 0}. We can define two functions f : A ∩ {x ∈ R | α(x) , 0} −→ R x 7→ α(x) and g : R ∗ −→ R y 7→ 1 y , so that α(x) −1 = (g ◦ f)(x) = g f(x)  . Now, y0 = lim x → +∞ f(x), and lim y → y0 g(y) = lim y → y0 1 y . Now, if y0 , 0 and is finite, function g is continuous at y0, and applying Theorem 60 we find immediately that the limit is 1/y0 (as in this example). If y0 = 0, the limit might be ±∞, and if y0 = ±∞ the limit is zero. In every case, y0 < R ∗ , and we can write lim y → y0 g(y) = 1 lim x → +∞ f(x) . This is exactly the limit of the composition, i.e., it is exactly the value of the limit lim x → +∞ α(x) −1 . Example We want to show that lim x → −∞ 1 + 1 x !x = e. We observe that 1 + 1 x > 0 if x < −1 or x > 0; hence, the limit is well defined, since −∞ is a generalized limit point of the set (−∞, −1) ∪ (0, +∞). For x < −1, we have 1 + 1 x !x = g(−x), with g(y) =  1 − 1 y −y . Since lim x → −∞ (−x) = +∞, from Theorem 61a we find lim x → −∞ 1 + 1 x !x = lim y → +∞ " 1 − 1 y !y #−1 = e. aWe can use this result in this particular example by defining f : (−∞, −1) ∪ (0, +∞) −→ R x 7→ −x and g : (−∞, 0) ∪ (1, +∞) −→ R y 7→  1 − 1 y −y , where the domain of g has been selected to ensure that 1 − 1 y > 0, whereas the domain of f has been found to ensure that the image of f is contained in (in this case it coincides with) the domain of g. Notice that the domain of f is exactly the natural domain of the function  1 + 1 x x . We have also (g ◦ f)(x) = g f(x)  = g(−x) =  1 + 1 x x . Since y0 = lim x → −∞ f(x) = +∞ and lim y → y0 g(y) = 1 e !−1 = e, we obtain the result. In what follows, we will call “natural logarithm” the function loge . We will use the symbol ln. Example Consider lim x → 0 ln(1 + x) x . (108) The expression ln(1+x) x is defined for x ∈ A = (−1, 0) ∪ (0, +∞). We begin by determining lim x → 0 + ln(1 + x) x . Page 153 of 4.9 Some important limits MATH1017 We can write ln(1+x) x as the composition g ◦ f of the functions f : A −→ R x 7→ 1 x and g : (−∞, −1) ∪ (0, +∞) −→ R y 7→ y ln  1 + 1 y  , where the domain of g ensures that 1 + 1 y > 0, and the domain of f ensures that 1 x ∈ (−∞, −1) ∪ (0, +∞) (which is the same as 1 x < −1 or 1 x > 0, i.e., x+1 x < 0 or x > 0, and this is satisfied if and only if −1 ≤ x < 0 or x > 0, i.e., for all x ∈ A). We have indeed g f(x)  = g 1 x ! = 1 x ln(1 + x). We can apply again Theorem 61. From lim x → 0 + 1 x = +∞, and lim y → +∞ y ln 1 + 1 y ! = lim y → +∞ ln " 1 + 1 y !y # = ln " lim y → +∞ 1 + 1 y !y # = ln e = 1 from Theorem 60 (because the logarithm is continuous), we obtain lim x → 0 + ln(1 + x) x = 1. In a similar way, it is easy to see that lim x → 0 − ln(1 + x) x = 1, because, since lim x → 0 − 1 x = −∞, we have lim x → 0 − ln(1 + x) x = lim y → −∞ y ln 1 + 1 y ! = lim y → −∞ ln " 1 + 1 y !y # = 1. Example We verify that lim x → 0 e x − 1 x = 1. The expression is defined for x , 0. In this case e x − 1 x = e x − 1 ln(e x ) . Thus, we can define f : R ∗ −→ R x 7→ e x and g : (0, +∞) \ {1} −→ R y 7→ y−1 ln y , Page 154 of 17 4.9 Some important limits MATH1017 where the domain of f ensures that e x ∈ (0, +∞) (which is always satisfied), and e x , 1, i.e., x , 0. Since lim x → 0 e x = 1, we have lim x → 0 e x − 1 x = lim y → 1 y − 1 ln y = lim y → 1 1 ln y y−1 = 1. from a previous example.a aNote that now we are still applying the theorem of limit of the composition, but without making all the steps explicit. For example, in the previous computation we are computing the limit lim x → 1 ln x x − 1 . We can essentially change variable, by viewing the function ln x x−1 as g ◦ f , where g(y) = ln(1+y) y and f(x) = x − 1. Since lim x → 1 f(x) = 0 and lim y → 0 ln(1 + y) y = 1 from the previous example, we obtain lim x → 1 ln x x − 1 = 1. We also use the limit lim x → 1 1 ln x x−1 . This is the composition of f(x) = ln x x−1 with g(y) = 1 y , and since lim x → 1 f(x) = 1 and lim y → 1 g(y) = 1, we conclude that the limit is 1. Example Let α ∈ R. We verify that lim x → 0 (1 + x) α − 1 x = α. (109) The expression is defined for x ∈ (−1, 0) ∪ (0, +∞). The conclusion is obvious if α = 0. For α , 0 we have (1 + x) α − 1 x = e α ln(1+x) − 1 α ln(1 + x) α ln(1 + x) x . (110) The second factor in the right hand-side tends to α. Since lim x → 0 α ln(1 + x) = 0, we obtain lim x → 0 e α ln(1+x) − 1 α ln(1 + x) = lim y → 0 e y − 1 y = 1. Remark 43 We will study an important result, called L’Hopital’s Theorem, which will allow us to ˆ compute limits such as lim x → 0 sin x x = 1 and lim x → +∞ ln x x α = 0 (111) for α > 0. Example Let α ∈ R and a > 1. We show that lim x → +∞ x α a x = 0. (112) If α ≤ 0, the conclusion follows immediately from the table for the quotient. Suppose α > 0. In this case we have an Page 155 of 175 4.9 Some important limits MATH1017 indeterminate form +∞ +∞ . For x > 0 we have x α a x = loga (a x ) (a x ) 1 α !α . Since lim x → +∞ a x = +∞, we can change variable with y = a x , recalling the formula logb x = logb a · loga x: lim y → +∞   loga y y 1 α   α = lim y → +∞   loga e · ln y y 1 α   α = 0, since loga e > loga 1 = 0 and applying the second of (111) and Theorem 61. Example We show that for all α > 0 lim x → 0 x α ln x = 0. (113) For x > 0 x α ln x = − ln(x −1 ) (x −1 ) α . Since lim x → 0 x −1 = +∞ (the expression makes sense only for x > 0), we obtain lim x → 0 x α ln x = lim y → +∞ − ln y y α ! = 0. Example We want to find the limits at the accumulation points of the natural domain of the expression √3 x ln(|x|) ln(|x + 1|) . First, we want to find the natural domain. The term √3 x is defined for x ≥ 0, while ln(|x|) is defined for x , 0. Finally, ln(|x + 1|) is defined for x , −1. Moreover, ln(|x + 1|) , 0 if x , 0. Hence, the natural domain if R ∗ + . The boundary of R ∗ + is {0}. We therefore need to study lim x → 0 √3 x ln(|x|) ln(|x + 1|) = lim x → 0 √3 x ln x ln(x + 1) . This is an indeterminate form 0 0 . For x > 0 √3 x ln x ln(x + 1) = x − 2 3 ln x ln(x+1) x x→0 −−−−−−−→ −∞. Here, in the numerator we used the fact that lim x → 0 ln x x α = −∞, for α > 0. Now, we study lim x → +∞ √3 x ln x ln(x + 1) . This is an indeterminate form +∞ +∞ . Since, for x > 0, ln(x + 1) = ln x + ln 1 + 1 x ! Page 156 of 175 4.10 Limits of sequences MATH1017 we can write √3 x ln x ln(x + 1) = √3 x ln x ln x + ln  1 + 1 x  = √3 x 1 + ln(1+ 1 x ) ln x . Since lim x → +∞ ln  1 + 1 x  ln x = 0 +∞ = 0, we obtain lim x → +∞ √3 x 1 + ln(1+ 1 x ) ln x = lim x → +∞ √3 x = +∞. 4.10 Limits of sequences Sequences are functions for which it makes sense to talk about the limit as x → +∞. Let A be a set. A sequence of values of A is a function N −→ A. We use the notation (an)n ∈ N instead of f : N −→ A n 7→ f(n). Hence, with this notation f(n) = an for all n ∈ N. Remark 44 We have already observed that N does not have accumulation points (all its points are isolated points), but it is not bounded from above, and therefore it makes sense to ask ourselves if the limit lim n → +∞ an exists. This is only a particular case of Definition 34. It follows that the condition for a sequence (an)n ∈ N∗ to converge to a certain limit ℓ ∈ R is ∀ ε > 0, ∃ N ∈ R : ∀ n ∈ N, n > N ⇒ |an − ℓ| < ε. Likewise, the condition for divergence to +∞ (positive divergence) is ∀ M ∈ R, ∃ N ∈ R : ∀ n ∈ N, n > N ⇒ an > M, while the one for divergence to −∞ (negative divergence) is ∀ M ∈ R, ∃ N ∈ R : ∀ n ∈ N, n > N ⇒ an < M. Notice that in the three definitions can be equivalently expressed by requiring N ∈ N instead of N ∈ R (why?). The only result on sequences that we consider is the following. Theorem 68 Let (an)n ∈ N be a non-decreasing sequence of values of R. Then, lim n → +∞ an exists in R. If the sequence is bounded from above, the limit is real and coincides with sup{an | n ∈ N}. If the sequence is not bounded from above, the limit is +∞. Page 157 of 175 4.11 Asymptotic expansions MATH1017 Proof Suppose that (an)n ∈ N is bounded from above. Let S = sup n ∈ N an. We show that lim n → +∞ an = S . Hence, we need to show that ∀ ε > 0, ∃ N ∈ N : ∀ n ∈ N, n > N ⇒ |an − S | < ε. Let ε > 0. Hence, S − ε is not an upper bound of the sequence. It follows that there exists p ∈ N such that ap > S − ε. Let n ∈ N be such that n > p. Then, S − ε < ap ≤ an. On the other hand, from the definition of supremum, we have also an ≤ S < S + ε, so that we obtain |an − S | < ε for all n > p. Hence, choosing N = p proves the statement. Now, we assume that the sequence is not bounded from above. We must show that ∀ M ∈ R, ∃ N ∈ R : ∀ n ∈ N, n > N ⇒ an > M. Let M ∈ R be arbitrary. Since M is not an upper bound for {an | n ∈ N}, there exists p ∈ N such that M < ap. It follows that, if n > p, we have M < ap ≤ an. The statement follows taking N = p. A similar result obviously holds for non-increasing sequences. Theorem 69 Let (an)n ∈ N be a non-increasing sequence of values of R. Then, lim n → +∞ an exists in R. If the sequence is bounded from below, the limit is real and coincides with inf{an | n ∈ N}. If the sequence is not bounded from below, the limit is −∞. Remark 45 With some abuse of notation, given a sequence (an)n ∈ N, instead of writing lim n → +∞ an, we will be writing instead lim n → ∞ an. (114) The abuse of notation comes from the fact that ∞ without sign normally has a different meaning, that we will explain later. However, when the notation (114) is used, we write ∞ but, as a matter of fact, we mean +∞. 4.11 Asymptotic expansions Consider a function f : (α, +∞) −→ R, where α ∈ R. We want to approximate f(x), as x → +∞, with an affine function g(x) = a x + b, with a, b ∈ R (which is, geometrically, a straight line), so that the approximation error ϵ(x) vanishes as x → +∞. This is equivalent to requiring that f(x) = a x + b + ϵ(x), where lim x → +∞ ϵ(x) = 0. This is equivalent to saying that f(x) − a x = b + ϵ(x) x→+∞ −−−−−→ b, Page 158 of 175 4.11 Asymptotic expansions MATH1017 which is in turn equivalent to saying that b = lim x → +∞ f(x) − a x . However, we still need to find a. We notice that we can write f(x) = a x + b + ϵ(x) as f(x) x = a + b + ϵ(x) x x→+∞ −−−−−→ a, and therefore a = lim x → +∞ f(x) x . It follows that a = lim x → +∞ f(x) x and b = lim x → +∞ f(x) − a x , and they are unique. The function g(x) = a x + b thus obtained, which approximates f(x) as x → +∞ with an error that vanishes as x → +∞, is a so-called affine asymptotic approximation of f as x → +∞. Geometrically, the equation f(x) = a x + b + ϵ(x) means to approximate the graph of f with the straight line y = a x+b, so that the distance between the graph of f with the straight line tends to 0 as x → +∞. This straight line is called asymptote of f as x → +∞. Definition 48 Let α ∈ R. Let f : (α, +∞) −→ R. We say that f has an affine asymptotic expansion as x → +∞ if there exist a, b ∈ R such that f(x) = a x + b + ox → 1(1). The function g : R −→ R x 7→ a x + b (115) is called “affine asymptotic expansion” or “affine asymptotic approximation” of f as x → +∞. Theorem 70 Let α ∈ R. Let f : (α, +∞) −→ R. Then, f has an affine asymptotic expansion as x → +∞ if and only if (i) the limit lim x → +∞ f(x) x exists in R; (ii) the limit lim x → +∞ f(x) − a x exists in R, where a = lim x → +∞ f(x) x . The function f can admit an affine asymptotic approximation as x → +∞ or not. If it does, this approximation is unique, and the straight line y = a x + b is called asymptote as x → +∞. Page 159 of 1 4.11 Asymptotic expansions MATH1017 Example Let f : R \ {2} −→ R x 7→ x 2 − 1 x − 2 We have a = lim x → +∞ f(x) x = lim x → +∞ x 2 − 1 x (x − 2) = 1 and b = lim x → +∞ f(x) − a x = lim x → +∞ x 2 − 1 x − 2 − x ! = lim x → +∞ 2 x − 1 x − 2 = 2, so that y = x + 2 is an asymptote as x → +∞. x y y = x + 2 From the graph we can see that the line y = x+2 is also an asymptote as x → −∞, and the way to see is essentially the same: lim x → −∞ f(x) x = lim x → −∞ x 2 − 1 x (x − 2) = 1 and b = lim x → −∞ f(x) − a x = lim x → −∞ 2 x − 1 x − 2 = 2. If a = 0, the asymptote is horizontal. Suppose that lim x → +∞ f(x) = 0. It follows that f(x) = ox→+∞(1), so that f has an affine asymptotic approximation as x → +∞, and the asymptote is y = 0. If, instead, lim x → +∞ f(x) = ℓ ∈ R ∗ , then lim x → +∞ f(x) − ℓ = 0, which implies f(x) − ℓ = ox→+∞(1). It follows that f(x) = ℓ + ox→+∞(1). This says that f has an affine asymptotic approximation as x → +∞, and the asymptote is y = ℓ. In both cases (i.e., ℓ = 0 and ℓ , 0), if lim x → +∞ f(x) = ℓ, then y = ℓ is a horizontal asymptote for f as x → +∞. Page 160 of 1 4.11 Asymptotic expansions MATH1017 ℓ ℓ Example Let, for x ∈ R+, f(x) = 1 − e −x We have a = lim x → +∞ f(x) x = lim x → +∞ 1 − e −x x = 0 and b = lim x → +∞ f(x) = lim x → +∞ 1 − e −x  = 1. Hence, y = 1 is an asymptote as x → +∞. x y From the graph we can see that the line y = x+2 is also an asymptote as x → −∞, and the way to see is essentially the same: lim x → −∞ f(x) x = lim x → −∞ x 2 − 1 x (x − 2) = 1 and b = lim x → −∞ f(x) − a x = lim x → −∞ 2 x − 1 x − 2 = 2. All these considerations can be adapted, mutatis mutandis (i.e., changing the things that need to be changed) to the case where x → −∞. What we have seen on asymptotic expansions is part of a broader theory that aims at approximating functions as a sum of powers an x n , with n ∈ Z, so that if m is the largest exponent and p is the smallest exponent, we can write f(x) = am x m + am−1 x m−1 + . . . + ap x p + o(x p ). In the case of the affine asymptotic expansion, we require m = 1 and p = 0. If we want a better approximation, we would look for c ∈ R such that f(x) = a x + b + c x + o 1 x ! , and we would have p = −1. We will see other cases of asymptotic approximation. 4.11.1 Vertical asymptotes Vertical asymptotes cannot be obtained as a particular case of affine asymptotic expansions. Let f : (α, a) −→ R, where a, α ∈ R. If lim x → a − f(x) = ±∞, Page 161 of 1 4.11 Asymptotic expansions MATH1017 then we say that the line x = a is a vertical asymptote of f as x → a − . Similar considerations can be used to define vertical asymptotes as x → a + . a a a a Example Let f : R ∗ + −→ R x 7→ 1 x . Then, f has a horizontal asymptote as x → +∞, and a vertical asymptote as x → 0 + , with equation x = 0. x y Example Let f : R −→ R x 7→ √ x 2 + 1. The limit lim x → +∞ f(x) x = lim x → +∞ √ x 2 + 1 x Page 162 of 175 MATH1017 exists in R and is equal to 1. Moreover, defining a = 1, the limit lim x → +∞ f(x) − a x = lim x → +∞ √ x 2 + 1 − x  = lim x → +∞ √ x 2 + 1 − x  √ x 2 + 1 + x √ x 2 + 1 + x = lim x → +∞ 1 √ x 2 + 1 + x = 0 exists. Defining b = 0, the asymptote is y = a x + b, i.e, y = x. Let us now consider x → −∞: the limit lim x → −∞ f(x) x = lim x → −∞ √ x 2 + 1 x = lim x → −∞ −x q 1 + 1 x 2 x = lim x → −∞ − r 1 + 1 x 2 exists in R and is equal to −1. Defining a = −1, the limit lim x → −∞ f(x) − a x = lim x → −∞ √ x 2 + 1 + x  = lim x → −∞ √ x 2 + 1 + x  √ x 2 + 1 − x √ x 2 + 1 − x = lim x → −∞ 1 √ x 2 + 1 − x = 0 exists. Defining b = 0, the asymptote is y = a x + b, i.e, y = −x. x y 5 Complement: Limits for complex numbers The definition of limit can easily be generalised to functions f : A −→ C, where A ⊆ C. Given ℓ ∈ C and z0 ∈ C (and also defining a notion of derived set for C), we say that f converges to ℓ as z → z0 if ∀ ϵ > 0, ∃ δ > 0 : ∀ z ∈ C, 0 < |z − z0| < δ ⇒ | f(z) − ℓ| < ε. This time, the symbol | · | denotes the modulus of a complex number. This definition captures intuitively what we would like it to mean: if we want f(z) to be within an ε of ℓ (or, in other words, if we want f(z) to be inside a circle of radius ε centred at ℓ) we need z to be inside a circle centred at z0 of radius δ: Page 163 MATH1017 x y f z0 δ ℓ ε u v The problem is the definition of limit as z goes to ±∞, because in C it makes no sense to talk about +∞ and −∞. However, we can still define a notion of ∞ without sign: it satisfies the property ∀ z ∈ C, |z| < ∞. Hence, to say that z approaches ∞ means that its modulus can be made arbitrarily large, regardless of the direction that we are choosing. Hence, • If z0 ∈ C and ℓ = ∞, we write lim z → z0 f(z) = ∞ when ∀ M > 0, ∃ δ > 0 : ∀ z ∈ C, 0 < |z − z0| < δ ⇒ | f(z)| > M. • If z0 = ∞ and ℓ ∈ C, , we write lim z → ∞ f(z) = ℓ when ∀ ϵ > 0, ∃ N > 0 : ∀ z ∈ C, |z| > N ⇒ | f(z) − ℓ| < ε. • Finally, when both z0 and ℓ are equal to ∞, we have lim z → ∞ f(z) = ∞ if and only if ∀ M > 0, ∃ N > 0 : ∀ z ∈ C, |z| > N ⇒ | f(z)| > M. Importantly, once again we can capture all these particular cases using the notion of neighborhood. The neighborhood of a complex number is easy to define: U is a neighborhood of z0 if there exists r > 0 such that Br(z0) = {z ∈ C | |z − z0| < r} ⊆ U, and U is a neighborhood of ∞ if if its complement is bounded. For example, the complement of a disc or of a square are neighbourhoods of ∞. C We say that f(z) tends to ℓ as z tends to z0 if for every neighbourhood U of ℓ, there exists a neighbourhood V of z0 such that for every z ∈ V \ {z0} we have f(z) ∈ U. Again, the definition of limit remains the same: we simply needed to give a meaning to the notion of neighborhood for the complex case. Page 164 of 175 MATH1017 This begs the question: since C = R 2 , what happens in R 3 , R 4 , and so on? Obviously in all these spaces we do not have a signed ∞, but we can still define a notion of distance, using, instead of the absolute value, a new notion called “norm”. In this way, ∞ can be defined for R n , for all n ≥ 1. However, this is saying that ∞ is defined also for R, where we have already introduced ±∞. In other words, in R we can have +∞, −∞ and ∞. We recall that R = R ∪ {±∞}. We define S1 = R ∪ {∞} (this is a particular case of a more general definition of the so-called Riemann sphere: S n = R n ∪ {∞}; unfortunately, we cannot develop this notion further). 6 Complement: Limits in topological spaces We can define the following five topological spaces (i.e., spaces where a notion of “closeness” can be defined): R, R(+) , R(−) , R, S1. We denote by TR the set of these spaces: TR def = {R, R(+) , R(−) , R, S1}. Each one of these topological spaces comes with its own notion of neighborhood: given X ∈ TR and x0 ∈ X, the set U is a neighborhood of x0 if the following conditions, in each case, hold: • X = R: ∃ r > 0 : (x0 − r, x0 + r) ⊆ U; • X = R(+) : ∃ r > 0 : (x0, x0 + r) ⊆ U; • X = R(−) : ∃ r > 0 : (x0 − r, x0) ⊆ U; • We have the three cases for X = R: – x0 < {±∞}: ∃ r > 0 : (x0 − r, x0 + r) ⊆ U; – x0 = +∞: ∃ a ∈ R : (a, +∞) ⊆ U; – x0 = −∞: ∃ a ∈ R : (−∞, a) ⊆ U; • We have the two cases for X = S1: – x0 , ∞: ∃ r > 0 : (x0 − r, x0 + r) ⊆ U; – x0 = ∞: ∃ a > 0 : (−∞, −a) ∪ (a, +∞) ⊆ U. Given X ∈ TR and x0 ∈ X, we denote by NX(x0) the set of neighborhoods of x0. Let A ⊆ R, X ∈ TR, and x0 ∈ X. We say that x0 is a limit point for A with respect to the topological space X if ∀ V ∈ NX(x0), (A ∩ V) \ {x0} , ∅. We denote by DX(A) the set of limit points of A. We can now define the notion of limit and convergence. Page 165 of 175 MATH1017 Let A ⊆ R. Let X, Y ∈ TR. Let x0 ∈ DX(A). Let f : A −→ R. Let ℓ ∈ Y. We say that f converges to ℓ as x approaches x0 with respect to the topological spaces X and Y if ∀ U ∈ NY (ℓ), ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0}, f(x) ∈ U. As you can see, the definition of limit involves two neighborhoods: one of x0, which lives in the domain (or in the derived set of the domain) and another that lives in the codomain. Hence, the definition depends hinges a notion of closeness in the domain of f and in a notion of closeness in the codomain, which may be entirely different and independent from the previous one. Example The problem of finding the limit lim x → 0 1 x is not well posed. x y f : R ∗ −→ R x 7→ 1 x Indeed, it does not exist with respect to (R, R), because the function does not converge to a real number as x approaches 0. It does not exist with respect to (R, R), because from the right the limit would be +∞ and from the left it would be −∞. However, it exists with respect to (R(+) , R), which means that we are considering, in essence, lim x → 0 + 1 x , and in this case the limit is +∞ ∈ R. Clearly, it also exists with respect to (R(−) , R) and in this case it is −∞. However, it also exists with respect to (R, S1), because for every neighborhood of ∞, say U = (−∞, −α) ∪ (α, +∞), with α > 0, the condition f(x) ∈ U becomes      1 x      > α, which is the same as |x| < 1 α , which identifies a neighborhood of 0. We also have that lim x → ±∞ f(x) = 0, but also lim x → ∞ f(x) = 0. In other words, this limit exists w.r.t. (R, R) and (S1, R). Finally, the limit lim x → +∞ f(x) exists w.r.t. (R, R(+)), and in this case we write lim x → +∞ f(x) = 0 + . Likewise, the limit lim x → −∞ f(x) exists w.r.t. (R, R(−)), and we write lim x → −∞ f(x) = 0 − . Example The function Page 166 of 175 MATH1017 x y f : R −→ R x 7→ x 3 is divergent with respect to (S1, R), and convergent with respect to (S1, S1). However, the limit as x → ∞ does not exist with respect to (S1, R). This function is convergent with respect to (R, S1) and with respect to (R, R), and divergent with respect to (R, R). The function is also convergent with respect to (R(+) , R(+)) and with respect to (R(−) , R(−)), and in this case we write, respectively, lim x → 0 + x 3 = 0 + and lim x → 0 − x 3 = 0 − . Example Consider the function x y π 4 − π 4 1 −1 f : [−1, 0) ∪ (0, 1] −→ R x 7→ arctan 1 x . This function is not convergent at 0 w.r.t. (R, R), but it is convergent at 0 w.r.t. (R(+) , R) and (R(−) , R), and in these cases we have lim x → 0 + arctan 1 x = π 4 and lim x → 0 − arctan 1 x = − π 4 . It is also convergent w.r.t. (R(+) , R(+)) and (R(−) , R(−)), and in this case lim x → 0 + arctan 1 x = π 4 − and lim x → 0 − arctan 1 x = − π 4 + . The function x y π 4 −1 1 g : [−1, 0) ∪ (0, 1] −→ R x 7→      arctan 1 x      . is convergent with respect to (R, R), and also w.r.t. (R(+) , R) and (R(−) , R). Indeed, lim x → 0 arctan 1 x = π 4 , lim x → 0 + arctan 1 x = π 4 − and lim x → 0 − arctan 1 x = π 4 − . Page 167 of 175 MATH1017 Example Consider the sequence  n 2 (−1)n  n ∈ N , whose terms are n an • • • • • • • 1 2 3 4 5 6 0, − 1 2 , 1, − 3 2 , 2, − 5 2 , 3, . . . This sequence does not admit limit with respect to (R, R), because neither the condition ∀ M > 0, ∃ N ∈ R : ∀ n ∈ N, n > N ⇒ an > M nor the condition ∀ M > 0, ∃ N ∈ R : ∀ n ∈ N, n > N ⇒ an < M is satisfied. However, it admits limit with respect to (R, S1), and the limit is ∞. Indeed, the condition ∀ M > 0, ∃ N ∈ R : ∀ n ∈ N, n > N ⇒ |an| > M is satisfied in this case: why? 7 Complement: Asymptotic comparison We have already studied a way to compare functions. We now examine this issue in more detail. Definition 49 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). We say that • f is negligible with respect to g, or • f is dominated by g, or that • g is dominates f if ∀ ε > 0, ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0}, | f(x)| ≤ ε |g(x)|. (116) In this case, we write f(x) x0 ≺≺ g(x) (Hardy notation). We denote by ox0 (g) any function f such that f(x) x0 ≺≺ g(x) (Landau notation). We notice immediately from this definition that f(x) x0 ≺≺ g(x) if and only if | f(x)| x0 ≺≺ |g(x)|. The next result links Definition 49 with the definition of negligible function given earlier. Page 168 of 175 MATH1017 Theorem 71 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Let W ∈ NX(x0) be such that g(x) , 0 for all x ∈ (W ∩ A) \ {x0}. Then, f(x) x0 ≺≺ g(x) ⇔ limx → x0 x ∈W∩A      f(x) g(x)      = 0. Proof Since the intersection of neighborhoods of a point is a neighborhood of the same point, we see that condition (116) is equivalent to ∀ ε > 0, ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ W ∩ A) \ {x0}, | f(x)| ≤ ε |g(x)|. Since for those x we have g(x) , 0, this is the same as ∀ ε > 0, ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ W ∩ A) \ {x0},      f(x) g(x)      ≤ ε, which says that limx → x0 x ∈W∩A      f(x) g(x)      = 0. Example We have lim x → +∞ |x 2 + x + 1| |x 3 + 1| = 0 ⇒ x 2 + x + 1 +∞ ≺≺ x 3 + 1. We can write also x 2 + x + 1 = o+∞(x 3 + 1). The red graph in the figure is the function x 3 + 1, and the blue one is x 2 + x + 1. We notice that saying that x 2 + x + 1 is negligible compared to x 3 + 1 as x → +∞ means, loosely speaking, that x 3 + 1 goes to +∞ much faster than x 2 + x + 1: x y We also say that x 2 + x + 1 is an infinite of order strictly smaller than the order of x 3 + 1, or that x 3 + 1 dominates x 2 + x + 1 as x → +∞. Example The expression x − x 3 + x 5 = x + o0(x 2 ) Page 169 of 175 MATH1017 means that −x 3 + x 5 = o0(x 2 ), i.e., that −x 3 + x 5 0 ≺≺ x 2 , i.e., that lim x → 0       −x 3 + x 5 x 2       = lim x → 0 | − x + x 3 | = 0. The red graph is the graph of the function x 2 , and the blue one is the graph of −x 3 + x 5 . One can see that in a neighborhood of the origin the function x 2 dominates −x 3 + x 5 . x y We say that −x 3 + x 5 is an infinitesimal of order strictly smaller than x 2 , and that x 2 dominates −x 3 + x 5 as x → 0. As x → +∞, the roles of these functions are reversed: we have x 2 +∞ ≺≺ −x 3 + x 5 , i.e., that lim x → +∞       x 2 −x 3 + x 5       = lim x → +∞ 1 | − x + x 3 | = 0. Thus, x 2 is an infinite of order strictly smaller than −x 3 + x 5 , or, in other words, −x 3 + x 5 dominates x 2 as x → +∞. Exercise Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Let W ∈ NX(x0) be such that g(x) , 0 for all x ∈ (W ∩ A) \ {x0}. Show that f(x) x0 ≺≺ g(x) ⇔ limx → x0 x ∈W∩A      g(x) f(x)      = +∞. Theorem 72 Let A ⊆ R, f, g, h : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Then, f(x) x0 ≺≺ g(x) and g(x) x0 ≺≺ h(x) ⇒ f(x) x0 ≺≺ h(x). Proof We have to prove that ∀ ε > 0, ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0}, | f(x)| ≤ ε |h(x)|. Let ε > 0. Since f(x) x0 ≺≺ g(x), then ∃ V1 ∈ NX(x0) : ∀ x ∈ (V1 ∩ A) \ {x0}, | f(x)| ≤ √ ε |g(x)|. Likewise, since g(x) x0 ≺≺ h(x), then ∃ V2 ∈ NX(x0) : ∀ x ∈ (V2 ∩ A) \ {x0}, |g(x)| ≤ √ ε |h(x)|. Let V = V1 ∩ V2, which is still in NX(x0). For every x ∈ (V ∩ A) \ {x0} we have | f(x)| ≤ √ ε |g(x)| ≤ √ ε √ ε |h(x)| = ε |h(x)|, as required. Page 170 of 175 MATH1017 The statement of the previous theorem can be written using the Landau notation: o o(h)  = o(h). Theorem 73 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Let k ∈ R ∗ . Then, (i) f(x) x0 ≺≺ g(x) ⇒ k f(x) x0 ≺≺ g(x); (ii) f(x) x0 ≺≺ g(x) ⇒ f(x) x0 ≺≺ k g(x). Proof The proof is straightforward. Let ε > 0. We only need to write the condition f(x) x0 ≺≺ g(x) using ε/|k| in place of ε. Notice that the first result of the previous theorem is true also if k = 0. In this case, the neighborhood can be chosen to be any neighborhood containing x0. However, in this case the statement of this result becomes less interesting: indeed, 0 = ox0 (g) for any function g. The second, however, requires k , 0 (why?). The statements of the previous theorem can be written using the Landau notation: (i) k o(g) = o(g); (ii) o(g) = o(k g). Exercise Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Show that f(x) x0 ≺≺ g(x) ⇔ ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0}, f(x) = 0. Theorem 74 Let A ⊆ R, f, g, h : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Then, f(x) x0 ≺≺ h(x) and g(x) x0 ≺≺ h(x) ⇒ f(x) + g(x) x0 ≺≺ h(x). Proof Let ε > 0. Since f(x) x0 ≺≺ h(x), there exists V1 ∈ NX(x0) such that for all x ∈ (V1 ∩ A) \ {x0} there holds | f(x)| ≤ ε 2 |h(x)|. Likewise, since g(x) x0 ≺≺ h(x), there exists V2 ∈ NX(x0) such that for all x ∈ (V2 ∩ A) \ {x0} there holds |g(x)| ≤ ε 2 |h(x)|. Hence, for all x ∈ (V1 ∩ V2 ∩ A) \ {x0} we have, using the triangle inequality, | f(x) + g(x)| ≤ | f(x)| + |g(x)| ≤ ε 2 + ε 2 = ε. Since V1 ∩ V2 ∈ NX(x0), the statement is proved. The statement of the previous theorem can be written using the Landau notation: o(h) + o(h) = o(h). In the notion of function negligible compared to another function around a point x0, what counts are the values of the functions in a neighborhood of x0. It is therefore natural to define the same concept for functions which do not have the same domain, but which are coincident in a suitable neighborhood of x0. Page 171 of 17 MATH1017 Definition 50 Let A, B ⊆ R, f : A −→ R and g : B −→ R, X ∈ TR, and let x0 ∈ DX(A) ∩ DX(B). We say that f is negligible with respect to g if there exists a neighborhood U ∈ NX(x0) such that U ∩ A = U ∩ B and f |U ∩ A(x) x0 ≺≺ g|U ∩ B(x). Example The functions x 7→ x √ 2 and x 7→ x are defined over R+ and R, respectively, but we can write x √ 2 0 + ≺≺ x, because both functions are defined in a right neighborhood of 0. This corresponds to the fact that the limit, w.r.t. the topological spaces R(+) and R, is lim x → 0 x √ 2 x = 0. x y We conclude with the following result, that we do not prove. Theorem 75 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Then, f(x) x0 ≺≺ g(x) if and only if ∃ U ∈ NX(x0), ∃ h : U ∩ A −→ R : f(x) = h(x) g(x) and lim x → x0 h(x) = 0. In other words, f(x) x0 ≺≺ g(x) if and only if in a neighborhood U of x0 we can write f(x) = ox0 (x) g(x). We can now introduce the notion of a function of asymptotic order smaller or equal to another. Definition 51 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). We say that f is of asymptotic order smaller or equal to g if ∃ M > 0, ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0}, | f(x)| ≤ M |g(x)|. (117) In this case, we write f(x) x0 ⪯ g(x) (Hardy notation). We denote by Ox0 (g) any function f such that f(x) x0 ⪯ g(x) (Landau notation). The symbol O is referred to as big “O”. We notice immediately from this definition that f(x) x0 ⪯ g(x) if and only if | f(x)| x0 ⪯ |g(x)|. We now want to see how this definition can be written in the case there is a neighborhood of x0 where g Page 172 of 175 MATH1017 is invertible. Theorem 76 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Let U ∈ NX(x0) be such that g(x) , 0 for all x ∈ (U ∩ A) \ {x0}. Then, f(x) x0 ⪯ g(x) ⇔ ∃ V ∈ NX(x0) :      f(x) g(x)      is bounded ∀ x ∈ (V ∩ U ∩ A) \ {x0}. Proof If f(x) x0 ⪯ g(x), condition (117) holds true. The set V ∩ U is still in NX(x0) and, for all x ∈ (V ∩ U ∩ A) \ {x0}, we can write      f(x) g(x)      ≤ M, so that     f(x) g(x)     is bounded. The converse is trivial. Unlike the condition f(x) x0 ≺≺ g(x), when a neighborhood U of x0 exists where g is non-zero (except at x0), it is not true that f(x) x0 ⪯ g(x) implies that the limit lim x → x0      f(x) g(x)      exists. For example, we have sin x +∞ ⪯ 1, because the function |sin x | is bounded by 1, but lim x → +∞ |sin x | does not exist. When we add the condition of the existence of the limit in (X, R) as x → x0, we have the following result. Theorem 77 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Let W ∈ NX(x0) be such that g(x) , 0 for all x ∈ (W ∩ A) \ {x0}. Let the limit limx → x0 x ∈W ∩ A      f(x) g(x)      (118) exist w.r.t. (X, R). Then, limx → x0 x ∈W ∩ A      f(x) g(x)      ∈ [0, +∞) ⇔ f(x) x0 ⪯ g(x). Proof Let (118) exist, and let ℓ be the value of such limit, so that ℓ ∈ [0, +∞). From the definition of limit, we know that ∀ U ∈ UR (ℓ), ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0},      f(x) g(x)      ∈ U. (119) Let M ∈ R be such that M > ℓ. The set (−∞, M) is a neighborhood of ℓ, and therefore from (119) there exists V ∈ NX(x0) such that, for all x ∈ (V ∩ A) \ {x0}, we have      f(x) g(x)      ∈ U ⇒      f(x) g(x)      ∈ (−∞, M) ⇒      f(x) g(x)      ≤ M ⇒ | f(x)| ≤ M |g(x)|. Page 173 of 175 MATH1017 In a similar way, it is possible to show that if the limit in (118) exists w.r.t. (X, R), we have limx → x0 x ∈W ∩ A      f(x) g(x)      ∈ (0, +∞] ⇔ g(x) x0 ⪯ f(x). Example We have lim x → +∞ |x 2 + x + 1| |x 3 + 1| = 0 ⇒ x 2 + x + 1 +∞ ⪯ x 3 + 1. We can write also x 2 + x + 1 = O+∞(x 3 + 1). Example We have lim x → +∞ |x 2 + x + 1| |2 x + 4| = +∞ ⇒ 2 x + 4 +∞ ⪯ x 2 + x + 1. We can write also 2 x + 4 = O+∞(x 2 + x + 1). Example We have lim x → +∞ |x 2 + x + 1| |2 x 2 + 1| = 1 2 ⇒ x 2 + x + 1 +∞ ⪯ 2 x 2 + 1 and 2 x 2 + 1 +∞ ⪯ x 2 + x + 1. We can write also x 2 + x + 1 = O+∞(2 x 2 + 1) and 2 x 2 + 1 = O+∞(x 2 + x + 1). Exercise Let A ⊆ R, f : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Show that: • 0 x0 ⪯ f(x); • f(x) x0 ⪯ g(x) ⇔ ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0}, f(x) = 0. The following result shows that the relation ≺≺ is a stronger relation that ⪯. Theorem 78 Let A ⊆ R, f : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Then, f(x) x0 ≺≺ g(x) ⇒ f(x) x0 ⪯ g(x). The proof is straightforward. Indeed, in the definition of lower or equal asymptotic order the condition has to be true for at least one constant M, the same condition must hold for every positive constant ε (however small) in the case of negligible function. This means that every function that is o(g) is also O(g). Hence, we can write o(g) = O(g). For example, x = o+∞(x 2 ) implies x = O+∞(x 2 ). However, it is not true that O(g) = o(g). For example, x 2 = O+∞(x 2 ), but x 2 , o+∞(x 2 ). The following result gives the main properties of the relation ⪯. Page 174 of 175 MATH1017 Theorem 79 Let A ⊆ R, f, g, h : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Then, (i) f(x) x0 ⪯ f(x); (ii) f(x) x0 ⪯ g(x) and g(x) x0 ⪯ h(x) ⇒ f(x) x0 ⪯ h(x); (iii) f(x) x0 ⪯ h(x) and g(x) x0 ⪯ h(x) ⇒ f(x) + g(x) x0 ⪯ h(x). Proof The first is trivial. Consider the second. We have to show that there exists M > 0 and V ∈ NX(x0) such that, for all x ∈ (V ∩ A) \ {x0}, there holds | f(x)| ≤ M |h(x)|. Since f(x) x0 ⪯ g(x), there exists N1 > 0 and V1 ∈ NX(x0) such that, for all x ∈ (V1 ∩ A) \ {x0}, there holds | f(x)| ≤ N1 |g(x)|. Since g(x) x0 ⪯ h(x), there exists N2 > 0 and V2 ∈ NX(x0) such that, for all x ∈ (V2 ∩ A) \ {x0}, there holds |g(x)| ≤ N2 |h(x)|. Since for all x ∈ (V1 ∩ V2 ∩ A) \ {x0} we have | f(x)| ≤ N1 |g(x)| ≤ N1 N2 |h(x)|, the statement is proven taking M = N1 N2 and V = V1 ∩ V2. We prove the third. We have to show that there exists M > 0 and V ∈ NX(x0) such that, for all x ∈ (V ∩ A) \ {x0}, there holds | f(x) + g(x)| ≤ M |h(x)|. Since f(x) x0 ⪯ h(x), there exists N1 > 0 and V1 ∈ NX(x0) such that, for all x ∈ (V1 ∩ A) \ {x0}, there holds | f(x)| ≤ N1 |h(x)|. Since g(x) x0 ⪯ h(x), there exists N2 > 0 and V2 ∈ NX(x0) such that, for all x ∈ (V2 ∩ A) \ {x0}, there holds |g(x)| ≤ N2 |h(x)|. Thus, for all x ∈ (V1 ∩ V2 ∩ A) \ {x0}, using the triangle inequality | f(x) + g(x)| ≤ | f(x)| + |g(x)| ≤ N1 |h(x)| + N2 |h(x)| = (N1 + N2) h(x). Hence, the claim holds taking M = N1 + N2 and V = V1 ∩ V2. Using the Landau symbols, (ii) in Theorem 79 reads as Ox0 Ox0 (g)  = Ox0 (g), and (ii) in Theorem 79 reads as Ox0 (g) + Ox0 (g) = Ox0 (g). In the notion of function of asymptotic order smaller or equal than the asymptotic order of another function around a point x0, what counts are the values of the functions in a neighborhood of the point x0. Definition 52 Let A, B ⊆ R, f : A −→ R and g : B −→ R, X ∈ TR, and let x0 ∈ DX(A) ∩ DX(B). We say that f has asymptotic order smaller or equal to g if there exists a neighborhood U ∈ NX(x0) such that U ∩ A = U ∩ B and f |U ∩ A(x) x0 ⪯ g|U ∩ B(x). Theorem 80 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Then, f(x) x0 ⪯ g(x) if and only if ∃ U ∈ NX(x0), ∃ h : U ∩ A −→ R : f(x) = h(x) g(x) and h is bounded. Definition 53 Let A ⊆ R, f, g : A −→ R, X ∈ TR, and let x0 ∈ DX(A). We say that f has the same asymptotic order of g if f(x) x0 ⪯ g(x) and g(x) x0 ⪯ f(x). In this case, we use the notation f(x) x0 ≍ g(x) (Hardy-Bourbaki notation). It follows immediately that Page 175 of 17 MATH1017 • f(x) x0 ≍ g(x) if and only if | f(x)| x0 ≍ |g(x)|; • f(x) x0 ≍ g(x) if and only if ∃ M, N > 0, ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0}, N g(x) ≤ | f(x)| ≤ M |g(x)|; • if ∃W ∈ NX(x0) such that g(x) , 0 for all x ∈ (W ∩ A) \ {x0}, and if the limit limx → x0 x ∈W ∩ A      f(x) g(x)      exists w.r.t. (X, R), then limx → x0 x ∈W ∩ A      f(x) g(x)      ∈ (0, +∞) ⇒ f(x) x0 ≍ g(x). Example We have seen that lim x → +∞ |x 2 + x + 1| |2 x 2 + 1| = 1 2 ⇒ x 2 + x + 1 +∞ ⪯ 2 x 2 + 1 and 2 x 2 + 1 +∞ ⪯ x 2 + x + 1. Thus, we have x 2 + x + 1 +∞ ≍ 2 x 2 + 1. Exercise Let A ⊆ R, f, g, h : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Let k ∈ R ∗ . Show that: • f(x) x0 ≍ 0 ⇔ ∃ V ∈ NX(x0) : ∀ x ∈ (V ∩ A) \ {x0}, f(x) = 0; • f(x) x0 ≍ f(x); • f(x) x0 ≍ g(x) ⇒ g(x) x0 ≍ f(x); • f(x) x0 ≍ g(x) and g(x) x0 ≍ h(x) ⇒ f(x) x0 ≍ h(x); • f(x) x0 ⪯ g(x) and f(x) x0 ≍ h(x) and g(x) x0 ≍ l(x) ⇒ h(x) x0 ⪯ l(x); • k , 0 ⇒ f(x) x0 ≍ k f(x). Exercise Let A ⊆ R, f, g, h : A −→ R, X ∈ TR, and let x0 ∈ DX(A). Show that: • f(x) x0 ≺≺ g(x) and g(x) x0 ⪯ h(x) ⇒ f(x) x0 ≺≺ h(x); • f(x) x0 ⪯ g(x) and g(x) x0 ≺≺ h(x) ⇒ f(x) x0 ≺≺ h(x); • f(x) x0 ≺≺ g(x) and f(x) x0 ≍ h(x) and g(x) x0 ≍ l(x) ⇒ h(x) x0 ≺≺ l(x). Page 176 of 175